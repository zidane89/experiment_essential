{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "\n",
    "from vehicle_model_DDPG2 import Environment \n",
    "from cell_model import CellModel \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_e-4wd_Battery.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_id_75_110_Westinghouse.mat\"\n",
    "cell_model = CellModel()\n",
    "env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64): \n",
    "        self.power_mean = 0 \n",
    "        self.power_std = 0\n",
    "        self.sum = 0 \n",
    "        self.sum_deviation = 0 \n",
    "        self.N = 0 \n",
    "        \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        self.N += 1 \n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "        power = obs_tuple[0][0] \n",
    "        \n",
    "        self.sum += power \n",
    "        self.power_mean = self.sum / self.N \n",
    "        self.sum_deviation += (power - self.power_mean) ** 2  \n",
    "        self.power_std = np.sqrt(self.sum_deviation / self.N) \n",
    "            \n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "        \n",
    "        state_batch = self.state_buffer[batch_indices]\n",
    "        power_batch = (state_batch[:, 0] - self.power_mean) / self.power_std\n",
    "        state_batch[:, 0] = power_batch \n",
    "        \n",
    "        next_state_batch = self.next_state_buffer[batch_indices]\n",
    "        power_batch = (next_state_batch[:, 0] - self.power_mean) / self.power_std\n",
    "        next_state_batch[:, 0] = power_batch \n",
    "#         print(state_batch)\n",
    "        \n",
    "        state_batch = tf.convert_to_tensor(state_batch)\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(next_state_batch)\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_input)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200\n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "\n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 21.864\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3307.748476306719 SOC: 1.0000 Cumulative_SOC_deviation: 323.1043 Fuel Consumption: 76.7056 Mean: 2.2368, STD: 5.0389\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 24.057\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3081.1689001913314 SOC: 1.0000 Cumulative_SOC_deviation: 300.4793 Fuel Consumption: 76.3755 Mean: 2.2368, STD: 5.0426\n",
      "WARNING:tensorflow:Layer dense_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 75.498\n",
      "Episode: 3 Exploration P: 0.9255 Total reward: -3219.518613133278 SOC: 1.0000 Cumulative_SOC_deviation: 314.4580 Fuel Consumption: 74.9385 Mean: 2.2368, STD: 5.0441\n",
      "Available condition is not avail... SOC: 0.9999848443012948\n",
      "elapsed_time: 86.349\n",
      "Episode: 4 Exploration P: 0.9019 Total reward: -2929.3589188814663 SOC: 1.0000 Cumulative_SOC_deviation: 285.6502 Fuel Consumption: 72.8570 Mean: 2.2368, STD: 5.0449\n",
      "Available condition is not avail... SOC: 0.9893127667402927\n",
      "elapsed_time: 74.024\n",
      "Episode: 5 Exploration P: 0.8789 Total reward: -2774.757261289039 SOC: 0.9893 Cumulative_SOC_deviation: 270.3675 Fuel Consumption: 71.0822 Mean: 2.2368, STD: 5.0454\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 96.536\n",
      "Episode: 6 Exploration P: 0.8554 Total reward: -2949.0165315276113 SOC: 1.0000 Cumulative_SOC_deviation: 287.6448 Fuel Consumption: 72.5686 Mean: 2.2142, STD: 5.0408\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.037\n",
      "Episode: 7 Exploration P: 0.8325 Total reward: -2678.062869713183 SOC: 0.9803 Cumulative_SOC_deviation: 260.7506 Fuel Consumption: 70.5566 Mean: 2.1983, STD: 5.0376\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.168\n",
      "Episode: 8 Exploration P: 0.8102 Total reward: -2702.418675482906 SOC: 0.9939 Cumulative_SOC_deviation: 263.0655 Fuel Consumption: 71.7638 Mean: 2.1865, STD: 5.0351\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.931\n",
      "Episode: 9 Exploration P: 0.7885 Total reward: -2350.3462083485138 SOC: 0.9590 Cumulative_SOC_deviation: 228.1059 Fuel Consumption: 69.2875 Mean: 2.1773, STD: 5.0332\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 109.889\n",
      "Episode: 10 Exploration P: 0.7674 Total reward: -2440.6454990988186 SOC: 0.9428 Cumulative_SOC_deviation: 237.2555 Fuel Consumption: 68.0906 Mean: 2.1701, STD: 5.0317\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.410\n",
      "Episode: 11 Exploration P: 0.7469 Total reward: -2076.0494632189575 SOC: 0.9125 Cumulative_SOC_deviation: 201.0167 Fuel Consumption: 65.8825 Mean: 2.1642, STD: 5.0305\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.658\n",
      "Episode: 12 Exploration P: 0.7269 Total reward: -2070.7327486513022 SOC: 0.9182 Cumulative_SOC_deviation: 200.4706 Fuel Consumption: 66.0269 Mean: 2.1593, STD: 5.0294\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.687\n",
      "Episode: 13 Exploration P: 0.7075 Total reward: -1853.7302823383538 SOC: 0.9026 Cumulative_SOC_deviation: 178.8477 Fuel Consumption: 65.2531 Mean: 2.1552, STD: 5.0285\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.452\n",
      "Episode: 14 Exploration P: 0.6886 Total reward: -1884.67553382473 SOC: 0.9061 Cumulative_SOC_deviation: 181.9433 Fuel Consumption: 65.2427 Mean: 2.1517, STD: 5.0278\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.270\n",
      "Episode: 15 Exploration P: 0.6703 Total reward: -1586.6727700513259 SOC: 0.8817 Cumulative_SOC_deviation: 152.2906 Fuel Consumption: 63.7673 Mean: 2.1486, STD: 5.0271\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.432\n",
      "Episode: 16 Exploration P: 0.6524 Total reward: -1573.3056397286136 SOC: 0.8661 Cumulative_SOC_deviation: 151.0746 Fuel Consumption: 62.5600 Mean: 2.1460, STD: 5.0266\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.155\n",
      "Episode: 17 Exploration P: 0.6350 Total reward: -1770.8668919360357 SOC: 0.8749 Cumulative_SOC_deviation: 170.7781 Fuel Consumption: 63.0863 Mean: 2.1436, STD: 5.0261\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.159\n",
      "Episode: 18 Exploration P: 0.6180 Total reward: -1331.4806024942523 SOC: 0.8530 Cumulative_SOC_deviation: 126.9890 Fuel Consumption: 61.5901 Mean: 2.1416, STD: 5.0256\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.223\n",
      "Episode: 19 Exploration P: 0.6016 Total reward: -1484.650460331456 SOC: 0.8563 Cumulative_SOC_deviation: 142.2771 Fuel Consumption: 61.8790 Mean: 2.1397, STD: 5.0252\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.645\n",
      "Episode: 20 Exploration P: 0.5855 Total reward: -1304.9066472185555 SOC: 0.8366 Cumulative_SOC_deviation: 124.4441 Fuel Consumption: 60.4654 Mean: 2.1380, STD: 5.0249\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.500\n",
      "Episode: 21 Exploration P: 0.5700 Total reward: -910.2854888696863 SOC: 0.7779 Cumulative_SOC_deviation: 85.4216 Fuel Consumption: 56.0699 Mean: 2.1365, STD: 5.0245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.805\n",
      "Episode: 22 Exploration P: 0.5548 Total reward: -1111.8921334589047 SOC: 0.7996 Cumulative_SOC_deviation: 105.4109 Fuel Consumption: 57.7827 Mean: 2.1352, STD: 5.0242\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.777\n",
      "Episode: 23 Exploration P: 0.5400 Total reward: -863.5418571926253 SOC: 0.7427 Cumulative_SOC_deviation: 81.0021 Fuel Consumption: 53.5213 Mean: 2.1339, STD: 5.0240\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.866\n",
      "Episode: 24 Exploration P: 0.5257 Total reward: -949.0377524195727 SOC: 0.7759 Cumulative_SOC_deviation: 89.3019 Fuel Consumption: 56.0183 Mean: 2.1328, STD: 5.0237\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.711\n",
      "Episode: 25 Exploration P: 0.5117 Total reward: -747.799749555121 SOC: 0.7489 Cumulative_SOC_deviation: 69.3566 Fuel Consumption: 54.2333 Mean: 2.1317, STD: 5.0235\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.905\n",
      "Episode: 26 Exploration P: 0.4981 Total reward: -872.991216056405 SOC: 0.7583 Cumulative_SOC_deviation: 81.8232 Fuel Consumption: 54.7595 Mean: 2.1307, STD: 5.0233\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.736\n",
      "Episode: 27 Exploration P: 0.4849 Total reward: -617.454441281278 SOC: 0.6977 Cumulative_SOC_deviation: 56.7245 Fuel Consumption: 50.2092 Mean: 2.1299, STD: 5.0231\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.812\n",
      "Episode: 28 Exploration P: 0.4720 Total reward: -740.3126799106453 SOC: 0.7257 Cumulative_SOC_deviation: 68.7679 Fuel Consumption: 52.6340 Mean: 2.1290, STD: 5.0229\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.888\n",
      "Episode: 29 Exploration P: 0.4595 Total reward: -510.27892808646266 SOC: 0.6815 Cumulative_SOC_deviation: 46.1215 Fuel Consumption: 49.0639 Mean: 2.1282, STD: 5.0227\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.278\n",
      "Episode: 30 Exploration P: 0.4473 Total reward: -625.3842936341435 SOC: 0.6506 Cumulative_SOC_deviation: 57.8240 Fuel Consumption: 47.1447 Mean: 2.1275, STD: 5.0226\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.750\n",
      "Episode: 31 Exploration P: 0.4355 Total reward: -579.4652304339019 SOC: 0.6497 Cumulative_SOC_deviation: 53.2651 Fuel Consumption: 46.8146 Mean: 2.1268, STD: 5.0224\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.095\n",
      "Episode: 32 Exploration P: 0.4240 Total reward: -500.03885254228766 SOC: 0.6884 Cumulative_SOC_deviation: 45.0180 Fuel Consumption: 49.8584 Mean: 2.1262, STD: 5.0223\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.905\n",
      "Episode: 33 Exploration P: 0.4128 Total reward: -603.4681834652807 SOC: 0.6468 Cumulative_SOC_deviation: 55.6509 Fuel Consumption: 46.9590 Mean: 2.1256, STD: 5.0222\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.556\n",
      "Episode: 34 Exploration P: 0.4019 Total reward: -693.437045295869 SOC: 0.6253 Cumulative_SOC_deviation: 64.8139 Fuel Consumption: 45.2978 Mean: 2.1251, STD: 5.0220\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.944\n",
      "Episode: 35 Exploration P: 0.3912 Total reward: -707.351883366969 SOC: 0.6516 Cumulative_SOC_deviation: 65.9949 Fuel Consumption: 47.4027 Mean: 2.1245, STD: 5.0219\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.015\n",
      "Episode: 36 Exploration P: 0.3809 Total reward: -564.561484562424 SOC: 0.6010 Cumulative_SOC_deviation: 52.1121 Fuel Consumption: 43.4405 Mean: 2.1240, STD: 5.0218\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.762\n",
      "Episode: 37 Exploration P: 0.3709 Total reward: -672.4955657102744 SOC: 0.6417 Cumulative_SOC_deviation: 62.5887 Fuel Consumption: 46.6082 Mean: 2.1236, STD: 5.0217\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.332\n",
      "Episode: 38 Exploration P: 0.3611 Total reward: -894.653856688715 SOC: 0.5851 Cumulative_SOC_deviation: 85.2039 Fuel Consumption: 42.6151 Mean: 2.1231, STD: 5.0216\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.432\n",
      "Episode: 39 Exploration P: 0.3516 Total reward: -876.1235960579307 SOC: 0.6030 Cumulative_SOC_deviation: 83.2291 Fuel Consumption: 43.8326 Mean: 2.1227, STD: 5.0215\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.108\n",
      "Episode: 40 Exploration P: 0.3423 Total reward: -1030.9082779504479 SOC: 0.5632 Cumulative_SOC_deviation: 98.9965 Fuel Consumption: 40.9435 Mean: 2.1223, STD: 5.0214\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.300\n",
      "Episode: 41 Exploration P: 0.3333 Total reward: -941.0292790026703 SOC: 0.5787 Cumulative_SOC_deviation: 89.8682 Fuel Consumption: 42.3468 Mean: 2.1219, STD: 5.0214\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.073\n",
      "Episode: 42 Exploration P: 0.3246 Total reward: -927.1689589573599 SOC: 0.5762 Cumulative_SOC_deviation: 88.5245 Fuel Consumption: 41.9238 Mean: 2.1216, STD: 5.0213\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.110\n",
      "Episode: 43 Exploration P: 0.3160 Total reward: -1567.630885218267 SOC: 0.5224 Cumulative_SOC_deviation: 152.9432 Fuel Consumption: 38.1989 Mean: 2.1212, STD: 5.0212\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.980\n",
      "Episode: 44 Exploration P: 0.3078 Total reward: -1126.9232448369867 SOC: 0.5530 Cumulative_SOC_deviation: 108.6547 Fuel Consumption: 40.3760 Mean: 2.1209, STD: 5.0211\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.202\n",
      "Episode: 45 Exploration P: 0.2997 Total reward: -1471.8412004807776 SOC: 0.5249 Cumulative_SOC_deviation: 143.3426 Fuel Consumption: 38.4156 Mean: 2.1206, STD: 5.0211\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.924\n",
      "Episode: 46 Exploration P: 0.2918 Total reward: -1489.8123111677626 SOC: 0.5157 Cumulative_SOC_deviation: 145.1882 Fuel Consumption: 37.9306 Mean: 2.1203, STD: 5.0210\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.332\n",
      "Episode: 47 Exploration P: 0.2842 Total reward: -1133.8680819360843 SOC: 0.5603 Cumulative_SOC_deviation: 109.2821 Fuel Consumption: 41.0467 Mean: 2.1200, STD: 5.0209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.407\n",
      "Episode: 48 Exploration P: 0.2768 Total reward: -1944.9764422981073 SOC: 0.4694 Cumulative_SOC_deviation: 191.0379 Fuel Consumption: 34.5979 Mean: 2.1197, STD: 5.0209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.463\n",
      "Episode: 49 Exploration P: 0.2696 Total reward: -1538.2236685260884 SOC: 0.4960 Cumulative_SOC_deviation: 150.1944 Fuel Consumption: 36.2797 Mean: 2.1194, STD: 5.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.223\n",
      "Episode: 50 Exploration P: 0.2625 Total reward: -1039.4884426369383 SOC: 0.6279 Cumulative_SOC_deviation: 99.3525 Fuel Consumption: 45.9632 Mean: 2.1192, STD: 5.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.972\n",
      "Episode: 51 Exploration P: 0.2557 Total reward: -335.2601270254077 SOC: 0.6413 Cumulative_SOC_deviation: 28.9503 Fuel Consumption: 45.7567 Mean: 2.1189, STD: 5.0207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.756\n",
      "Episode: 52 Exploration P: 0.2490 Total reward: -336.3897891755995 SOC: 0.6280 Cumulative_SOC_deviation: 29.1781 Fuel Consumption: 44.6085 Mean: 2.1187, STD: 5.0207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.473\n",
      "Episode: 53 Exploration P: 0.2426 Total reward: -313.21945764278036 SOC: 0.6247 Cumulative_SOC_deviation: 26.9101 Fuel Consumption: 44.1181 Mean: 2.1185, STD: 5.0206\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.461\n",
      "Episode: 54 Exploration P: 0.2363 Total reward: -166.4424017902012 SOC: 0.6214 Cumulative_SOC_deviation: 12.2509 Fuel Consumption: 43.9339 Mean: 2.1183, STD: 5.0206\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.236\n",
      "Episode: 55 Exploration P: 0.2301 Total reward: -175.71397056089688 SOC: 0.6134 Cumulative_SOC_deviation: 13.2337 Fuel Consumption: 43.3771 Mean: 2.1180, STD: 5.0205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.278\n",
      "Episode: 56 Exploration P: 0.2242 Total reward: -169.51970044273648 SOC: 0.6111 Cumulative_SOC_deviation: 12.6556 Fuel Consumption: 42.9633 Mean: 2.1178, STD: 5.0205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.214\n",
      "Episode: 57 Exploration P: 0.2184 Total reward: -176.3699028149922 SOC: 0.6279 Cumulative_SOC_deviation: 13.2763 Fuel Consumption: 43.6066 Mean: 2.1176, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.580\n",
      "Episode: 58 Exploration P: 0.2127 Total reward: -311.9791957907896 SOC: 0.6256 Cumulative_SOC_deviation: 26.7817 Fuel Consumption: 44.1626 Mean: 2.1175, STD: 5.0204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.111\n",
      "Episode: 59 Exploration P: 0.2072 Total reward: -196.0454304182059 SOC: 0.6306 Cumulative_SOC_deviation: 15.1643 Fuel Consumption: 44.4028 Mean: 2.1173, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.398\n",
      "Episode: 60 Exploration P: 0.2019 Total reward: -130.18059893491298 SOC: 0.6051 Cumulative_SOC_deviation: 8.8152 Fuel Consumption: 42.0288 Mean: 2.1171, STD: 5.0203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.548\n",
      "Episode: 61 Exploration P: 0.1967 Total reward: -133.56558270167412 SOC: 0.6029 Cumulative_SOC_deviation: 9.1204 Fuel Consumption: 42.3617 Mean: 2.1169, STD: 5.0203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.362\n",
      "Episode: 62 Exploration P: 0.1916 Total reward: -152.5705164632572 SOC: 0.6011 Cumulative_SOC_deviation: 11.0235 Fuel Consumption: 42.3352 Mean: 2.1168, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.570\n",
      "Episode: 63 Exploration P: 0.1867 Total reward: -176.4150248089364 SOC: 0.6076 Cumulative_SOC_deviation: 13.3334 Fuel Consumption: 43.0814 Mean: 2.1166, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.334\n",
      "Episode: 64 Exploration P: 0.1819 Total reward: -181.5265506433437 SOC: 0.6010 Cumulative_SOC_deviation: 13.8670 Fuel Consumption: 42.8562 Mean: 2.1164, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.270\n",
      "Episode: 65 Exploration P: 0.1773 Total reward: -178.38941860431245 SOC: 0.6028 Cumulative_SOC_deviation: 13.5622 Fuel Consumption: 42.7673 Mean: 2.1163, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.622\n",
      "Episode: 66 Exploration P: 0.1727 Total reward: -173.84445868843127 SOC: 0.6048 Cumulative_SOC_deviation: 13.0830 Fuel Consumption: 43.0146 Mean: 2.1162, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.245\n",
      "Episode: 67 Exploration P: 0.1683 Total reward: -157.24849302403396 SOC: 0.6048 Cumulative_SOC_deviation: 11.4524 Fuel Consumption: 42.7241 Mean: 2.1160, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.951\n",
      "Episode: 68 Exploration P: 0.1640 Total reward: -179.94571204896823 SOC: 0.6002 Cumulative_SOC_deviation: 13.7329 Fuel Consumption: 42.6165 Mean: 2.1159, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.142\n",
      "Episode: 69 Exploration P: 0.1599 Total reward: -164.65125923048427 SOC: 0.6014 Cumulative_SOC_deviation: 12.1962 Fuel Consumption: 42.6890 Mean: 2.1157, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.859\n",
      "Episode: 70 Exploration P: 0.1558 Total reward: -169.61533428801076 SOC: 0.6006 Cumulative_SOC_deviation: 12.7108 Fuel Consumption: 42.5071 Mean: 2.1156, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.882\n",
      "Episode: 71 Exploration P: 0.1519 Total reward: -167.51639517574677 SOC: 0.6021 Cumulative_SOC_deviation: 12.4866 Fuel Consumption: 42.6502 Mean: 2.1155, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.278\n",
      "Episode: 72 Exploration P: 0.1480 Total reward: -159.01590891557436 SOC: 0.6033 Cumulative_SOC_deviation: 11.6405 Fuel Consumption: 42.6106 Mean: 2.1154, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.722\n",
      "Episode: 73 Exploration P: 0.1443 Total reward: -146.06823010651138 SOC: 0.6017 Cumulative_SOC_deviation: 10.3847 Fuel Consumption: 42.2215 Mean: 2.1152, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.560\n",
      "Episode: 74 Exploration P: 0.1406 Total reward: -152.34461707323 SOC: 0.6018 Cumulative_SOC_deviation: 11.0074 Fuel Consumption: 42.2704 Mean: 2.1151, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.273\n",
      "Episode: 75 Exploration P: 0.1371 Total reward: -177.63103017589876 SOC: 0.6059 Cumulative_SOC_deviation: 13.4971 Fuel Consumption: 42.6596 Mean: 2.1150, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.550\n",
      "Episode: 76 Exploration P: 0.1337 Total reward: -175.88181498927915 SOC: 0.6083 Cumulative_SOC_deviation: 13.3328 Fuel Consumption: 42.5541 Mean: 2.1149, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.365\n",
      "Episode: 77 Exploration P: 0.1303 Total reward: -138.41553696540987 SOC: 0.6032 Cumulative_SOC_deviation: 9.6649 Fuel Consumption: 41.7662 Mean: 2.1148, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.323\n",
      "Episode: 78 Exploration P: 0.1271 Total reward: -166.1886400399398 SOC: 0.6090 Cumulative_SOC_deviation: 12.4214 Fuel Consumption: 41.9750 Mean: 2.1147, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.511\n",
      "Episode: 79 Exploration P: 0.1239 Total reward: -186.54237056959118 SOC: 0.6147 Cumulative_SOC_deviation: 14.4074 Fuel Consumption: 42.4682 Mean: 2.1146, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.585\n",
      "Episode: 80 Exploration P: 0.1208 Total reward: -201.4081910192433 SOC: 0.6091 Cumulative_SOC_deviation: 15.9577 Fuel Consumption: 41.8313 Mean: 2.1145, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.331\n",
      "Episode: 81 Exploration P: 0.1178 Total reward: -226.51601800593588 SOC: 0.6207 Cumulative_SOC_deviation: 18.4028 Fuel Consumption: 42.4882 Mean: 2.1144, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.244\n",
      "Episode: 82 Exploration P: 0.1149 Total reward: -233.71832565909773 SOC: 0.6122 Cumulative_SOC_deviation: 19.1772 Fuel Consumption: 41.9466 Mean: 2.1143, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.048\n",
      "Episode: 83 Exploration P: 0.1120 Total reward: -241.39217836007967 SOC: 0.6123 Cumulative_SOC_deviation: 19.9320 Fuel Consumption: 42.0727 Mean: 2.1142, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.081\n",
      "Episode: 84 Exploration P: 0.1093 Total reward: -279.88863670163295 SOC: 0.6198 Cumulative_SOC_deviation: 23.7205 Fuel Consumption: 42.6833 Mean: 2.1141, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.210\n",
      "Episode: 85 Exploration P: 0.1066 Total reward: -208.59160320461854 SOC: 0.6125 Cumulative_SOC_deviation: 16.6418 Fuel Consumption: 42.1732 Mean: 2.1140, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.549\n",
      "Episode: 86 Exploration P: 0.1040 Total reward: -198.9501629857068 SOC: 0.6124 Cumulative_SOC_deviation: 15.7119 Fuel Consumption: 41.8315 Mean: 2.1140, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.702\n",
      "Episode: 87 Exploration P: 0.1014 Total reward: -174.2154373615476 SOC: 0.6156 Cumulative_SOC_deviation: 13.2281 Fuel Consumption: 41.9347 Mean: 2.1139, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.660\n",
      "Episode: 88 Exploration P: 0.0989 Total reward: -173.1684861915454 SOC: 0.6154 Cumulative_SOC_deviation: 13.1227 Fuel Consumption: 41.9417 Mean: 2.1138, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.779\n",
      "Episode: 89 Exploration P: 0.0965 Total reward: -217.13245866497672 SOC: 0.6122 Cumulative_SOC_deviation: 17.5401 Fuel Consumption: 41.7312 Mean: 2.1137, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.487\n",
      "Episode: 90 Exploration P: 0.0942 Total reward: -195.7432822718938 SOC: 0.6095 Cumulative_SOC_deviation: 15.4114 Fuel Consumption: 41.6290 Mean: 2.1136, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.685\n",
      "Episode: 91 Exploration P: 0.0919 Total reward: -162.92379345908844 SOC: 0.6145 Cumulative_SOC_deviation: 12.0960 Fuel Consumption: 41.9637 Mean: 2.1136, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.922\n",
      "Episode: 92 Exploration P: 0.0897 Total reward: -153.04831665071677 SOC: 0.6159 Cumulative_SOC_deviation: 11.1095 Fuel Consumption: 41.9533 Mean: 2.1135, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.862\n",
      "Episode: 93 Exploration P: 0.0875 Total reward: -149.95366789354614 SOC: 0.6109 Cumulative_SOC_deviation: 10.8325 Fuel Consumption: 41.6283 Mean: 2.1134, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.044\n",
      "Episode: 94 Exploration P: 0.0854 Total reward: -156.9990392308059 SOC: 0.6115 Cumulative_SOC_deviation: 11.5595 Fuel Consumption: 41.4043 Mean: 2.1133, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.607\n",
      "Episode: 95 Exploration P: 0.0834 Total reward: -144.52323987702988 SOC: 0.6128 Cumulative_SOC_deviation: 10.2441 Fuel Consumption: 42.0818 Mean: 2.1133, STD: 5.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.552\n",
      "Episode: 96 Exploration P: 0.0814 Total reward: -143.43052585765392 SOC: 0.6142 Cumulative_SOC_deviation: 10.1260 Fuel Consumption: 42.1702 Mean: 2.1132, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.957\n",
      "Episode: 97 Exploration P: 0.0795 Total reward: -112.06640971442869 SOC: 0.6053 Cumulative_SOC_deviation: 7.1010 Fuel Consumption: 41.0564 Mean: 2.1131, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.114\n",
      "Episode: 98 Exploration P: 0.0776 Total reward: -102.99820269067203 SOC: 0.6060 Cumulative_SOC_deviation: 6.1769 Fuel Consumption: 41.2293 Mean: 2.1131, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.035\n",
      "Episode: 99 Exploration P: 0.0758 Total reward: -89.5344637105874 SOC: 0.6062 Cumulative_SOC_deviation: 4.8408 Fuel Consumption: 41.1262 Mean: 2.1130, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.589\n",
      "Episode: 100 Exploration P: 0.0740 Total reward: -87.40277763807934 SOC: 0.6059 Cumulative_SOC_deviation: 4.6199 Fuel Consumption: 41.2034 Mean: 2.1130, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.566\n",
      "Episode: 101 Exploration P: 0.0722 Total reward: -91.40538299657472 SOC: 0.6021 Cumulative_SOC_deviation: 5.0427 Fuel Consumption: 40.9787 Mean: 2.1129, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.082\n",
      "Episode: 102 Exploration P: 0.0706 Total reward: -90.95876063548727 SOC: 0.6060 Cumulative_SOC_deviation: 4.9648 Fuel Consumption: 41.3111 Mean: 2.1128, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.184\n",
      "Episode: 103 Exploration P: 0.0689 Total reward: -86.28208416781655 SOC: 0.6035 Cumulative_SOC_deviation: 4.5296 Fuel Consumption: 40.9861 Mean: 2.1128, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.372\n",
      "Episode: 104 Exploration P: 0.0673 Total reward: -111.2136984504556 SOC: 0.6004 Cumulative_SOC_deviation: 6.9579 Fuel Consumption: 41.6346 Mean: 2.1127, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.541\n",
      "Episode: 105 Exploration P: 0.0658 Total reward: -93.54454139865163 SOC: 0.5998 Cumulative_SOC_deviation: 5.2638 Fuel Consumption: 40.9065 Mean: 2.1127, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.697\n",
      "Episode: 106 Exploration P: 0.0643 Total reward: -107.66433324701407 SOC: 0.5991 Cumulative_SOC_deviation: 6.6677 Fuel Consumption: 40.9873 Mean: 2.1126, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.432\n",
      "Episode: 107 Exploration P: 0.0628 Total reward: -97.46200349998675 SOC: 0.6033 Cumulative_SOC_deviation: 5.6291 Fuel Consumption: 41.1711 Mean: 2.1125, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.708\n",
      "Episode: 108 Exploration P: 0.0614 Total reward: -100.74652977302894 SOC: 0.6029 Cumulative_SOC_deviation: 5.9031 Fuel Consumption: 41.7158 Mean: 2.1125, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.642\n",
      "Episode: 109 Exploration P: 0.0600 Total reward: -96.02271621726473 SOC: 0.5993 Cumulative_SOC_deviation: 5.5067 Fuel Consumption: 40.9555 Mean: 2.1124, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.486\n",
      "Episode: 110 Exploration P: 0.0586 Total reward: -116.45398859379421 SOC: 0.6031 Cumulative_SOC_deviation: 7.4727 Fuel Consumption: 41.7275 Mean: 2.1124, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.781\n",
      "Episode: 111 Exploration P: 0.0573 Total reward: -128.21438365043147 SOC: 0.6066 Cumulative_SOC_deviation: 8.6129 Fuel Consumption: 42.0854 Mean: 2.1123, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.707\n",
      "Episode: 112 Exploration P: 0.0560 Total reward: -90.15536523066308 SOC: 0.6029 Cumulative_SOC_deviation: 4.8960 Fuel Consumption: 41.1955 Mean: 2.1123, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.912\n",
      "Episode: 113 Exploration P: 0.0548 Total reward: -93.2400355828078 SOC: 0.6021 Cumulative_SOC_deviation: 5.1910 Fuel Consumption: 41.3301 Mean: 2.1122, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.867\n",
      "Episode: 114 Exploration P: 0.0536 Total reward: -124.49905743324199 SOC: 0.5984 Cumulative_SOC_deviation: 8.3209 Fuel Consumption: 41.2898 Mean: 2.1122, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.865\n",
      "Episode: 115 Exploration P: 0.0524 Total reward: -127.19511611951394 SOC: 0.5980 Cumulative_SOC_deviation: 8.6004 Fuel Consumption: 41.1912 Mean: 2.1121, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.850\n",
      "Episode: 116 Exploration P: 0.0512 Total reward: -142.60058086772867 SOC: 0.6031 Cumulative_SOC_deviation: 10.1035 Fuel Consumption: 41.5659 Mean: 2.1121, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.959\n",
      "Episode: 117 Exploration P: 0.0501 Total reward: -142.4337409709303 SOC: 0.6024 Cumulative_SOC_deviation: 10.0679 Fuel Consumption: 41.7550 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.863\n",
      "Episode: 118 Exploration P: 0.0490 Total reward: -140.4079429008487 SOC: 0.6066 Cumulative_SOC_deviation: 9.8297 Fuel Consumption: 42.1106 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.630\n",
      "Episode: 119 Exploration P: 0.0480 Total reward: -117.54701438091115 SOC: 0.6034 Cumulative_SOC_deviation: 7.6273 Fuel Consumption: 41.2737 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.728\n",
      "Episode: 120 Exploration P: 0.0469 Total reward: -111.37068387938443 SOC: 0.6061 Cumulative_SOC_deviation: 6.9960 Fuel Consumption: 41.4109 Mean: 2.1119, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.894\n",
      "Episode: 121 Exploration P: 0.0459 Total reward: -91.72945556081692 SOC: 0.6023 Cumulative_SOC_deviation: 5.0741 Fuel Consumption: 40.9884 Mean: 2.1119, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.397\n",
      "Episode: 122 Exploration P: 0.0450 Total reward: -125.57988739939933 SOC: 0.6049 Cumulative_SOC_deviation: 8.3532 Fuel Consumption: 42.0477 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.697\n",
      "Episode: 123 Exploration P: 0.0440 Total reward: -111.9261469125901 SOC: 0.6049 Cumulative_SOC_deviation: 7.0274 Fuel Consumption: 41.6518 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.867\n",
      "Episode: 124 Exploration P: 0.0431 Total reward: -104.97546492672703 SOC: 0.6052 Cumulative_SOC_deviation: 6.3281 Fuel Consumption: 41.6942 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.796\n",
      "Episode: 125 Exploration P: 0.0422 Total reward: -83.70476164558963 SOC: 0.6037 Cumulative_SOC_deviation: 4.2635 Fuel Consumption: 41.0702 Mean: 2.1117, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.146\n",
      "Episode: 126 Exploration P: 0.0413 Total reward: -107.74105183668424 SOC: 0.6058 Cumulative_SOC_deviation: 6.6346 Fuel Consumption: 41.3953 Mean: 2.1117, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.390\n",
      "Episode: 127 Exploration P: 0.0405 Total reward: -115.575506486929 SOC: 0.6031 Cumulative_SOC_deviation: 7.4132 Fuel Consumption: 41.4438 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.520\n",
      "Episode: 128 Exploration P: 0.0397 Total reward: -108.36632941437499 SOC: 0.6047 Cumulative_SOC_deviation: 6.7056 Fuel Consumption: 41.3108 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.795\n",
      "Episode: 129 Exploration P: 0.0389 Total reward: -117.46437739118535 SOC: 0.6048 Cumulative_SOC_deviation: 7.6189 Fuel Consumption: 41.2757 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.878\n",
      "Episode: 130 Exploration P: 0.0381 Total reward: -114.06981047184135 SOC: 0.6073 Cumulative_SOC_deviation: 7.2813 Fuel Consumption: 41.2568 Mean: 2.1115, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.757\n",
      "Episode: 131 Exploration P: 0.0373 Total reward: -125.28833180935008 SOC: 0.6092 Cumulative_SOC_deviation: 8.3759 Fuel Consumption: 41.5293 Mean: 2.1115, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.785\n",
      "Episode: 132 Exploration P: 0.0366 Total reward: -98.4793031591917 SOC: 0.6044 Cumulative_SOC_deviation: 5.7246 Fuel Consumption: 41.2336 Mean: 2.1114, STD: 5.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.834\n",
      "Episode: 133 Exploration P: 0.0359 Total reward: -139.38855596197715 SOC: 0.6063 Cumulative_SOC_deviation: 9.7673 Fuel Consumption: 41.7151 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.699\n",
      "Episode: 134 Exploration P: 0.0352 Total reward: -115.96886795543391 SOC: 0.6040 Cumulative_SOC_deviation: 7.4586 Fuel Consumption: 41.3826 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.583\n",
      "Episode: 135 Exploration P: 0.0345 Total reward: -135.20721815862728 SOC: 0.6037 Cumulative_SOC_deviation: 9.3797 Fuel Consumption: 41.4106 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.024\n",
      "Episode: 136 Exploration P: 0.0338 Total reward: -123.88474380673541 SOC: 0.6038 Cumulative_SOC_deviation: 8.2788 Fuel Consumption: 41.0965 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.808\n",
      "Episode: 137 Exploration P: 0.0332 Total reward: -147.5606231865747 SOC: 0.6029 Cumulative_SOC_deviation: 10.6094 Fuel Consumption: 41.4664 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.814\n",
      "Episode: 138 Exploration P: 0.0325 Total reward: -132.1001721360664 SOC: 0.6077 Cumulative_SOC_deviation: 9.0430 Fuel Consumption: 41.6707 Mean: 2.1112, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.717\n",
      "Episode: 139 Exploration P: 0.0319 Total reward: -156.19306662524664 SOC: 0.6009 Cumulative_SOC_deviation: 11.4578 Fuel Consumption: 41.6152 Mean: 2.1112, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.205\n",
      "Episode: 140 Exploration P: 0.0313 Total reward: -127.38073967376721 SOC: 0.6011 Cumulative_SOC_deviation: 8.6053 Fuel Consumption: 41.3279 Mean: 2.1112, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.228\n",
      "Episode: 141 Exploration P: 0.0308 Total reward: -137.53780860360175 SOC: 0.5972 Cumulative_SOC_deviation: 9.6158 Fuel Consumption: 41.3798 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.123\n",
      "Episode: 142 Exploration P: 0.0302 Total reward: -129.91734647827482 SOC: 0.6026 Cumulative_SOC_deviation: 8.8458 Fuel Consumption: 41.4594 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.011\n",
      "Episode: 143 Exploration P: 0.0296 Total reward: -107.5222575539408 SOC: 0.6037 Cumulative_SOC_deviation: 6.6363 Fuel Consumption: 41.1594 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.091\n",
      "Episode: 144 Exploration P: 0.0291 Total reward: -112.89971334293776 SOC: 0.6049 Cumulative_SOC_deviation: 7.1678 Fuel Consumption: 41.2221 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.975\n",
      "Episode: 145 Exploration P: 0.0286 Total reward: -93.13851978213614 SOC: 0.6046 Cumulative_SOC_deviation: 5.2102 Fuel Consumption: 41.0369 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.100\n",
      "Episode: 146 Exploration P: 0.0281 Total reward: -93.00926694022561 SOC: 0.6007 Cumulative_SOC_deviation: 5.1919 Fuel Consumption: 41.0899 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.238\n",
      "Episode: 147 Exploration P: 0.0276 Total reward: -132.96163145771803 SOC: 0.6010 Cumulative_SOC_deviation: 9.1399 Fuel Consumption: 41.5631 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.359\n",
      "Episode: 148 Exploration P: 0.0271 Total reward: -124.59462273619812 SOC: 0.6018 Cumulative_SOC_deviation: 8.2942 Fuel Consumption: 41.6522 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.006\n",
      "Episode: 149 Exploration P: 0.0267 Total reward: -123.38649202566248 SOC: 0.6013 Cumulative_SOC_deviation: 8.1799 Fuel Consumption: 41.5879 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.155\n",
      "Episode: 150 Exploration P: 0.0262 Total reward: -144.30093711957892 SOC: 0.6031 Cumulative_SOC_deviation: 10.2377 Fuel Consumption: 41.9236 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.192\n",
      "Episode: 151 Exploration P: 0.0258 Total reward: -141.4871014632133 SOC: 0.6005 Cumulative_SOC_deviation: 9.9783 Fuel Consumption: 41.7036 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.926\n",
      "Episode: 152 Exploration P: 0.0253 Total reward: -136.87658052679265 SOC: 0.5993 Cumulative_SOC_deviation: 9.5429 Fuel Consumption: 41.4472 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.634\n",
      "Episode: 153 Exploration P: 0.0249 Total reward: -115.00300206198801 SOC: 0.6055 Cumulative_SOC_deviation: 7.3333 Fuel Consumption: 41.6703 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.654\n",
      "Episode: 154 Exploration P: 0.0245 Total reward: -114.01576375583494 SOC: 0.6041 Cumulative_SOC_deviation: 7.2619 Fuel Consumption: 41.3963 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.823\n",
      "Episode: 155 Exploration P: 0.0241 Total reward: -100.81583444213862 SOC: 0.6022 Cumulative_SOC_deviation: 5.9687 Fuel Consumption: 41.1290 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.980\n",
      "Episode: 156 Exploration P: 0.0237 Total reward: -103.40479130100142 SOC: 0.6037 Cumulative_SOC_deviation: 6.1941 Fuel Consumption: 41.4640 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.606\n",
      "Episode: 157 Exploration P: 0.0234 Total reward: -105.73038358724757 SOC: 0.6049 Cumulative_SOC_deviation: 6.4031 Fuel Consumption: 41.6991 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.743\n",
      "Episode: 158 Exploration P: 0.0230 Total reward: -99.09281247432796 SOC: 0.6064 Cumulative_SOC_deviation: 5.7982 Fuel Consumption: 41.1110 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.443\n",
      "Episode: 159 Exploration P: 0.0227 Total reward: -101.31162202359798 SOC: 0.6010 Cumulative_SOC_deviation: 6.0568 Fuel Consumption: 40.7435 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.728\n",
      "Episode: 160 Exploration P: 0.0223 Total reward: -97.20524132962512 SOC: 0.6040 Cumulative_SOC_deviation: 5.6046 Fuel Consumption: 41.1593 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.680\n",
      "Episode: 161 Exploration P: 0.0220 Total reward: -97.55132374328547 SOC: 0.6008 Cumulative_SOC_deviation: 5.6562 Fuel Consumption: 40.9889 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.598\n",
      "Episode: 162 Exploration P: 0.0217 Total reward: -91.45755168526006 SOC: 0.6014 Cumulative_SOC_deviation: 5.0390 Fuel Consumption: 41.0671 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.625\n",
      "Episode: 163 Exploration P: 0.0213 Total reward: -100.09876688907607 SOC: 0.6039 Cumulative_SOC_deviation: 5.8605 Fuel Consumption: 41.4938 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.795\n",
      "Episode: 164 Exploration P: 0.0210 Total reward: -102.51198275031847 SOC: 0.6050 Cumulative_SOC_deviation: 6.0697 Fuel Consumption: 41.8147 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.693\n",
      "Episode: 165 Exploration P: 0.0207 Total reward: -96.21647929864075 SOC: 0.6042 Cumulative_SOC_deviation: 5.5025 Fuel Consumption: 41.1912 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.188\n",
      "Episode: 166 Exploration P: 0.0204 Total reward: -106.88231734456916 SOC: 0.5962 Cumulative_SOC_deviation: 6.6155 Fuel Consumption: 40.7269 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.779\n",
      "Episode: 167 Exploration P: 0.0202 Total reward: -121.07105590553704 SOC: 0.6092 Cumulative_SOC_deviation: 7.9457 Fuel Consumption: 41.6136 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.741\n",
      "Episode: 168 Exploration P: 0.0199 Total reward: -124.16465815892494 SOC: 0.6119 Cumulative_SOC_deviation: 8.2617 Fuel Consumption: 41.5475 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.482\n",
      "Episode: 169 Exploration P: 0.0196 Total reward: -135.25918473503015 SOC: 0.6067 Cumulative_SOC_deviation: 9.4139 Fuel Consumption: 41.1198 Mean: 2.1104, STD: 5.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.782\n",
      "Episode: 170 Exploration P: 0.0194 Total reward: -108.11612098013033 SOC: 0.6105 Cumulative_SOC_deviation: 6.6419 Fuel Consumption: 41.6969 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.565\n",
      "Episode: 171 Exploration P: 0.0191 Total reward: -130.50357949542766 SOC: 0.5928 Cumulative_SOC_deviation: 8.9825 Fuel Consumption: 40.6783 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.380\n",
      "Episode: 172 Exploration P: 0.0189 Total reward: -162.92566083028038 SOC: 0.6024 Cumulative_SOC_deviation: 11.9946 Fuel Consumption: 42.9798 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.584\n",
      "Episode: 173 Exploration P: 0.0186 Total reward: -103.4001159690034 SOC: 0.6046 Cumulative_SOC_deviation: 6.1911 Fuel Consumption: 41.4895 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.643\n",
      "Episode: 174 Exploration P: 0.0184 Total reward: -140.01546301107507 SOC: 0.6084 Cumulative_SOC_deviation: 9.8248 Fuel Consumption: 41.7672 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.435\n",
      "Episode: 175 Exploration P: 0.0182 Total reward: -156.5441076904978 SOC: 0.6106 Cumulative_SOC_deviation: 11.3496 Fuel Consumption: 43.0485 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.692\n",
      "Episode: 176 Exploration P: 0.0179 Total reward: -119.0929266169036 SOC: 0.6070 Cumulative_SOC_deviation: 7.7354 Fuel Consumption: 41.7388 Mean: 2.1103, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.455\n",
      "Episode: 177 Exploration P: 0.0177 Total reward: -142.71458308781698 SOC: 0.6117 Cumulative_SOC_deviation: 10.0171 Fuel Consumption: 42.5432 Mean: 2.1103, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.577\n",
      "Episode: 178 Exploration P: 0.0175 Total reward: -144.16171973468818 SOC: 0.6095 Cumulative_SOC_deviation: 10.1840 Fuel Consumption: 42.3214 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.399\n",
      "Episode: 179 Exploration P: 0.0173 Total reward: -123.97731255115625 SOC: 0.6074 Cumulative_SOC_deviation: 8.1976 Fuel Consumption: 42.0016 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.630\n",
      "Episode: 180 Exploration P: 0.0171 Total reward: -115.34336901118348 SOC: 0.6036 Cumulative_SOC_deviation: 7.3740 Fuel Consumption: 41.6032 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.822\n",
      "Episode: 181 Exploration P: 0.0169 Total reward: -104.60479176868154 SOC: 0.6007 Cumulative_SOC_deviation: 6.3586 Fuel Consumption: 41.0188 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.637\n",
      "Episode: 182 Exploration P: 0.0167 Total reward: -101.21115106308505 SOC: 0.5956 Cumulative_SOC_deviation: 6.0140 Fuel Consumption: 41.0709 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.215\n",
      "Episode: 183 Exploration P: 0.0165 Total reward: -98.69748454729731 SOC: 0.6078 Cumulative_SOC_deviation: 5.6206 Fuel Consumption: 42.4912 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.108\n",
      "Episode: 184 Exploration P: 0.0164 Total reward: -109.93667558143677 SOC: 0.6096 Cumulative_SOC_deviation: 6.7834 Fuel Consumption: 42.1023 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.325\n",
      "Episode: 185 Exploration P: 0.0162 Total reward: -101.88333024086552 SOC: 0.6049 Cumulative_SOC_deviation: 6.0788 Fuel Consumption: 41.0951 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.951\n",
      "Episode: 186 Exploration P: 0.0160 Total reward: -100.78907918159867 SOC: 0.6022 Cumulative_SOC_deviation: 5.9417 Fuel Consumption: 41.3718 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.087\n",
      "Episode: 187 Exploration P: 0.0159 Total reward: -92.60855581158467 SOC: 0.6054 Cumulative_SOC_deviation: 5.0476 Fuel Consumption: 42.1324 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.810\n",
      "Episode: 188 Exploration P: 0.0157 Total reward: -82.68642837181862 SOC: 0.6036 Cumulative_SOC_deviation: 4.1615 Fuel Consumption: 41.0719 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.279\n",
      "Episode: 189 Exploration P: 0.0156 Total reward: -104.18194519791582 SOC: 0.6000 Cumulative_SOC_deviation: 6.2627 Fuel Consumption: 41.5546 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.592\n",
      "Episode: 190 Exploration P: 0.0154 Total reward: -103.49481181547308 SOC: 0.5982 Cumulative_SOC_deviation: 6.1290 Fuel Consumption: 42.2044 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.416\n",
      "Episode: 191 Exploration P: 0.0153 Total reward: -94.4482630000234 SOC: 0.6062 Cumulative_SOC_deviation: 5.2338 Fuel Consumption: 42.1107 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.495\n",
      "Episode: 192 Exploration P: 0.0151 Total reward: -86.37656347457273 SOC: 0.5983 Cumulative_SOC_deviation: 4.5154 Fuel Consumption: 41.2223 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.783\n",
      "Episode: 193 Exploration P: 0.0150 Total reward: -92.98191180795084 SOC: 0.6029 Cumulative_SOC_deviation: 5.0820 Fuel Consumption: 42.1615 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.398\n",
      "Episode: 194 Exploration P: 0.0148 Total reward: -110.44272040923182 SOC: 0.6029 Cumulative_SOC_deviation: 6.7703 Fuel Consumption: 42.7399 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.330\n",
      "Episode: 195 Exploration P: 0.0147 Total reward: -101.2427728520714 SOC: 0.6011 Cumulative_SOC_deviation: 5.8721 Fuel Consumption: 42.5217 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.669\n",
      "Episode: 196 Exploration P: 0.0146 Total reward: -91.80494589060747 SOC: 0.6045 Cumulative_SOC_deviation: 4.9675 Fuel Consumption: 42.1298 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.519\n",
      "Episode: 197 Exploration P: 0.0145 Total reward: -88.21474896701544 SOC: 0.6023 Cumulative_SOC_deviation: 4.6510 Fuel Consumption: 41.7052 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.605\n",
      "Episode: 198 Exploration P: 0.0143 Total reward: -87.76233306014626 SOC: 0.6039 Cumulative_SOC_deviation: 4.5859 Fuel Consumption: 41.9029 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.691\n",
      "Episode: 199 Exploration P: 0.0142 Total reward: -81.7010396993106 SOC: 0.5958 Cumulative_SOC_deviation: 4.0708 Fuel Consumption: 40.9927 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.501\n",
      "Episode: 200 Exploration P: 0.0141 Total reward: -79.28428054514833 SOC: 0.5981 Cumulative_SOC_deviation: 3.8037 Fuel Consumption: 41.2468 Mean: 2.1099, STD: 5.0188\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 24.349\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3120.0588971410366 SOC: 1.0000 Cumulative_SOC_deviation: 304.4798 Fuel Consumption: 75.2611 Mean: 2.2368, STD: 5.0389\n",
      "Available condition is not avail... SOC: 0.9994583943739926\n",
      "elapsed_time: 24.108\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3322.715333638443 SOC: 0.9995 Cumulative_SOC_deviation: 324.6309 Fuel Consumption: 76.4064 Mean: 2.2368, STD: 5.0426\n",
      "WARNING:tensorflow:Layer dense_27 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_31 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_22 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_23 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_18 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Available condition is not avail... SOC: 0.9988796349385357\n",
      "elapsed_time: 60.010\n",
      "Episode: 3 Exploration P: 0.9255 Total reward: -3126.961812798018 SOC: 0.9989 Cumulative_SOC_deviation: 305.2367 Fuel Consumption: 74.5946 Mean: 2.2368, STD: 5.0441\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 70.850\n",
      "Episode: 4 Exploration P: 0.9019 Total reward: -3014.5867779110504 SOC: 1.0000 Cumulative_SOC_deviation: 294.1028 Fuel Consumption: 73.5586 Mean: 2.2368, STD: 5.0449\n",
      "Available condition is not avail... SOC: 0.9970509127666067\n",
      "elapsed_time: 76.164\n",
      "Episode: 5 Exploration P: 0.8789 Total reward: -2766.6364587643525 SOC: 0.9971 Cumulative_SOC_deviation: 269.5080 Fuel Consumption: 71.5569 Mean: 2.2368, STD: 5.0454\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.871\n",
      "Episode: 6 Exploration P: 0.8554 Total reward: -3019.0709633390497 SOC: 1.0000 Cumulative_SOC_deviation: 294.6884 Fuel Consumption: 72.1869 Mean: 2.2142, STD: 5.0408\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.075\n",
      "Episode: 7 Exploration P: 0.8325 Total reward: -2795.9963978137453 SOC: 0.9966 Cumulative_SOC_deviation: 272.4016 Fuel Consumption: 71.9805 Mean: 2.1983, STD: 5.0376\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.780\n",
      "Episode: 8 Exploration P: 0.8102 Total reward: -2592.4145816645573 SOC: 0.9753 Cumulative_SOC_deviation: 252.1889 Fuel Consumption: 70.5256 Mean: 2.1865, STD: 5.0351\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.505\n",
      "Episode: 9 Exploration P: 0.7885 Total reward: -2643.040591612867 SOC: 0.9718 Cumulative_SOC_deviation: 257.2886 Fuel Consumption: 70.1542 Mean: 2.1773, STD: 5.0332\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.331\n",
      "Episode: 10 Exploration P: 0.7674 Total reward: -2320.3712079767456 SOC: 0.9464 Cumulative_SOC_deviation: 225.2157 Fuel Consumption: 68.2144 Mean: 2.1701, STD: 5.0317\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.410\n",
      "Episode: 11 Exploration P: 0.7469 Total reward: -2086.4451279243453 SOC: 0.9255 Cumulative_SOC_deviation: 201.9902 Fuel Consumption: 66.5428 Mean: 2.1642, STD: 5.0305\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.201\n",
      "Episode: 12 Exploration P: 0.7269 Total reward: -2202.0206935264373 SOC: 0.9307 Cumulative_SOC_deviation: 213.4941 Fuel Consumption: 67.0794 Mean: 2.1593, STD: 5.0294\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.409\n",
      "Episode: 13 Exploration P: 0.7075 Total reward: -2143.980012607653 SOC: 0.9249 Cumulative_SOC_deviation: 207.7190 Fuel Consumption: 66.7905 Mean: 2.1552, STD: 5.0285\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.010\n",
      "Episode: 14 Exploration P: 0.6886 Total reward: -1880.5751563268052 SOC: 0.8819 Cumulative_SOC_deviation: 181.6994 Fuel Consumption: 63.5815 Mean: 2.1517, STD: 5.0278\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.450\n",
      "Episode: 15 Exploration P: 0.6703 Total reward: -1622.5658250874371 SOC: 0.8758 Cumulative_SOC_deviation: 155.9552 Fuel Consumption: 63.0140 Mean: 2.1486, STD: 5.0271\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.695\n",
      "Episode: 16 Exploration P: 0.6524 Total reward: -1328.0859716044972 SOC: 0.8354 Cumulative_SOC_deviation: 126.7693 Fuel Consumption: 60.3932 Mean: 2.1460, STD: 5.0266\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.346\n",
      "Episode: 17 Exploration P: 0.6350 Total reward: -1572.4916207741808 SOC: 0.8610 Cumulative_SOC_deviation: 151.0375 Fuel Consumption: 62.1164 Mean: 2.1436, STD: 5.0261\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.371\n",
      "Episode: 18 Exploration P: 0.6180 Total reward: -1323.3474745761398 SOC: 0.8315 Cumulative_SOC_deviation: 126.3450 Fuel Consumption: 59.8980 Mean: 2.1416, STD: 5.0256\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.995\n",
      "Episode: 19 Exploration P: 0.6016 Total reward: -1449.124747072003 SOC: 0.8470 Cumulative_SOC_deviation: 138.7968 Fuel Consumption: 61.1568 Mean: 2.1397, STD: 5.0252\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.874\n",
      "Episode: 20 Exploration P: 0.5855 Total reward: -883.5476553601266 SOC: 0.7738 Cumulative_SOC_deviation: 82.7746 Fuel Consumption: 55.8017 Mean: 2.1380, STD: 5.0249\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.369\n",
      "Episode: 21 Exploration P: 0.5700 Total reward: -1193.29805598602 SOC: 0.8147 Cumulative_SOC_deviation: 113.4453 Fuel Consumption: 58.8455 Mean: 2.1365, STD: 5.0245\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.932\n",
      "Episode: 22 Exploration P: 0.5548 Total reward: -1125.524134797453 SOC: 0.7891 Cumulative_SOC_deviation: 106.8515 Fuel Consumption: 57.0089 Mean: 2.1352, STD: 5.0242\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.562\n",
      "Episode: 23 Exploration P: 0.5400 Total reward: -1149.5796519943326 SOC: 0.8068 Cumulative_SOC_deviation: 109.1395 Fuel Consumption: 58.1851 Mean: 2.1339, STD: 5.0240\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.144\n",
      "Episode: 24 Exploration P: 0.5257 Total reward: -899.5267545286403 SOC: 0.7561 Cumulative_SOC_deviation: 84.5005 Fuel Consumption: 54.5222 Mean: 2.1328, STD: 5.0237\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.545\n",
      "Episode: 25 Exploration P: 0.5117 Total reward: -954.0608242435378 SOC: 0.7734 Cumulative_SOC_deviation: 89.8228 Fuel Consumption: 55.8326 Mean: 2.1317, STD: 5.0235\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.899\n",
      "Episode: 26 Exploration P: 0.4981 Total reward: -785.0821002277239 SOC: 0.7388 Cumulative_SOC_deviation: 73.1901 Fuel Consumption: 53.1808 Mean: 2.1307, STD: 5.0233\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.273\n",
      "Episode: 27 Exploration P: 0.4849 Total reward: -601.3543843016356 SOC: 0.7149 Cumulative_SOC_deviation: 54.9701 Fuel Consumption: 51.6538 Mean: 2.1299, STD: 5.0231\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.019\n",
      "Episode: 28 Exploration P: 0.4720 Total reward: -584.0782963114947 SOC: 0.7042 Cumulative_SOC_deviation: 53.3198 Fuel Consumption: 50.8799 Mean: 2.1290, STD: 5.0229\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.027\n",
      "Episode: 29 Exploration P: 0.4595 Total reward: -617.8121456643004 SOC: 0.7101 Cumulative_SOC_deviation: 56.6385 Fuel Consumption: 51.4268 Mean: 2.1282, STD: 5.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.070\n",
      "Episode: 30 Exploration P: 0.4473 Total reward: -566.7483522818159 SOC: 0.6769 Cumulative_SOC_deviation: 51.7850 Fuel Consumption: 48.8988 Mean: 2.1275, STD: 5.0226\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.397\n",
      "Episode: 31 Exploration P: 0.4355 Total reward: -552.0198724670125 SOC: 0.6844 Cumulative_SOC_deviation: 50.2265 Fuel Consumption: 49.7552 Mean: 2.1268, STD: 5.0224\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.368\n",
      "Episode: 32 Exploration P: 0.4240 Total reward: -698.3110373974553 SOC: 0.6305 Cumulative_SOC_deviation: 65.2497 Fuel Consumption: 45.8137 Mean: 2.1262, STD: 5.0223\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.304\n",
      "Episode: 33 Exploration P: 0.4128 Total reward: -582.3311700521274 SOC: 0.6460 Cumulative_SOC_deviation: 53.5486 Fuel Consumption: 46.8455 Mean: 2.1256, STD: 5.0222\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.168\n",
      "Episode: 34 Exploration P: 0.4019 Total reward: -734.9237839818193 SOC: 0.6192 Cumulative_SOC_deviation: 68.9884 Fuel Consumption: 45.0398 Mean: 2.1251, STD: 5.0220\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.638\n",
      "Episode: 35 Exploration P: 0.3912 Total reward: -475.32804958041606 SOC: 0.6461 Cumulative_SOC_deviation: 42.8524 Fuel Consumption: 46.8042 Mean: 2.1245, STD: 5.0219\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.195\n",
      "Episode: 36 Exploration P: 0.3809 Total reward: -605.6547751293976 SOC: 0.6094 Cumulative_SOC_deviation: 56.1461 Fuel Consumption: 44.1937 Mean: 2.1240, STD: 5.0218\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.925\n",
      "Episode: 37 Exploration P: 0.3709 Total reward: -783.777879321802 SOC: 0.6113 Cumulative_SOC_deviation: 73.9264 Fuel Consumption: 44.5136 Mean: 2.1236, STD: 5.0217\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.264\n",
      "Episode: 38 Exploration P: 0.3611 Total reward: -779.7105950555751 SOC: 0.5911 Cumulative_SOC_deviation: 73.6683 Fuel Consumption: 43.0278 Mean: 2.1231, STD: 5.0216\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.212\n",
      "Episode: 39 Exploration P: 0.3516 Total reward: -757.2265898822609 SOC: 0.5866 Cumulative_SOC_deviation: 71.4539 Fuel Consumption: 42.6873 Mean: 2.1227, STD: 5.0215\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.982\n",
      "Episode: 40 Exploration P: 0.3423 Total reward: -823.994533473566 SOC: 0.5760 Cumulative_SOC_deviation: 78.2009 Fuel Consumption: 41.9857 Mean: 2.1223, STD: 5.0214\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.294\n",
      "Episode: 41 Exploration P: 0.3333 Total reward: -1511.563679676506 SOC: 0.5460 Cumulative_SOC_deviation: 147.1538 Fuel Consumption: 40.0252 Mean: 2.1219, STD: 5.0214\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.429\n",
      "Episode: 42 Exploration P: 0.3246 Total reward: -1518.4040026550504 SOC: 0.5323 Cumulative_SOC_deviation: 147.9380 Fuel Consumption: 39.0244 Mean: 2.1216, STD: 5.0213\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.058\n",
      "Episode: 43 Exploration P: 0.3160 Total reward: -1274.0668337941452 SOC: 0.5403 Cumulative_SOC_deviation: 123.4547 Fuel Consumption: 39.5196 Mean: 2.1212, STD: 5.0212\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.250\n",
      "Episode: 44 Exploration P: 0.3078 Total reward: -1470.9529918573376 SOC: 0.5172 Cumulative_SOC_deviation: 143.3033 Fuel Consumption: 37.9203 Mean: 2.1209, STD: 5.0211\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.371\n",
      "Episode: 45 Exploration P: 0.2997 Total reward: -1676.2877334340071 SOC: 0.5011 Cumulative_SOC_deviation: 163.9492 Fuel Consumption: 36.7956 Mean: 2.1206, STD: 5.0211\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.042\n",
      "Episode: 46 Exploration P: 0.2918 Total reward: -1645.1127433971783 SOC: 0.5060 Cumulative_SOC_deviation: 160.8111 Fuel Consumption: 37.0020 Mean: 2.1203, STD: 5.0210\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.207\n",
      "Episode: 47 Exploration P: 0.2842 Total reward: -1737.845369798405 SOC: 0.5100 Cumulative_SOC_deviation: 170.0224 Fuel Consumption: 37.6211 Mean: 2.1200, STD: 5.0209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.765\n",
      "Episode: 48 Exploration P: 0.2768 Total reward: -1806.1094707402954 SOC: 0.4979 Cumulative_SOC_deviation: 176.9623 Fuel Consumption: 36.4861 Mean: 2.1197, STD: 5.0209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.518\n",
      "Episode: 49 Exploration P: 0.2696 Total reward: -1945.8189610013164 SOC: 0.4762 Cumulative_SOC_deviation: 191.0777 Fuel Consumption: 35.0416 Mean: 2.1194, STD: 5.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.982\n",
      "Episode: 50 Exploration P: 0.2625 Total reward: -1613.909153834936 SOC: 0.6386 Cumulative_SOC_deviation: 156.7042 Fuel Consumption: 46.8670 Mean: 2.1192, STD: 5.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.518\n",
      "Episode: 51 Exploration P: 0.2557 Total reward: -481.4478484292961 SOC: 0.6540 Cumulative_SOC_deviation: 43.4912 Fuel Consumption: 46.5355 Mean: 2.1189, STD: 5.0207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.305\n",
      "Episode: 52 Exploration P: 0.2490 Total reward: -487.4921882018182 SOC: 0.6467 Cumulative_SOC_deviation: 44.1348 Fuel Consumption: 46.1439 Mean: 2.1187, STD: 5.0207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.570\n",
      "Episode: 53 Exploration P: 0.2426 Total reward: -372.8819319256868 SOC: 0.6343 Cumulative_SOC_deviation: 32.7921 Fuel Consumption: 44.9612 Mean: 2.1185, STD: 5.0206\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.663\n",
      "Episode: 54 Exploration P: 0.2363 Total reward: -269.19071562452774 SOC: 0.6399 Cumulative_SOC_deviation: 22.3975 Fuel Consumption: 45.2158 Mean: 2.1183, STD: 5.0206\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.204\n",
      "Episode: 55 Exploration P: 0.2301 Total reward: -249.583363848936 SOC: 0.6316 Cumulative_SOC_deviation: 20.5313 Fuel Consumption: 44.2706 Mean: 2.1180, STD: 5.0205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.505\n",
      "Episode: 56 Exploration P: 0.2242 Total reward: -217.92088246084472 SOC: 0.6133 Cumulative_SOC_deviation: 17.4385 Fuel Consumption: 43.5359 Mean: 2.1178, STD: 5.0205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.907\n",
      "Episode: 57 Exploration P: 0.2184 Total reward: -278.83933121101484 SOC: 0.6408 Cumulative_SOC_deviation: 23.3497 Fuel Consumption: 45.3422 Mean: 2.1176, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.726\n",
      "Episode: 58 Exploration P: 0.2127 Total reward: -258.76830141912666 SOC: 0.6213 Cumulative_SOC_deviation: 21.4662 Fuel Consumption: 44.1062 Mean: 2.1175, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.463\n",
      "Episode: 59 Exploration P: 0.2072 Total reward: -273.99388085439386 SOC: 0.6350 Cumulative_SOC_deviation: 22.9471 Fuel Consumption: 44.5232 Mean: 2.1173, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.861\n",
      "Episode: 60 Exploration P: 0.2019 Total reward: -230.33818557882495 SOC: 0.6249 Cumulative_SOC_deviation: 18.6738 Fuel Consumption: 43.6007 Mean: 2.1171, STD: 5.0203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.908\n",
      "Episode: 61 Exploration P: 0.1967 Total reward: -222.51325180012205 SOC: 0.6163 Cumulative_SOC_deviation: 17.9091 Fuel Consumption: 43.4226 Mean: 2.1169, STD: 5.0203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.752\n",
      "Episode: 62 Exploration P: 0.1916 Total reward: -155.36176178926294 SOC: 0.6050 Cumulative_SOC_deviation: 11.2594 Fuel Consumption: 42.7679 Mean: 2.1168, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.781\n",
      "Episode: 63 Exploration P: 0.1867 Total reward: -214.62209528428468 SOC: 0.6346 Cumulative_SOC_deviation: 16.9839 Fuel Consumption: 44.7829 Mean: 2.1166, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.097\n",
      "Episode: 64 Exploration P: 0.1819 Total reward: -307.51156571082896 SOC: 0.6188 Cumulative_SOC_deviation: 26.4075 Fuel Consumption: 43.4367 Mean: 2.1164, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.685\n",
      "Episode: 65 Exploration P: 0.1773 Total reward: -226.28349577032412 SOC: 0.6124 Cumulative_SOC_deviation: 18.3357 Fuel Consumption: 42.9261 Mean: 2.1163, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.787\n",
      "Episode: 66 Exploration P: 0.1727 Total reward: -224.5732035319148 SOC: 0.6231 Cumulative_SOC_deviation: 18.1054 Fuel Consumption: 43.5192 Mean: 2.1162, STD: 5.0201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.755\n",
      "Episode: 67 Exploration P: 0.1683 Total reward: -237.32095575969956 SOC: 0.6181 Cumulative_SOC_deviation: 19.4174 Fuel Consumption: 43.1466 Mean: 2.1160, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.673\n",
      "Episode: 68 Exploration P: 0.1640 Total reward: -208.48683904373704 SOC: 0.6166 Cumulative_SOC_deviation: 16.5310 Fuel Consumption: 43.1771 Mean: 2.1159, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.163\n",
      "Episode: 69 Exploration P: 0.1599 Total reward: -186.41926794775847 SOC: 0.6157 Cumulative_SOC_deviation: 14.3675 Fuel Consumption: 42.7443 Mean: 2.1157, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.034\n",
      "Episode: 70 Exploration P: 0.1558 Total reward: -180.70905573035907 SOC: 0.6106 Cumulative_SOC_deviation: 13.8576 Fuel Consumption: 42.1332 Mean: 2.1156, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.630\n",
      "Episode: 71 Exploration P: 0.1519 Total reward: -214.67261926540516 SOC: 0.6183 Cumulative_SOC_deviation: 17.1509 Fuel Consumption: 43.1641 Mean: 2.1155, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.678\n",
      "Episode: 72 Exploration P: 0.1480 Total reward: -208.60986130502394 SOC: 0.6169 Cumulative_SOC_deviation: 16.5807 Fuel Consumption: 42.8031 Mean: 2.1154, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.793\n",
      "Episode: 73 Exploration P: 0.1443 Total reward: -235.15758146564622 SOC: 0.6219 Cumulative_SOC_deviation: 19.1493 Fuel Consumption: 43.6648 Mean: 2.1152, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.904\n",
      "Episode: 74 Exploration P: 0.1406 Total reward: -254.79392880263177 SOC: 0.6155 Cumulative_SOC_deviation: 21.1689 Fuel Consumption: 43.1047 Mean: 2.1151, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.071\n",
      "Episode: 75 Exploration P: 0.1371 Total reward: -220.6434983964459 SOC: 0.6185 Cumulative_SOC_deviation: 17.7900 Fuel Consumption: 42.7437 Mean: 2.1150, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.884\n",
      "Episode: 76 Exploration P: 0.1337 Total reward: -189.6070654832801 SOC: 0.6086 Cumulative_SOC_deviation: 14.6984 Fuel Consumption: 42.6234 Mean: 2.1149, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.738\n",
      "Episode: 77 Exploration P: 0.1303 Total reward: -182.75246626672845 SOC: 0.6182 Cumulative_SOC_deviation: 14.0315 Fuel Consumption: 42.4375 Mean: 2.1148, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.661\n",
      "Episode: 78 Exploration P: 0.1271 Total reward: -239.28724135741564 SOC: 0.6167 Cumulative_SOC_deviation: 19.6022 Fuel Consumption: 43.2656 Mean: 2.1147, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.479\n",
      "Episode: 79 Exploration P: 0.1239 Total reward: -197.7502826906816 SOC: 0.6238 Cumulative_SOC_deviation: 15.4441 Fuel Consumption: 43.3095 Mean: 2.1146, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.803\n",
      "Episode: 80 Exploration P: 0.1208 Total reward: -272.80111483587183 SOC: 0.6195 Cumulative_SOC_deviation: 22.8969 Fuel Consumption: 43.8320 Mean: 2.1145, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.963\n",
      "Episode: 81 Exploration P: 0.1178 Total reward: -271.312114064958 SOC: 0.6181 Cumulative_SOC_deviation: 22.7510 Fuel Consumption: 43.8022 Mean: 2.1144, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.223\n",
      "Episode: 82 Exploration P: 0.1149 Total reward: -181.69031491072832 SOC: 0.6107 Cumulative_SOC_deviation: 13.9615 Fuel Consumption: 42.0757 Mean: 2.1143, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.773\n",
      "Episode: 83 Exploration P: 0.1120 Total reward: -167.1547135043741 SOC: 0.6118 Cumulative_SOC_deviation: 12.4916 Fuel Consumption: 42.2386 Mean: 2.1142, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.755\n",
      "Episode: 84 Exploration P: 0.1093 Total reward: -233.8417851324051 SOC: 0.6138 Cumulative_SOC_deviation: 19.0529 Fuel Consumption: 43.3124 Mean: 2.1141, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.046\n",
      "Episode: 85 Exploration P: 0.1066 Total reward: -266.2560848662936 SOC: 0.6184 Cumulative_SOC_deviation: 22.2409 Fuel Consumption: 43.8468 Mean: 2.1140, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.079\n",
      "Episode: 86 Exploration P: 0.1040 Total reward: -271.50566352414546 SOC: 0.6137 Cumulative_SOC_deviation: 22.7928 Fuel Consumption: 43.5772 Mean: 2.1140, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.863\n",
      "Episode: 87 Exploration P: 0.1014 Total reward: -207.53392278295829 SOC: 0.6125 Cumulative_SOC_deviation: 16.4726 Fuel Consumption: 42.8077 Mean: 2.1139, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.995\n",
      "Episode: 88 Exploration P: 0.0989 Total reward: -238.6940682688716 SOC: 0.6136 Cumulative_SOC_deviation: 19.5636 Fuel Consumption: 43.0584 Mean: 2.1138, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.870\n",
      "Episode: 89 Exploration P: 0.0965 Total reward: -174.61373063336757 SOC: 0.6084 Cumulative_SOC_deviation: 13.2303 Fuel Consumption: 42.3103 Mean: 2.1137, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.792\n",
      "Episode: 90 Exploration P: 0.0942 Total reward: -167.15774490699332 SOC: 0.6114 Cumulative_SOC_deviation: 12.5013 Fuel Consumption: 42.1443 Mean: 2.1136, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.078\n",
      "Episode: 91 Exploration P: 0.0919 Total reward: -170.216906029212 SOC: 0.6116 Cumulative_SOC_deviation: 12.7836 Fuel Consumption: 42.3811 Mean: 2.1136, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.557\n",
      "Episode: 92 Exploration P: 0.0897 Total reward: -180.6107761720639 SOC: 0.6101 Cumulative_SOC_deviation: 13.8214 Fuel Consumption: 42.3970 Mean: 2.1135, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.349\n",
      "Episode: 93 Exploration P: 0.0875 Total reward: -162.98415379601096 SOC: 0.6103 Cumulative_SOC_deviation: 12.0805 Fuel Consumption: 42.1788 Mean: 2.1134, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.169\n",
      "Episode: 94 Exploration P: 0.0854 Total reward: -151.75741840512183 SOC: 0.6075 Cumulative_SOC_deviation: 10.9963 Fuel Consumption: 41.7944 Mean: 2.1133, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.335\n",
      "Episode: 95 Exploration P: 0.0834 Total reward: -168.36610225726065 SOC: 0.6124 Cumulative_SOC_deviation: 12.6379 Fuel Consumption: 41.9866 Mean: 2.1133, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.908\n",
      "Episode: 96 Exploration P: 0.0814 Total reward: -195.33843255869817 SOC: 0.6155 Cumulative_SOC_deviation: 15.2653 Fuel Consumption: 42.6854 Mean: 2.1132, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.055\n",
      "Episode: 97 Exploration P: 0.0795 Total reward: -192.32844968088054 SOC: 0.6138 Cumulative_SOC_deviation: 14.9775 Fuel Consumption: 42.5533 Mean: 2.1131, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.037\n",
      "Episode: 98 Exploration P: 0.0776 Total reward: -212.4314308545458 SOC: 0.6153 Cumulative_SOC_deviation: 16.9655 Fuel Consumption: 42.7767 Mean: 2.1131, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.869\n",
      "Episode: 99 Exploration P: 0.0758 Total reward: -181.0478685254877 SOC: 0.6120 Cumulative_SOC_deviation: 13.8787 Fuel Consumption: 42.2612 Mean: 2.1130, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.928\n",
      "Episode: 100 Exploration P: 0.0740 Total reward: -179.75037820267548 SOC: 0.6080 Cumulative_SOC_deviation: 13.7512 Fuel Consumption: 42.2385 Mean: 2.1130, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.309\n",
      "Episode: 101 Exploration P: 0.0722 Total reward: -189.0014091451772 SOC: 0.6128 Cumulative_SOC_deviation: 14.6529 Fuel Consumption: 42.4727 Mean: 2.1129, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.030\n",
      "Episode: 102 Exploration P: 0.0706 Total reward: -175.46535176175192 SOC: 0.6119 Cumulative_SOC_deviation: 13.3155 Fuel Consumption: 42.3099 Mean: 2.1128, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.164\n",
      "Episode: 103 Exploration P: 0.0689 Total reward: -134.92239676906638 SOC: 0.6091 Cumulative_SOC_deviation: 9.3362 Fuel Consumption: 41.5605 Mean: 2.1128, STD: 5.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.536\n",
      "Episode: 104 Exploration P: 0.0673 Total reward: -95.87933726131693 SOC: 0.6058 Cumulative_SOC_deviation: 5.4737 Fuel Consumption: 41.1420 Mean: 2.1127, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.999\n",
      "Episode: 105 Exploration P: 0.0658 Total reward: -140.44545734571477 SOC: 0.6057 Cumulative_SOC_deviation: 9.8968 Fuel Consumption: 41.4775 Mean: 2.1127, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.688\n",
      "Episode: 106 Exploration P: 0.0643 Total reward: -99.49906895464069 SOC: 0.6087 Cumulative_SOC_deviation: 5.8186 Fuel Consumption: 41.3128 Mean: 2.1126, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.808\n",
      "Episode: 107 Exploration P: 0.0628 Total reward: -121.80946209591683 SOC: 0.6113 Cumulative_SOC_deviation: 8.0367 Fuel Consumption: 41.4423 Mean: 2.1125, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.362\n",
      "Episode: 108 Exploration P: 0.0614 Total reward: -108.4912823029547 SOC: 0.6045 Cumulative_SOC_deviation: 6.7608 Fuel Consumption: 40.8830 Mean: 2.1125, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.965\n",
      "Episode: 109 Exploration P: 0.0600 Total reward: -81.14613939880401 SOC: 0.6065 Cumulative_SOC_deviation: 3.9945 Fuel Consumption: 41.2014 Mean: 2.1124, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.933\n",
      "Episode: 110 Exploration P: 0.0586 Total reward: -101.19215525695273 SOC: 0.6027 Cumulative_SOC_deviation: 6.0439 Fuel Consumption: 40.7528 Mean: 2.1124, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.200\n",
      "Episode: 111 Exploration P: 0.0573 Total reward: -106.88792756406227 SOC: 0.6088 Cumulative_SOC_deviation: 6.5712 Fuel Consumption: 41.1758 Mean: 2.1123, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.872\n",
      "Episode: 112 Exploration P: 0.0560 Total reward: -112.3924928940625 SOC: 0.6063 Cumulative_SOC_deviation: 7.1070 Fuel Consumption: 41.3223 Mean: 2.1123, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.875\n",
      "Episode: 113 Exploration P: 0.0548 Total reward: -92.46399062389207 SOC: 0.6021 Cumulative_SOC_deviation: 5.1585 Fuel Consumption: 40.8790 Mean: 2.1122, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.847\n",
      "Episode: 114 Exploration P: 0.0536 Total reward: -88.98250549110598 SOC: 0.6056 Cumulative_SOC_deviation: 4.7845 Fuel Consumption: 41.1380 Mean: 2.1122, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.654\n",
      "Episode: 115 Exploration P: 0.0524 Total reward: -96.99763265831554 SOC: 0.6089 Cumulative_SOC_deviation: 5.5376 Fuel Consumption: 41.6220 Mean: 2.1121, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.727\n",
      "Episode: 116 Exploration P: 0.0512 Total reward: -95.45758822804032 SOC: 0.6049 Cumulative_SOC_deviation: 5.4124 Fuel Consumption: 41.3332 Mean: 2.1121, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.586\n",
      "Episode: 117 Exploration P: 0.0501 Total reward: -90.49666092513002 SOC: 0.5998 Cumulative_SOC_deviation: 4.9442 Fuel Consumption: 41.0545 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.774\n",
      "Episode: 118 Exploration P: 0.0490 Total reward: -110.74187377320294 SOC: 0.6024 Cumulative_SOC_deviation: 6.9177 Fuel Consumption: 41.5651 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.072\n",
      "Episode: 119 Exploration P: 0.0480 Total reward: -106.6341276313411 SOC: 0.6031 Cumulative_SOC_deviation: 6.5048 Fuel Consumption: 41.5865 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.986\n",
      "Episode: 120 Exploration P: 0.0469 Total reward: -89.32668325410339 SOC: 0.6010 Cumulative_SOC_deviation: 4.8423 Fuel Consumption: 40.9035 Mean: 2.1119, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.039\n",
      "Episode: 121 Exploration P: 0.0459 Total reward: -90.58864534006223 SOC: 0.6013 Cumulative_SOC_deviation: 4.9577 Fuel Consumption: 41.0117 Mean: 2.1119, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.051\n",
      "Episode: 122 Exploration P: 0.0450 Total reward: -96.94743766683474 SOC: 0.6017 Cumulative_SOC_deviation: 5.5936 Fuel Consumption: 41.0111 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.087\n",
      "Episode: 123 Exploration P: 0.0440 Total reward: -84.32095576962865 SOC: 0.6042 Cumulative_SOC_deviation: 4.3432 Fuel Consumption: 40.8885 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.067\n",
      "Episode: 124 Exploration P: 0.0431 Total reward: -88.45816866830793 SOC: 0.6059 Cumulative_SOC_deviation: 4.7400 Fuel Consumption: 41.0578 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.554\n",
      "Episode: 125 Exploration P: 0.0422 Total reward: -114.09814766641645 SOC: 0.6078 Cumulative_SOC_deviation: 7.3115 Fuel Consumption: 40.9834 Mean: 2.1117, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.869\n",
      "Episode: 126 Exploration P: 0.0413 Total reward: -82.55246967678713 SOC: 0.6041 Cumulative_SOC_deviation: 4.2007 Fuel Consumption: 40.5450 Mean: 2.1117, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.813\n",
      "Episode: 127 Exploration P: 0.0405 Total reward: -95.04023550247143 SOC: 0.6061 Cumulative_SOC_deviation: 5.4234 Fuel Consumption: 40.8062 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.391\n",
      "Episode: 128 Exploration P: 0.0397 Total reward: -84.69309574023791 SOC: 0.6030 Cumulative_SOC_deviation: 4.4128 Fuel Consumption: 40.5651 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.810\n",
      "Episode: 129 Exploration P: 0.0389 Total reward: -122.55415607536995 SOC: 0.6003 Cumulative_SOC_deviation: 8.1878 Fuel Consumption: 40.6766 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.358\n",
      "Episode: 130 Exploration P: 0.0381 Total reward: -115.93330161973822 SOC: 0.5994 Cumulative_SOC_deviation: 7.5126 Fuel Consumption: 40.8071 Mean: 2.1115, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.741\n",
      "Episode: 131 Exploration P: 0.0373 Total reward: -126.29040842587953 SOC: 0.6003 Cumulative_SOC_deviation: 8.5173 Fuel Consumption: 41.1172 Mean: 2.1115, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.218\n",
      "Episode: 132 Exploration P: 0.0366 Total reward: -125.98764368773368 SOC: 0.6008 Cumulative_SOC_deviation: 8.4942 Fuel Consumption: 41.0459 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.760\n",
      "Episode: 133 Exploration P: 0.0359 Total reward: -103.31786354287686 SOC: 0.6012 Cumulative_SOC_deviation: 6.2471 Fuel Consumption: 40.8467 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.975\n",
      "Episode: 134 Exploration P: 0.0352 Total reward: -108.73717546291505 SOC: 0.6068 Cumulative_SOC_deviation: 6.7526 Fuel Consumption: 41.2107 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.963\n",
      "Episode: 135 Exploration P: 0.0345 Total reward: -87.74300869820064 SOC: 0.6044 Cumulative_SOC_deviation: 4.7242 Fuel Consumption: 40.5013 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.940\n",
      "Episode: 136 Exploration P: 0.0338 Total reward: -108.12945803482665 SOC: 0.6068 Cumulative_SOC_deviation: 6.7422 Fuel Consumption: 40.7073 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.742\n",
      "Episode: 137 Exploration P: 0.0332 Total reward: -94.65602452844367 SOC: 0.6085 Cumulative_SOC_deviation: 5.3728 Fuel Consumption: 40.9281 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.678\n",
      "Episode: 138 Exploration P: 0.0325 Total reward: -104.4651588818636 SOC: 0.6055 Cumulative_SOC_deviation: 6.3848 Fuel Consumption: 40.6169 Mean: 2.1112, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.824\n",
      "Episode: 139 Exploration P: 0.0319 Total reward: -90.60326261468728 SOC: 0.6028 Cumulative_SOC_deviation: 5.0042 Fuel Consumption: 40.5612 Mean: 2.1112, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.710\n",
      "Episode: 140 Exploration P: 0.0313 Total reward: -101.72938276398797 SOC: 0.6001 Cumulative_SOC_deviation: 6.1081 Fuel Consumption: 40.6482 Mean: 2.1112, STD: 5.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.790\n",
      "Episode: 141 Exploration P: 0.0308 Total reward: -116.02177650295137 SOC: 0.6019 Cumulative_SOC_deviation: 7.5037 Fuel Consumption: 40.9846 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.970\n",
      "Episode: 142 Exploration P: 0.0302 Total reward: -102.37317876835682 SOC: 0.6010 Cumulative_SOC_deviation: 6.1281 Fuel Consumption: 41.0926 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.920\n",
      "Episode: 143 Exploration P: 0.0296 Total reward: -129.4198127784279 SOC: 0.6008 Cumulative_SOC_deviation: 8.8244 Fuel Consumption: 41.1761 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.491\n",
      "Episode: 144 Exploration P: 0.0291 Total reward: -103.7946574058235 SOC: 0.6014 Cumulative_SOC_deviation: 6.2849 Fuel Consumption: 40.9453 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.714\n",
      "Episode: 145 Exploration P: 0.0286 Total reward: -136.4707658276297 SOC: 0.6027 Cumulative_SOC_deviation: 9.5159 Fuel Consumption: 41.3114 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.056\n",
      "Episode: 146 Exploration P: 0.0281 Total reward: -118.7151340820801 SOC: 0.6044 Cumulative_SOC_deviation: 7.7281 Fuel Consumption: 41.4340 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.669\n",
      "Episode: 147 Exploration P: 0.0276 Total reward: -102.26216605576825 SOC: 0.6047 Cumulative_SOC_deviation: 6.0857 Fuel Consumption: 41.4049 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.556\n",
      "Episode: 148 Exploration P: 0.0271 Total reward: -104.35318968987991 SOC: 0.6055 Cumulative_SOC_deviation: 6.3424 Fuel Consumption: 40.9289 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.093\n",
      "Episode: 149 Exploration P: 0.0267 Total reward: -96.41249265985418 SOC: 0.5974 Cumulative_SOC_deviation: 5.6038 Fuel Consumption: 40.3749 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.885\n",
      "Episode: 150 Exploration P: 0.0262 Total reward: -139.19585158802104 SOC: 0.5993 Cumulative_SOC_deviation: 9.8090 Fuel Consumption: 41.1060 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.049\n",
      "Episode: 151 Exploration P: 0.0258 Total reward: -111.37982162564809 SOC: 0.6012 Cumulative_SOC_deviation: 7.0258 Fuel Consumption: 41.1217 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.150\n",
      "Episode: 152 Exploration P: 0.0253 Total reward: -107.26155668370657 SOC: 0.6000 Cumulative_SOC_deviation: 6.6009 Fuel Consumption: 41.2525 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.716\n",
      "Episode: 153 Exploration P: 0.0249 Total reward: -120.76966551601616 SOC: 0.6016 Cumulative_SOC_deviation: 7.9522 Fuel Consumption: 41.2477 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.871\n",
      "Episode: 154 Exploration P: 0.0245 Total reward: -119.0132149766436 SOC: 0.6030 Cumulative_SOC_deviation: 7.7620 Fuel Consumption: 41.3930 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.889\n",
      "Episode: 155 Exploration P: 0.0241 Total reward: -116.06866186448424 SOC: 0.6017 Cumulative_SOC_deviation: 7.4966 Fuel Consumption: 41.1026 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.461\n",
      "Episode: 156 Exploration P: 0.0237 Total reward: -108.0374908656673 SOC: 0.6004 Cumulative_SOC_deviation: 6.7111 Fuel Consumption: 40.9269 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.277\n",
      "Episode: 157 Exploration P: 0.0234 Total reward: -134.99662876882124 SOC: 0.6001 Cumulative_SOC_deviation: 9.4056 Fuel Consumption: 40.9403 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.965\n",
      "Episode: 158 Exploration P: 0.0230 Total reward: -144.05388031237067 SOC: 0.6007 Cumulative_SOC_deviation: 10.2713 Fuel Consumption: 41.3412 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.255\n",
      "Episode: 159 Exploration P: 0.0227 Total reward: -161.41216604388993 SOC: 0.5995 Cumulative_SOC_deviation: 11.9895 Fuel Consumption: 41.5175 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.953\n",
      "Episode: 160 Exploration P: 0.0223 Total reward: -147.89978382620384 SOC: 0.6003 Cumulative_SOC_deviation: 10.6294 Fuel Consumption: 41.6063 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.322\n",
      "Episode: 161 Exploration P: 0.0220 Total reward: -148.13176939951413 SOC: 0.5995 Cumulative_SOC_deviation: 10.6503 Fuel Consumption: 41.6284 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.473\n",
      "Episode: 162 Exploration P: 0.0217 Total reward: -129.64349280238162 SOC: 0.5990 Cumulative_SOC_deviation: 8.8336 Fuel Consumption: 41.3076 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.325\n",
      "Episode: 163 Exploration P: 0.0213 Total reward: -132.74268850777213 SOC: 0.5990 Cumulative_SOC_deviation: 9.1496 Fuel Consumption: 41.2472 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.453\n",
      "Episode: 164 Exploration P: 0.0210 Total reward: -137.8027786784787 SOC: 0.6015 Cumulative_SOC_deviation: 9.6118 Fuel Consumption: 41.6846 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.794\n",
      "Episode: 165 Exploration P: 0.0207 Total reward: -133.52491015535705 SOC: 0.6006 Cumulative_SOC_deviation: 9.1741 Fuel Consumption: 41.7837 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.883\n",
      "Episode: 166 Exploration P: 0.0204 Total reward: -145.87479176171206 SOC: 0.6009 Cumulative_SOC_deviation: 10.4055 Fuel Consumption: 41.8201 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.306\n",
      "Episode: 167 Exploration P: 0.0202 Total reward: -151.39553608543616 SOC: 0.5989 Cumulative_SOC_deviation: 10.9409 Fuel Consumption: 41.9866 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.761\n",
      "Episode: 168 Exploration P: 0.0199 Total reward: -152.94857768568548 SOC: 0.5978 Cumulative_SOC_deviation: 11.1255 Fuel Consumption: 41.6934 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.721\n",
      "Episode: 169 Exploration P: 0.0196 Total reward: -155.0850895128231 SOC: 0.5983 Cumulative_SOC_deviation: 11.3731 Fuel Consumption: 41.3538 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.659\n",
      "Episode: 170 Exploration P: 0.0194 Total reward: -141.50571693232837 SOC: 0.5998 Cumulative_SOC_deviation: 10.0185 Fuel Consumption: 41.3211 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.711\n",
      "Episode: 171 Exploration P: 0.0191 Total reward: -141.4410505502914 SOC: 0.6000 Cumulative_SOC_deviation: 10.0138 Fuel Consumption: 41.3034 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.886\n",
      "Episode: 172 Exploration P: 0.0189 Total reward: -154.2172313296923 SOC: 0.6008 Cumulative_SOC_deviation: 11.2846 Fuel Consumption: 41.3716 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.809\n",
      "Episode: 173 Exploration P: 0.0186 Total reward: -138.42661563393807 SOC: 0.5991 Cumulative_SOC_deviation: 9.7338 Fuel Consumption: 41.0891 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.780\n",
      "Episode: 174 Exploration P: 0.0184 Total reward: -127.25586585491511 SOC: 0.5986 Cumulative_SOC_deviation: 8.6320 Fuel Consumption: 40.9362 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.890\n",
      "Episode: 175 Exploration P: 0.0182 Total reward: -130.82057300032812 SOC: 0.5980 Cumulative_SOC_deviation: 8.9834 Fuel Consumption: 40.9864 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.661\n",
      "Episode: 176 Exploration P: 0.0179 Total reward: -145.10579891033214 SOC: 0.5995 Cumulative_SOC_deviation: 10.3894 Fuel Consumption: 41.2119 Mean: 2.1103, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.762\n",
      "Episode: 177 Exploration P: 0.0177 Total reward: -128.42649102192578 SOC: 0.6006 Cumulative_SOC_deviation: 8.7351 Fuel Consumption: 41.0756 Mean: 2.1103, STD: 5.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.775\n",
      "Episode: 178 Exploration P: 0.0175 Total reward: -113.49561366807112 SOC: 0.6000 Cumulative_SOC_deviation: 7.2881 Fuel Consumption: 40.6147 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.039\n",
      "Episode: 179 Exploration P: 0.0173 Total reward: -106.59652176686184 SOC: 0.6012 Cumulative_SOC_deviation: 6.5839 Fuel Consumption: 40.7574 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.117\n",
      "Episode: 180 Exploration P: 0.0171 Total reward: -98.1438006089424 SOC: 0.6015 Cumulative_SOC_deviation: 5.7558 Fuel Consumption: 40.5859 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.658\n",
      "Episode: 181 Exploration P: 0.0169 Total reward: -135.0351732772012 SOC: 0.5985 Cumulative_SOC_deviation: 9.4596 Fuel Consumption: 40.4394 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.828\n",
      "Episode: 182 Exploration P: 0.0167 Total reward: -145.47685825423707 SOC: 0.6031 Cumulative_SOC_deviation: 10.4781 Fuel Consumption: 40.6954 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.516\n",
      "Episode: 183 Exploration P: 0.0165 Total reward: -103.39092802767108 SOC: 0.6049 Cumulative_SOC_deviation: 6.2544 Fuel Consumption: 40.8471 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.555\n",
      "Episode: 184 Exploration P: 0.0164 Total reward: -93.9704353593405 SOC: 0.6065 Cumulative_SOC_deviation: 5.2669 Fuel Consumption: 41.3010 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 76.407\n",
      "Episode: 185 Exploration P: 0.0162 Total reward: -121.36736864878273 SOC: 0.6056 Cumulative_SOC_deviation: 8.0049 Fuel Consumption: 41.3186 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.699\n",
      "Episode: 186 Exploration P: 0.0160 Total reward: -140.4696432912347 SOC: 0.6073 Cumulative_SOC_deviation: 9.9179 Fuel Consumption: 41.2905 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.542\n",
      "Episode: 187 Exploration P: 0.0159 Total reward: -140.95225471770576 SOC: 0.5984 Cumulative_SOC_deviation: 10.0440 Fuel Consumption: 40.5124 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.646\n",
      "Episode: 188 Exploration P: 0.0157 Total reward: -168.9518422832053 SOC: 0.5991 Cumulative_SOC_deviation: 12.7918 Fuel Consumption: 41.0338 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.557\n",
      "Episode: 189 Exploration P: 0.0156 Total reward: -153.93266423101062 SOC: 0.6007 Cumulative_SOC_deviation: 11.3275 Fuel Consumption: 40.6576 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.440\n",
      "Episode: 190 Exploration P: 0.0154 Total reward: -123.12474048809908 SOC: 0.6025 Cumulative_SOC_deviation: 8.2443 Fuel Consumption: 40.6813 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.554\n",
      "Episode: 191 Exploration P: 0.0153 Total reward: -94.91767359100159 SOC: 0.6009 Cumulative_SOC_deviation: 5.4537 Fuel Consumption: 40.3805 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.900\n",
      "Episode: 192 Exploration P: 0.0151 Total reward: -131.2851302654058 SOC: 0.6044 Cumulative_SOC_deviation: 9.0452 Fuel Consumption: 40.8328 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.314\n",
      "Episode: 193 Exploration P: 0.0150 Total reward: -124.57358678449556 SOC: 0.6036 Cumulative_SOC_deviation: 8.3747 Fuel Consumption: 40.8267 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.629\n",
      "Episode: 194 Exploration P: 0.0148 Total reward: -106.60512164179634 SOC: 0.5981 Cumulative_SOC_deviation: 6.6222 Fuel Consumption: 40.3833 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.384\n",
      "Episode: 195 Exploration P: 0.0147 Total reward: -182.9874325670853 SOC: 0.6009 Cumulative_SOC_deviation: 14.1926 Fuel Consumption: 41.0618 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.706\n",
      "Episode: 196 Exploration P: 0.0146 Total reward: -141.97432620775893 SOC: 0.6027 Cumulative_SOC_deviation: 10.1149 Fuel Consumption: 40.8249 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.660\n",
      "Episode: 197 Exploration P: 0.0145 Total reward: -128.4463091507103 SOC: 0.6062 Cumulative_SOC_deviation: 8.7624 Fuel Consumption: 40.8221 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.563\n",
      "Episode: 198 Exploration P: 0.0143 Total reward: -90.11800517252823 SOC: 0.6065 Cumulative_SOC_deviation: 4.9497 Fuel Consumption: 40.6213 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.405\n",
      "Episode: 199 Exploration P: 0.0142 Total reward: -115.46043771223569 SOC: 0.6067 Cumulative_SOC_deviation: 7.4644 Fuel Consumption: 40.8165 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.468\n",
      "Episode: 200 Exploration P: 0.0141 Total reward: -138.24445158436419 SOC: 0.6081 Cumulative_SOC_deviation: 9.6484 Fuel Consumption: 41.7603 Mean: 2.1099, STD: 5.0188\n",
      "Available condition is not avail... SOC: 0.9993676704711516\n",
      "elapsed_time: 21.314\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3211.862254472645 SOC: 0.9994 Cumulative_SOC_deviation: 313.4950 Fuel Consumption: 76.9120 Mean: 2.2368, STD: 5.0389\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 21.216\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3253.2991630710085 SOC: 1.0000 Cumulative_SOC_deviation: 317.7037 Fuel Consumption: 76.2620 Mean: 2.2368, STD: 5.0426\n",
      "WARNING:tensorflow:Layer dense_45 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_49 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_40 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer dense_41 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_36 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Available condition is not avail... SOC: 1\n",
      "elapsed_time: 54.341\n",
      "Episode: 3 Exploration P: 0.9255 Total reward: -2988.800193728721 SOC: 1.0000 Cumulative_SOC_deviation: 291.6201 Fuel Consumption: 72.5990 Mean: 2.2368, STD: 5.0441\n",
      "Available condition is not avail... SOC: 0.998215173719458\n",
      "elapsed_time: 68.685\n",
      "Episode: 4 Exploration P: 0.9019 Total reward: -2859.8869908494526 SOC: 0.9982 Cumulative_SOC_deviation: 278.8206 Fuel Consumption: 71.6807 Mean: 2.2368, STD: 5.0449\n",
      "Available condition is not avail... SOC: 0.9985754558547004\n",
      "elapsed_time: 69.201\n",
      "Episode: 5 Exploration P: 0.8789 Total reward: -2910.112837288288 SOC: 0.9986 Cumulative_SOC_deviation: 283.8473 Fuel Consumption: 71.6394 Mean: 2.2368, STD: 5.0454\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.302\n",
      "Episode: 6 Exploration P: 0.8554 Total reward: -2894.369132772552 SOC: 0.9928 Cumulative_SOC_deviation: 282.2874 Fuel Consumption: 71.4955 Mean: 2.2142, STD: 5.0408\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.496\n",
      "Episode: 7 Exploration P: 0.8325 Total reward: -2811.4654100979096 SOC: 0.9961 Cumulative_SOC_deviation: 273.9650 Fuel Consumption: 71.8154 Mean: 2.1983, STD: 5.0376\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.781\n",
      "Episode: 8 Exploration P: 0.8102 Total reward: -2802.7021915621654 SOC: 0.9830 Cumulative_SOC_deviation: 273.1774 Fuel Consumption: 70.9280 Mean: 2.1865, STD: 5.0351\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.131\n",
      "Episode: 9 Exploration P: 0.7885 Total reward: -2579.4036394125924 SOC: 0.9623 Cumulative_SOC_deviation: 251.0065 Fuel Consumption: 69.3390 Mean: 2.1773, STD: 5.0332\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.236\n",
      "Episode: 10 Exploration P: 0.7674 Total reward: -2474.1512555958006 SOC: 0.9551 Cumulative_SOC_deviation: 240.5194 Fuel Consumption: 68.9573 Mean: 2.1701, STD: 5.0317\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.460\n",
      "Episode: 11 Exploration P: 0.7469 Total reward: -2204.937618464652 SOC: 0.9325 Cumulative_SOC_deviation: 213.7848 Fuel Consumption: 67.0897 Mean: 2.1642, STD: 5.0305\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.986\n",
      "Episode: 12 Exploration P: 0.7269 Total reward: -2130.9407822457097 SOC: 0.9281 Cumulative_SOC_deviation: 206.3913 Fuel Consumption: 67.0278 Mean: 2.1593, STD: 5.0294\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.275\n",
      "Episode: 13 Exploration P: 0.7075 Total reward: -2066.3877788212576 SOC: 0.9153 Cumulative_SOC_deviation: 200.0361 Fuel Consumption: 66.0269 Mean: 2.1552, STD: 5.0285\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.366\n",
      "Episode: 14 Exploration P: 0.6886 Total reward: -1712.5703530434864 SOC: 0.8962 Cumulative_SOC_deviation: 164.7823 Fuel Consumption: 64.7475 Mean: 2.1517, STD: 5.0278\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.731\n",
      "Episode: 15 Exploration P: 0.6703 Total reward: -1866.2896911324317 SOC: 0.8912 Cumulative_SOC_deviation: 180.2182 Fuel Consumption: 64.1078 Mean: 2.1486, STD: 5.0271\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.859\n",
      "Episode: 16 Exploration P: 0.6524 Total reward: -1378.9782715319138 SOC: 0.8625 Cumulative_SOC_deviation: 131.6490 Fuel Consumption: 62.4878 Mean: 2.1460, STD: 5.0266\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.195\n",
      "Episode: 17 Exploration P: 0.6350 Total reward: -1703.6445304636939 SOC: 0.8814 Cumulative_SOC_deviation: 164.0001 Fuel Consumption: 63.6434 Mean: 2.1436, STD: 5.0261\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.598\n",
      "Episode: 18 Exploration P: 0.6180 Total reward: -1446.480506147461 SOC: 0.8503 Cumulative_SOC_deviation: 138.5148 Fuel Consumption: 61.3322 Mean: 2.1416, STD: 5.0256\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.008\n",
      "Episode: 19 Exploration P: 0.6016 Total reward: -1277.20778030198 SOC: 0.8263 Cumulative_SOC_deviation: 121.7372 Fuel Consumption: 59.8360 Mean: 2.1397, STD: 5.0252\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.252\n",
      "Episode: 20 Exploration P: 0.5855 Total reward: -1478.310257522655 SOC: 0.8459 Cumulative_SOC_deviation: 141.7153 Fuel Consumption: 61.1568 Mean: 2.1380, STD: 5.0249\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.658\n",
      "Episode: 21 Exploration P: 0.5700 Total reward: -973.5281529089276 SOC: 0.7892 Cumulative_SOC_deviation: 91.6550 Fuel Consumption: 56.9779 Mean: 2.1365, STD: 5.0245\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.941\n",
      "Episode: 22 Exploration P: 0.5548 Total reward: -1160.9650919515457 SOC: 0.8044 Cumulative_SOC_deviation: 110.3007 Fuel Consumption: 57.9581 Mean: 2.1352, STD: 5.0242\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.878\n",
      "Episode: 23 Exploration P: 0.5400 Total reward: -933.4778562813931 SOC: 0.7718 Cumulative_SOC_deviation: 87.7852 Fuel Consumption: 55.6262 Mean: 2.1339, STD: 5.0240\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.076\n",
      "Episode: 24 Exploration P: 0.5257 Total reward: -737.6114091594239 SOC: 0.7497 Cumulative_SOC_deviation: 68.3399 Fuel Consumption: 54.2127 Mean: 2.1328, STD: 5.0237\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.134\n",
      "Episode: 25 Exploration P: 0.5117 Total reward: -961.2283768201249 SOC: 0.7615 Cumulative_SOC_deviation: 90.6283 Fuel Consumption: 54.9452 Mean: 2.1317, STD: 5.0235\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.013\n",
      "Episode: 26 Exploration P: 0.4981 Total reward: -732.4759293027842 SOC: 0.7327 Cumulative_SOC_deviation: 67.9883 Fuel Consumption: 52.5927 Mean: 2.1307, STD: 5.0233\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.912\n",
      "Episode: 27 Exploration P: 0.4849 Total reward: -585.4633482923595 SOC: 0.7001 Cumulative_SOC_deviation: 53.4934 Fuel Consumption: 50.5291 Mean: 2.1299, STD: 5.0231\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.036\n",
      "Episode: 28 Exploration P: 0.4720 Total reward: -548.404549858243 SOC: 0.6899 Cumulative_SOC_deviation: 49.8587 Fuel Consumption: 49.8171 Mean: 2.1290, STD: 5.0229\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.616\n",
      "Episode: 29 Exploration P: 0.4595 Total reward: -563.5776310150649 SOC: 0.7052 Cumulative_SOC_deviation: 51.2894 Fuel Consumption: 50.6839 Mean: 2.1282, STD: 5.0227\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.715\n",
      "Episode: 30 Exploration P: 0.4473 Total reward: -557.9687019093843 SOC: 0.6603 Cumulative_SOC_deviation: 51.0256 Fuel Consumption: 47.7122 Mean: 2.1275, STD: 5.0226\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.306\n",
      "Episode: 31 Exploration P: 0.4355 Total reward: -632.9347635259056 SOC: 0.6874 Cumulative_SOC_deviation: 58.3076 Fuel Consumption: 49.8584 Mean: 2.1268, STD: 5.0224\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.576\n",
      "Episode: 32 Exploration P: 0.4240 Total reward: -501.5733136833057 SOC: 0.6643 Cumulative_SOC_deviation: 45.3459 Fuel Consumption: 48.1146 Mean: 2.1262, STD: 5.0223\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.692\n",
      "Episode: 33 Exploration P: 0.4128 Total reward: -524.0854217229027 SOC: 0.6374 Cumulative_SOC_deviation: 47.7931 Fuel Consumption: 46.1542 Mean: 2.1256, STD: 5.0222\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.899\n",
      "Episode: 34 Exploration P: 0.4019 Total reward: -558.3083332038697 SOC: 0.6550 Cumulative_SOC_deviation: 51.0823 Fuel Consumption: 47.4852 Mean: 2.1251, STD: 5.0220\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.036\n",
      "Episode: 35 Exploration P: 0.3912 Total reward: -682.3561186999943 SOC: 0.6207 Cumulative_SOC_deviation: 63.7347 Fuel Consumption: 45.0089 Mean: 2.1245, STD: 5.0219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.718\n",
      "Episode: 36 Exploration P: 0.3809 Total reward: -821.6120726819954 SOC: 0.6112 Cumulative_SOC_deviation: 77.7191 Fuel Consumption: 44.4207 Mean: 2.1240, STD: 5.0218\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.283\n",
      "Episode: 37 Exploration P: 0.3709 Total reward: -837.1105369728457 SOC: 0.6229 Cumulative_SOC_deviation: 79.1617 Fuel Consumption: 45.4938 Mean: 2.1236, STD: 5.0217\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.579\n",
      "Episode: 38 Exploration P: 0.3611 Total reward: -1044.2880935153687 SOC: 0.5595 Cumulative_SOC_deviation: 100.3644 Fuel Consumption: 40.6443 Mean: 2.1231, STD: 5.0216\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.158\n",
      "Episode: 39 Exploration P: 0.3516 Total reward: -951.6332122037911 SOC: 0.5863 Cumulative_SOC_deviation: 90.8956 Fuel Consumption: 42.6770 Mean: 2.1227, STD: 5.0215\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 72.965\n",
      "Episode: 40 Exploration P: 0.3423 Total reward: -1215.1291741849448 SOC: 0.5666 Cumulative_SOC_deviation: 117.3670 Fuel Consumption: 41.4594 Mean: 2.1223, STD: 5.0214\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.318\n",
      "Episode: 41 Exploration P: 0.3333 Total reward: -1349.9957895835207 SOC: 0.5548 Cumulative_SOC_deviation: 130.9424 Fuel Consumption: 40.5721 Mean: 2.1219, STD: 5.0214\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.223\n",
      "Episode: 42 Exploration P: 0.3246 Total reward: -1236.3432639062762 SOC: 0.5543 Cumulative_SOC_deviation: 119.5833 Fuel Consumption: 40.5102 Mean: 2.1216, STD: 5.0213\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.397\n",
      "Episode: 43 Exploration P: 0.3160 Total reward: -1302.8262904256023 SOC: 0.5474 Cumulative_SOC_deviation: 126.2873 Fuel Consumption: 39.9530 Mean: 2.1212, STD: 5.0212\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.113\n",
      "Episode: 44 Exploration P: 0.3078 Total reward: -1364.7350383393564 SOC: 0.5321 Cumulative_SOC_deviation: 132.5896 Fuel Consumption: 38.8386 Mean: 2.1209, STD: 5.0211\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.285\n",
      "Episode: 45 Exploration P: 0.2997 Total reward: -1583.5041154927574 SOC: 0.5121 Cumulative_SOC_deviation: 154.5904 Fuel Consumption: 37.6005 Mean: 2.1206, STD: 5.0211\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.136\n",
      "Episode: 46 Exploration P: 0.2918 Total reward: -1752.1986612780952 SOC: 0.4807 Cumulative_SOC_deviation: 171.7013 Fuel Consumption: 35.1860 Mean: 2.1203, STD: 5.0210\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 77.398\n",
      "Episode: 47 Exploration P: 0.2842 Total reward: -1619.8108725535901 SOC: 0.5062 Cumulative_SOC_deviation: 158.2633 Fuel Consumption: 37.1774 Mean: 2.1200, STD: 5.0209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.491\n",
      "Episode: 48 Exploration P: 0.2768 Total reward: -1550.5859177629886 SOC: 0.4939 Cumulative_SOC_deviation: 151.4306 Fuel Consumption: 36.2797 Mean: 2.1197, STD: 5.0209\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.220\n",
      "Episode: 49 Exploration P: 0.2696 Total reward: -1739.6716613021142 SOC: 0.4749 Cumulative_SOC_deviation: 170.4764 Fuel Consumption: 34.9074 Mean: 2.1194, STD: 5.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.600\n",
      "Episode: 50 Exploration P: 0.2625 Total reward: -2041.3883624885523 SOC: 0.4482 Cumulative_SOC_deviation: 200.8493 Fuel Consumption: 32.8954 Mean: 2.1192, STD: 5.0208\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.309\n",
      "Episode: 51 Exploration P: 0.2557 Total reward: -2036.8212452656808 SOC: 0.4512 Cumulative_SOC_deviation: 200.3565 Fuel Consumption: 33.2565 Mean: 2.1189, STD: 5.0207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.195\n",
      "Episode: 52 Exploration P: 0.2490 Total reward: -2256.2307577772744 SOC: 0.4318 Cumulative_SOC_deviation: 222.4388 Fuel Consumption: 31.8429 Mean: 2.1187, STD: 5.0207\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.057\n",
      "Episode: 53 Exploration P: 0.2426 Total reward: -1948.6914030610953 SOC: 0.4529 Cumulative_SOC_deviation: 191.5466 Fuel Consumption: 33.2256 Mean: 2.1185, STD: 5.0206\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.736\n",
      "Episode: 54 Exploration P: 0.2363 Total reward: -2228.0541773881273 SOC: 0.4146 Cumulative_SOC_deviation: 219.7480 Fuel Consumption: 30.5738 Mean: 2.1183, STD: 5.0206\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.053\n",
      "Episode: 55 Exploration P: 0.2301 Total reward: -2506.632202357789 SOC: 0.4097 Cumulative_SOC_deviation: 247.6182 Fuel Consumption: 30.4500 Mean: 2.1180, STD: 5.0205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.218\n",
      "Episode: 56 Exploration P: 0.2242 Total reward: -2335.3794444359664 SOC: 0.4047 Cumulative_SOC_deviation: 230.5487 Fuel Consumption: 29.8928 Mean: 2.1178, STD: 5.0205\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.338\n",
      "Episode: 57 Exploration P: 0.2184 Total reward: -2335.560601468857 SOC: 0.4028 Cumulative_SOC_deviation: 230.5637 Fuel Consumption: 29.9238 Mean: 2.1176, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.559\n",
      "Episode: 58 Exploration P: 0.2127 Total reward: -2430.34328881882 SOC: 0.3953 Cumulative_SOC_deviation: 240.0987 Fuel Consumption: 29.3563 Mean: 2.1175, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.477\n",
      "Episode: 59 Exploration P: 0.2072 Total reward: -2743.0697271252193 SOC: 0.3694 Cumulative_SOC_deviation: 271.5313 Fuel Consumption: 27.7572 Mean: 2.1173, STD: 5.0204\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.438\n",
      "Episode: 60 Exploration P: 0.2019 Total reward: -816.9460937056023 SOC: 0.6665 Cumulative_SOC_deviation: 76.8289 Fuel Consumption: 48.6575 Mean: 2.1171, STD: 5.0203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.549\n",
      "Episode: 61 Exploration P: 0.1967 Total reward: -743.9159604249479 SOC: 0.6520 Cumulative_SOC_deviation: 69.7239 Fuel Consumption: 46.6773 Mean: 2.1169, STD: 5.0203\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.389\n",
      "Episode: 62 Exploration P: 0.1916 Total reward: -665.815876444053 SOC: 0.6527 Cumulative_SOC_deviation: 61.9069 Fuel Consumption: 46.7469 Mean: 2.1168, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.637\n",
      "Episode: 63 Exploration P: 0.1867 Total reward: -385.58193684852733 SOC: 0.6222 Cumulative_SOC_deviation: 34.1319 Fuel Consumption: 44.2629 Mean: 2.1166, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.577\n",
      "Episode: 64 Exploration P: 0.1819 Total reward: -279.0741429039814 SOC: 0.6120 Cumulative_SOC_deviation: 23.5658 Fuel Consumption: 43.4163 Mean: 2.1164, STD: 5.0202\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.139\n",
      "Episode: 65 Exploration P: 0.1773 Total reward: -251.14966689189956 SOC: 0.6262 Cumulative_SOC_deviation: 20.7005 Fuel Consumption: 44.1449 Mean: 2.1163, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.376\n",
      "Episode: 66 Exploration P: 0.1727 Total reward: -351.5750666397939 SOC: 0.6308 Cumulative_SOC_deviation: 30.6630 Fuel Consumption: 44.9450 Mean: 2.1162, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.404\n",
      "Episode: 67 Exploration P: 0.1683 Total reward: -239.1061235429251 SOC: 0.6279 Cumulative_SOC_deviation: 19.4455 Fuel Consumption: 44.6508 Mean: 2.1160, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.307\n",
      "Episode: 68 Exploration P: 0.1640 Total reward: -248.54810986455135 SOC: 0.6192 Cumulative_SOC_deviation: 20.4680 Fuel Consumption: 43.8684 Mean: 2.1159, STD: 5.0201\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.093\n",
      "Episode: 69 Exploration P: 0.1599 Total reward: -304.6788027717888 SOC: 0.6091 Cumulative_SOC_deviation: 26.1784 Fuel Consumption: 42.8949 Mean: 2.1157, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.501\n",
      "Episode: 70 Exploration P: 0.1558 Total reward: -275.4933264588887 SOC: 0.6124 Cumulative_SOC_deviation: 23.1913 Fuel Consumption: 43.5802 Mean: 2.1156, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.626\n",
      "Episode: 71 Exploration P: 0.1519 Total reward: -336.42897808312273 SOC: 0.6280 Cumulative_SOC_deviation: 29.0970 Fuel Consumption: 45.4589 Mean: 2.1155, STD: 5.0200\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.371\n",
      "Episode: 72 Exploration P: 0.1480 Total reward: -189.3348451352663 SOC: 0.6056 Cumulative_SOC_deviation: 14.6885 Fuel Consumption: 42.4502 Mean: 2.1154, STD: 5.0199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.392\n",
      "Episode: 73 Exploration P: 0.1443 Total reward: -252.92297848550137 SOC: 0.6133 Cumulative_SOC_deviation: 20.9389 Fuel Consumption: 43.5344 Mean: 2.1152, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.655\n",
      "Episode: 74 Exploration P: 0.1406 Total reward: -222.50902946922344 SOC: 0.6149 Cumulative_SOC_deviation: 17.9293 Fuel Consumption: 43.2162 Mean: 2.1151, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.849\n",
      "Episode: 75 Exploration P: 0.1371 Total reward: -209.76176744678614 SOC: 0.6104 Cumulative_SOC_deviation: 16.6999 Fuel Consumption: 42.7633 Mean: 2.1150, STD: 5.0199\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.301\n",
      "Episode: 76 Exploration P: 0.1337 Total reward: -168.22500223221016 SOC: 0.6146 Cumulative_SOC_deviation: 12.5493 Fuel Consumption: 42.7318 Mean: 2.1149, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.157\n",
      "Episode: 77 Exploration P: 0.1303 Total reward: -135.17742377536365 SOC: 0.6105 Cumulative_SOC_deviation: 9.2833 Fuel Consumption: 42.3447 Mean: 2.1148, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.700\n",
      "Episode: 78 Exploration P: 0.1271 Total reward: -128.07606630573096 SOC: 0.6096 Cumulative_SOC_deviation: 8.5435 Fuel Consumption: 42.6407 Mean: 2.1147, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.436\n",
      "Episode: 79 Exploration P: 0.1239 Total reward: -103.86298754025506 SOC: 0.6116 Cumulative_SOC_deviation: 6.1255 Fuel Consumption: 42.6075 Mean: 2.1146, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.517\n",
      "Episode: 80 Exploration P: 0.1208 Total reward: -115.6017732119348 SOC: 0.6014 Cumulative_SOC_deviation: 7.3498 Fuel Consumption: 42.1035 Mean: 2.1145, STD: 5.0198\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.719\n",
      "Episode: 81 Exploration P: 0.1178 Total reward: -116.883797276433 SOC: 0.6048 Cumulative_SOC_deviation: 7.4993 Fuel Consumption: 41.8910 Mean: 2.1144, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.347\n",
      "Episode: 82 Exploration P: 0.1149 Total reward: -126.42141820688984 SOC: 0.6072 Cumulative_SOC_deviation: 8.4079 Fuel Consumption: 42.3421 Mean: 2.1143, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.401\n",
      "Episode: 83 Exploration P: 0.1120 Total reward: -111.0802418197183 SOC: 0.6034 Cumulative_SOC_deviation: 6.8643 Fuel Consumption: 42.4377 Mean: 2.1142, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.753\n",
      "Episode: 84 Exploration P: 0.1093 Total reward: -113.14815316282133 SOC: 0.6101 Cumulative_SOC_deviation: 7.0415 Fuel Consumption: 42.7336 Mean: 2.1141, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.796\n",
      "Episode: 85 Exploration P: 0.1066 Total reward: -107.61599016253895 SOC: 0.6093 Cumulative_SOC_deviation: 6.5473 Fuel Consumption: 42.1430 Mean: 2.1140, STD: 5.0197\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.621\n",
      "Episode: 86 Exploration P: 0.1040 Total reward: -105.87788890028013 SOC: 0.6064 Cumulative_SOC_deviation: 6.4013 Fuel Consumption: 41.8646 Mean: 2.1140, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.697\n",
      "Episode: 87 Exploration P: 0.1014 Total reward: -132.38077044319866 SOC: 0.6016 Cumulative_SOC_deviation: 9.0982 Fuel Consumption: 41.3984 Mean: 2.1139, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.430\n",
      "Episode: 88 Exploration P: 0.0989 Total reward: -132.02987848246397 SOC: 0.6018 Cumulative_SOC_deviation: 8.9800 Fuel Consumption: 42.2297 Mean: 2.1138, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.656\n",
      "Episode: 89 Exploration P: 0.0965 Total reward: -117.11375155582766 SOC: 0.5994 Cumulative_SOC_deviation: 7.5326 Fuel Consumption: 41.7880 Mean: 2.1137, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.612\n",
      "Episode: 90 Exploration P: 0.0942 Total reward: -134.9546530737663 SOC: 0.6064 Cumulative_SOC_deviation: 9.2835 Fuel Consumption: 42.1193 Mean: 2.1136, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.620\n",
      "Episode: 91 Exploration P: 0.0919 Total reward: -153.0393751826669 SOC: 0.6089 Cumulative_SOC_deviation: 11.0859 Fuel Consumption: 42.1806 Mean: 2.1136, STD: 5.0196\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.957\n",
      "Episode: 92 Exploration P: 0.0897 Total reward: -130.58090459314937 SOC: 0.6018 Cumulative_SOC_deviation: 8.8777 Fuel Consumption: 41.8040 Mean: 2.1135, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.516\n",
      "Episode: 93 Exploration P: 0.0875 Total reward: -123.83317407687379 SOC: 0.6021 Cumulative_SOC_deviation: 8.2043 Fuel Consumption: 41.7902 Mean: 2.1134, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.497\n",
      "Episode: 94 Exploration P: 0.0854 Total reward: -131.8426974656458 SOC: 0.6030 Cumulative_SOC_deviation: 8.9902 Fuel Consumption: 41.9405 Mean: 2.1133, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.818\n",
      "Episode: 95 Exploration P: 0.0834 Total reward: -148.69475430365742 SOC: 0.6088 Cumulative_SOC_deviation: 10.6168 Fuel Consumption: 42.5264 Mean: 2.1133, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.129\n",
      "Episode: 96 Exploration P: 0.0814 Total reward: -127.85093669928379 SOC: 0.5965 Cumulative_SOC_deviation: 8.6225 Fuel Consumption: 41.6258 Mean: 2.1132, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.707\n",
      "Episode: 97 Exploration P: 0.0795 Total reward: -129.4882589129921 SOC: 0.6095 Cumulative_SOC_deviation: 8.7174 Fuel Consumption: 42.3141 Mean: 2.1131, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.353\n",
      "Episode: 98 Exploration P: 0.0776 Total reward: -137.70583293155704 SOC: 0.6056 Cumulative_SOC_deviation: 9.5530 Fuel Consumption: 42.1755 Mean: 2.1131, STD: 5.0195\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.477\n",
      "Episode: 99 Exploration P: 0.0758 Total reward: -142.3087596334157 SOC: 0.6145 Cumulative_SOC_deviation: 9.9400 Fuel Consumption: 42.9092 Mean: 2.1130, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.700\n",
      "Episode: 100 Exploration P: 0.0740 Total reward: -161.77628557409446 SOC: 0.6094 Cumulative_SOC_deviation: 11.9170 Fuel Consumption: 42.6061 Mean: 2.1130, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.651\n",
      "Episode: 101 Exploration P: 0.0722 Total reward: -133.5348163776046 SOC: 0.6040 Cumulative_SOC_deviation: 9.1765 Fuel Consumption: 41.7693 Mean: 2.1129, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.015\n",
      "Episode: 102 Exploration P: 0.0706 Total reward: -140.3265782656531 SOC: 0.5915 Cumulative_SOC_deviation: 9.9187 Fuel Consumption: 41.1400 Mean: 2.1128, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.500\n",
      "Episode: 103 Exploration P: 0.0689 Total reward: -167.832813653518 SOC: 0.6150 Cumulative_SOC_deviation: 12.4798 Fuel Consumption: 43.0346 Mean: 2.1128, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.731\n",
      "Episode: 104 Exploration P: 0.0673 Total reward: -187.84581599853544 SOC: 0.6085 Cumulative_SOC_deviation: 14.4916 Fuel Consumption: 42.9302 Mean: 2.1127, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.878\n",
      "Episode: 105 Exploration P: 0.0658 Total reward: -159.60027361951956 SOC: 0.6097 Cumulative_SOC_deviation: 11.6767 Fuel Consumption: 42.8333 Mean: 2.1127, STD: 5.0194\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.768\n",
      "Episode: 106 Exploration P: 0.0643 Total reward: -157.06232519993253 SOC: 0.6096 Cumulative_SOC_deviation: 11.4588 Fuel Consumption: 42.4739 Mean: 2.1126, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.707\n",
      "Episode: 107 Exploration P: 0.0628 Total reward: -138.45991414163092 SOC: 0.6108 Cumulative_SOC_deviation: 9.5865 Fuel Consumption: 42.5954 Mean: 2.1125, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.140\n",
      "Episode: 108 Exploration P: 0.0614 Total reward: -157.0052293500879 SOC: 0.6114 Cumulative_SOC_deviation: 11.4221 Fuel Consumption: 42.7838 Mean: 2.1125, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.620\n",
      "Episode: 109 Exploration P: 0.0600 Total reward: -151.0446677589066 SOC: 0.6060 Cumulative_SOC_deviation: 10.8640 Fuel Consumption: 42.4048 Mean: 2.1124, STD: 5.0193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.476\n",
      "Episode: 110 Exploration P: 0.0586 Total reward: -152.99858522489103 SOC: 0.6114 Cumulative_SOC_deviation: 11.0624 Fuel Consumption: 42.3747 Mean: 2.1124, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.301\n",
      "Episode: 111 Exploration P: 0.0573 Total reward: -142.90476781179697 SOC: 0.6081 Cumulative_SOC_deviation: 10.0845 Fuel Consumption: 42.0593 Mean: 2.1123, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.682\n",
      "Episode: 112 Exploration P: 0.0560 Total reward: -139.8458175164398 SOC: 0.6069 Cumulative_SOC_deviation: 9.7509 Fuel Consumption: 42.3364 Mean: 2.1123, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.444\n",
      "Episode: 113 Exploration P: 0.0548 Total reward: -131.85460838260875 SOC: 0.6084 Cumulative_SOC_deviation: 8.9749 Fuel Consumption: 42.1059 Mean: 2.1122, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.707\n",
      "Episode: 114 Exploration P: 0.0536 Total reward: -111.57647436676868 SOC: 0.6043 Cumulative_SOC_deviation: 6.9878 Fuel Consumption: 41.6988 Mean: 2.1122, STD: 5.0193\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.482\n",
      "Episode: 115 Exploration P: 0.0524 Total reward: -96.06640647925322 SOC: 0.6055 Cumulative_SOC_deviation: 5.4748 Fuel Consumption: 41.3181 Mean: 2.1121, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.810\n",
      "Episode: 116 Exploration P: 0.0512 Total reward: -95.93185752322552 SOC: 0.6029 Cumulative_SOC_deviation: 5.5056 Fuel Consumption: 40.8755 Mean: 2.1121, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.100\n",
      "Episode: 117 Exploration P: 0.0501 Total reward: -94.61482063689776 SOC: 0.6073 Cumulative_SOC_deviation: 5.2712 Fuel Consumption: 41.9030 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.811\n",
      "Episode: 118 Exploration P: 0.0490 Total reward: -86.84114974121805 SOC: 0.6004 Cumulative_SOC_deviation: 4.6102 Fuel Consumption: 40.7394 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.035\n",
      "Episode: 119 Exploration P: 0.0480 Total reward: -91.1484140768182 SOC: 0.6026 Cumulative_SOC_deviation: 5.0050 Fuel Consumption: 41.0987 Mean: 2.1120, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.427\n",
      "Episode: 120 Exploration P: 0.0469 Total reward: -100.46665331088168 SOC: 0.5993 Cumulative_SOC_deviation: 5.9408 Fuel Consumption: 41.0588 Mean: 2.1119, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.067\n",
      "Episode: 121 Exploration P: 0.0459 Total reward: -115.06917660665408 SOC: 0.5963 Cumulative_SOC_deviation: 7.4162 Fuel Consumption: 40.9070 Mean: 2.1119, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.401\n",
      "Episode: 122 Exploration P: 0.0450 Total reward: -121.1197705473628 SOC: 0.5959 Cumulative_SOC_deviation: 8.0213 Fuel Consumption: 40.9064 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.506\n",
      "Episode: 123 Exploration P: 0.0440 Total reward: -119.53422423540684 SOC: 0.5989 Cumulative_SOC_deviation: 7.7982 Fuel Consumption: 41.5521 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.569\n",
      "Episode: 124 Exploration P: 0.0431 Total reward: -119.57001349624905 SOC: 0.5955 Cumulative_SOC_deviation: 7.8476 Fuel Consumption: 41.0942 Mean: 2.1118, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.491\n",
      "Episode: 125 Exploration P: 0.0422 Total reward: -129.20053428398793 SOC: 0.5982 Cumulative_SOC_deviation: 8.7961 Fuel Consumption: 41.2396 Mean: 2.1117, STD: 5.0192\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.907\n",
      "Episode: 126 Exploration P: 0.0413 Total reward: -124.75106648246172 SOC: 0.5974 Cumulative_SOC_deviation: 8.3331 Fuel Consumption: 41.4203 Mean: 2.1117, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.539\n",
      "Episode: 127 Exploration P: 0.0405 Total reward: -114.50062425876847 SOC: 0.5994 Cumulative_SOC_deviation: 7.3129 Fuel Consumption: 41.3713 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.539\n",
      "Episode: 128 Exploration P: 0.0397 Total reward: -125.88355793993932 SOC: 0.5996 Cumulative_SOC_deviation: 8.4605 Fuel Consumption: 41.2781 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.885\n",
      "Episode: 129 Exploration P: 0.0389 Total reward: -120.17303729462864 SOC: 0.6023 Cumulative_SOC_deviation: 7.9378 Fuel Consumption: 40.7950 Mean: 2.1116, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.791\n",
      "Episode: 130 Exploration P: 0.0381 Total reward: -124.07601797490896 SOC: 0.5987 Cumulative_SOC_deviation: 8.3334 Fuel Consumption: 40.7423 Mean: 2.1115, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.887\n",
      "Episode: 131 Exploration P: 0.0373 Total reward: -108.09318717947633 SOC: 0.6018 Cumulative_SOC_deviation: 6.7028 Fuel Consumption: 41.0648 Mean: 2.1115, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.461\n",
      "Episode: 132 Exploration P: 0.0366 Total reward: -158.82731903901237 SOC: 0.5939 Cumulative_SOC_deviation: 11.8658 Fuel Consumption: 40.1689 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.442\n",
      "Episode: 133 Exploration P: 0.0359 Total reward: -175.08971063641897 SOC: 0.5912 Cumulative_SOC_deviation: 13.4427 Fuel Consumption: 40.6627 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.539\n",
      "Episode: 134 Exploration P: 0.0352 Total reward: -218.2717709457275 SOC: 0.5892 Cumulative_SOC_deviation: 17.7330 Fuel Consumption: 40.9416 Mean: 2.1114, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.513\n",
      "Episode: 135 Exploration P: 0.0345 Total reward: -204.29556828723034 SOC: 0.5986 Cumulative_SOC_deviation: 16.2907 Fuel Consumption: 41.3883 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.772\n",
      "Episode: 136 Exploration P: 0.0338 Total reward: -185.7253265579447 SOC: 0.6049 Cumulative_SOC_deviation: 14.4002 Fuel Consumption: 41.7234 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.739\n",
      "Episode: 137 Exploration P: 0.0332 Total reward: -165.78188210373636 SOC: 0.5968 Cumulative_SOC_deviation: 12.4256 Fuel Consumption: 41.5261 Mean: 2.1113, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.556\n",
      "Episode: 138 Exploration P: 0.0325 Total reward: -231.4256632865296 SOC: 0.6023 Cumulative_SOC_deviation: 19.0211 Fuel Consumption: 41.2148 Mean: 2.1112, STD: 5.0191\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.723\n",
      "Episode: 139 Exploration P: 0.0319 Total reward: -227.9159445440434 SOC: 0.6035 Cumulative_SOC_deviation: 18.5750 Fuel Consumption: 42.1656 Mean: 2.1112, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.620\n",
      "Episode: 140 Exploration P: 0.0313 Total reward: -175.9539322508671 SOC: 0.6115 Cumulative_SOC_deviation: 13.3754 Fuel Consumption: 42.2001 Mean: 2.1112, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.877\n",
      "Episode: 141 Exploration P: 0.0308 Total reward: -181.9578464417563 SOC: 0.6132 Cumulative_SOC_deviation: 13.9438 Fuel Consumption: 42.5198 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.712\n",
      "Episode: 142 Exploration P: 0.0302 Total reward: -158.54918410435133 SOC: 0.6100 Cumulative_SOC_deviation: 11.6409 Fuel Consumption: 42.1398 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.186\n",
      "Episode: 143 Exploration P: 0.0296 Total reward: -145.90218292338162 SOC: 0.6018 Cumulative_SOC_deviation: 10.4345 Fuel Consumption: 41.5568 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.248\n",
      "Episode: 144 Exploration P: 0.0291 Total reward: -125.13937721395178 SOC: 0.6098 Cumulative_SOC_deviation: 8.3427 Fuel Consumption: 41.7128 Mean: 2.1111, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.570\n",
      "Episode: 145 Exploration P: 0.0286 Total reward: -153.29955623432375 SOC: 0.6094 Cumulative_SOC_deviation: 11.1347 Fuel Consumption: 41.9530 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.802\n",
      "Episode: 146 Exploration P: 0.0281 Total reward: -155.9328477420409 SOC: 0.6091 Cumulative_SOC_deviation: 11.4101 Fuel Consumption: 41.8318 Mean: 2.1110, STD: 5.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.846\n",
      "Episode: 147 Exploration P: 0.0276 Total reward: -121.76730351052156 SOC: 0.6085 Cumulative_SOC_deviation: 8.0493 Fuel Consumption: 41.2739 Mean: 2.1110, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.983\n",
      "Episode: 148 Exploration P: 0.0271 Total reward: -134.33351682928458 SOC: 0.6073 Cumulative_SOC_deviation: 9.2759 Fuel Consumption: 41.5740 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.167\n",
      "Episode: 149 Exploration P: 0.0267 Total reward: -112.24774079046362 SOC: 0.6073 Cumulative_SOC_deviation: 7.0909 Fuel Consumption: 41.3391 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.017\n",
      "Episode: 150 Exploration P: 0.0262 Total reward: -88.08285946252543 SOC: 0.6030 Cumulative_SOC_deviation: 4.7133 Fuel Consumption: 40.9500 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.099\n",
      "Episode: 151 Exploration P: 0.0258 Total reward: -83.71943044517066 SOC: 0.6015 Cumulative_SOC_deviation: 4.2682 Fuel Consumption: 41.0369 Mean: 2.1109, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.127\n",
      "Episode: 152 Exploration P: 0.0253 Total reward: -90.1821878091588 SOC: 0.6007 Cumulative_SOC_deviation: 4.9514 Fuel Consumption: 40.6680 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.417\n",
      "Episode: 153 Exploration P: 0.0249 Total reward: -128.4726498157001 SOC: 0.5935 Cumulative_SOC_deviation: 8.8176 Fuel Consumption: 40.2969 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.460\n",
      "Episode: 154 Exploration P: 0.0245 Total reward: -147.30515306873255 SOC: 0.5971 Cumulative_SOC_deviation: 10.6129 Fuel Consumption: 41.1766 Mean: 2.1108, STD: 5.0190\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.398\n",
      "Episode: 155 Exploration P: 0.0241 Total reward: -202.12201773091007 SOC: 0.5967 Cumulative_SOC_deviation: 16.0687 Fuel Consumption: 41.4350 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.686\n",
      "Episode: 156 Exploration P: 0.0237 Total reward: -195.2032432520301 SOC: 0.5875 Cumulative_SOC_deviation: 15.4698 Fuel Consumption: 40.5049 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.823\n",
      "Episode: 157 Exploration P: 0.0234 Total reward: -281.84342377319194 SOC: 0.5946 Cumulative_SOC_deviation: 23.9445 Fuel Consumption: 42.3985 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.987\n",
      "Episode: 158 Exploration P: 0.0230 Total reward: -134.18957599920157 SOC: 0.6078 Cumulative_SOC_deviation: 9.2057 Fuel Consumption: 42.1321 Mean: 2.1107, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.014\n",
      "Episode: 159 Exploration P: 0.0227 Total reward: -150.62354724697002 SOC: 0.6045 Cumulative_SOC_deviation: 10.8282 Fuel Consumption: 42.3415 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.148\n",
      "Episode: 160 Exploration P: 0.0223 Total reward: -105.41377563499113 SOC: 0.6045 Cumulative_SOC_deviation: 6.3223 Fuel Consumption: 42.1909 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.695\n",
      "Episode: 161 Exploration P: 0.0220 Total reward: -121.61180913336506 SOC: 0.6016 Cumulative_SOC_deviation: 7.9485 Fuel Consumption: 42.1272 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.899\n",
      "Episode: 162 Exploration P: 0.0217 Total reward: -77.49648403393242 SOC: 0.6004 Cumulative_SOC_deviation: 3.6710 Fuel Consumption: 40.7870 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.076\n",
      "Episode: 163 Exploration P: 0.0213 Total reward: -103.03017521894645 SOC: 0.6039 Cumulative_SOC_deviation: 6.1712 Fuel Consumption: 41.3184 Mean: 2.1106, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.910\n",
      "Episode: 164 Exploration P: 0.0210 Total reward: -109.9877706871004 SOC: 0.6076 Cumulative_SOC_deviation: 6.7969 Fuel Consumption: 42.0184 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.883\n",
      "Episode: 165 Exploration P: 0.0207 Total reward: -121.54478856069431 SOC: 0.6028 Cumulative_SOC_deviation: 7.9807 Fuel Consumption: 41.7373 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.580\n",
      "Episode: 166 Exploration P: 0.0204 Total reward: -122.26639330153195 SOC: 0.6076 Cumulative_SOC_deviation: 8.0531 Fuel Consumption: 41.7353 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.683\n",
      "Episode: 167 Exploration P: 0.0202 Total reward: -122.46417660766512 SOC: 0.6052 Cumulative_SOC_deviation: 8.0919 Fuel Consumption: 41.5456 Mean: 2.1105, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.907\n",
      "Episode: 168 Exploration P: 0.0199 Total reward: -107.37702234123321 SOC: 0.6057 Cumulative_SOC_deviation: 6.5901 Fuel Consumption: 41.4758 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.805\n",
      "Episode: 169 Exploration P: 0.0196 Total reward: -94.44878862976526 SOC: 0.6009 Cumulative_SOC_deviation: 5.3770 Fuel Consumption: 40.6787 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.843\n",
      "Episode: 170 Exploration P: 0.0194 Total reward: -96.69208611734044 SOC: 0.6009 Cumulative_SOC_deviation: 5.5678 Fuel Consumption: 41.0137 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.786\n",
      "Episode: 171 Exploration P: 0.0191 Total reward: -99.68734161212305 SOC: 0.6050 Cumulative_SOC_deviation: 5.8482 Fuel Consumption: 41.2049 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.748\n",
      "Episode: 172 Exploration P: 0.0189 Total reward: -95.9755319599003 SOC: 0.6048 Cumulative_SOC_deviation: 5.5075 Fuel Consumption: 40.9002 Mean: 2.1104, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.074\n",
      "Episode: 173 Exploration P: 0.0186 Total reward: -83.18701578037623 SOC: 0.5975 Cumulative_SOC_deviation: 4.2961 Fuel Consumption: 40.2257 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.031\n",
      "Episode: 174 Exploration P: 0.0184 Total reward: -93.46288125706187 SOC: 0.5995 Cumulative_SOC_deviation: 5.3047 Fuel Consumption: 40.4156 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.174\n",
      "Episode: 175 Exploration P: 0.0182 Total reward: -108.30649873546119 SOC: 0.6022 Cumulative_SOC_deviation: 6.7144 Fuel Consumption: 41.1623 Mean: 2.1103, STD: 5.0189\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.386\n",
      "Episode: 176 Exploration P: 0.0179 Total reward: -88.07796496659327 SOC: 0.6029 Cumulative_SOC_deviation: 4.7322 Fuel Consumption: 40.7559 Mean: 2.1103, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.680\n",
      "Episode: 177 Exploration P: 0.0177 Total reward: -87.17815520249411 SOC: 0.6026 Cumulative_SOC_deviation: 4.6639 Fuel Consumption: 40.5394 Mean: 2.1103, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.707\n",
      "Episode: 178 Exploration P: 0.0175 Total reward: -107.04346541211834 SOC: 0.6043 Cumulative_SOC_deviation: 6.5883 Fuel Consumption: 41.1608 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.761\n",
      "Episode: 179 Exploration P: 0.0173 Total reward: -90.22559369044133 SOC: 0.6025 Cumulative_SOC_deviation: 4.9615 Fuel Consumption: 40.6108 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.750\n",
      "Episode: 180 Exploration P: 0.0171 Total reward: -98.5830507056856 SOC: 0.6069 Cumulative_SOC_deviation: 5.7361 Fuel Consumption: 41.2222 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.197\n",
      "Episode: 181 Exploration P: 0.0169 Total reward: -84.41891996286074 SOC: 0.6004 Cumulative_SOC_deviation: 4.4046 Fuel Consumption: 40.3729 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.601\n",
      "Episode: 182 Exploration P: 0.0167 Total reward: -88.9991692382735 SOC: 0.6011 Cumulative_SOC_deviation: 4.8526 Fuel Consumption: 40.4729 Mean: 2.1102, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.570\n",
      "Episode: 183 Exploration P: 0.0165 Total reward: -100.237779631821 SOC: 0.6009 Cumulative_SOC_deviation: 5.9120 Fuel Consumption: 41.1177 Mean: 2.1101, STD: 5.0188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.780\n",
      "Episode: 184 Exploration P: 0.0164 Total reward: -84.01181522442931 SOC: 0.6030 Cumulative_SOC_deviation: 4.3521 Fuel Consumption: 40.4906 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.528\n",
      "Episode: 185 Exploration P: 0.0162 Total reward: -81.5893547676322 SOC: 0.5999 Cumulative_SOC_deviation: 4.1347 Fuel Consumption: 40.2425 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.660\n",
      "Episode: 186 Exploration P: 0.0160 Total reward: -79.61945055007689 SOC: 0.6036 Cumulative_SOC_deviation: 3.9087 Fuel Consumption: 40.5323 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.604\n",
      "Episode: 187 Exploration P: 0.0159 Total reward: -77.65330542707967 SOC: 0.6006 Cumulative_SOC_deviation: 3.7283 Fuel Consumption: 40.3702 Mean: 2.1101, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.871\n",
      "Episode: 188 Exploration P: 0.0157 Total reward: -84.21927492461144 SOC: 0.6028 Cumulative_SOC_deviation: 4.3665 Fuel Consumption: 40.5546 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.002\n",
      "Episode: 189 Exploration P: 0.0156 Total reward: -88.18909647149351 SOC: 0.6018 Cumulative_SOC_deviation: 4.7528 Fuel Consumption: 40.6612 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.926\n",
      "Episode: 190 Exploration P: 0.0154 Total reward: -112.68831290491725 SOC: 0.5965 Cumulative_SOC_deviation: 7.1973 Fuel Consumption: 40.7154 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.249\n",
      "Episode: 191 Exploration P: 0.0153 Total reward: -92.87341842915804 SOC: 0.6049 Cumulative_SOC_deviation: 5.1701 Fuel Consumption: 41.1720 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.730\n",
      "Episode: 192 Exploration P: 0.0151 Total reward: -84.03517282462002 SOC: 0.5988 Cumulative_SOC_deviation: 4.3571 Fuel Consumption: 40.4641 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 74.253\n",
      "Episode: 193 Exploration P: 0.0150 Total reward: -110.46462028515421 SOC: 0.6010 Cumulative_SOC_deviation: 6.9296 Fuel Consumption: 41.1688 Mean: 2.1100, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.712\n",
      "Episode: 194 Exploration P: 0.0148 Total reward: -97.15057054829178 SOC: 0.5996 Cumulative_SOC_deviation: 5.6020 Fuel Consumption: 41.1304 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 73.588\n",
      "Episode: 195 Exploration P: 0.0147 Total reward: -106.93325279035838 SOC: 0.5996 Cumulative_SOC_deviation: 6.5800 Fuel Consumption: 41.1328 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.901\n",
      "Episode: 196 Exploration P: 0.0146 Total reward: -111.51439846027775 SOC: 0.5967 Cumulative_SOC_deviation: 7.0622 Fuel Consumption: 40.8925 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.801\n",
      "Episode: 197 Exploration P: 0.0145 Total reward: -116.74137922683225 SOC: 0.5987 Cumulative_SOC_deviation: 7.5894 Fuel Consumption: 40.8470 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.687\n",
      "Episode: 198 Exploration P: 0.0143 Total reward: -129.94361739618157 SOC: 0.5970 Cumulative_SOC_deviation: 8.9171 Fuel Consumption: 40.7728 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.625\n",
      "Episode: 199 Exploration P: 0.0142 Total reward: -128.8274053085443 SOC: 0.5995 Cumulative_SOC_deviation: 8.7393 Fuel Consumption: 41.4349 Mean: 2.1099, STD: 5.0188\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.484\n",
      "Episode: 200 Exploration P: 0.0141 Total reward: -118.08402032232448 SOC: 0.5983 Cumulative_SOC_deviation: 7.6818 Fuel Consumption: 41.2660 Mean: 2.1099, STD: 5.0188\n"
     ]
    }
   ],
   "source": [
    "print(env.version)\n",
    "\n",
    "num_trials = 3\n",
    "results_dict = {} \n",
    "for trial in range(num_trials): \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    for ep in range(total_episodes): \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * steps)\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "              \"Mean: {:.4f}, STD: {:.4f}\".format(buffer.power_mean, buffer.power_std)\n",
    "        )\n",
    "\n",
    "    results_dict[trial + 1] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG2_400.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
