{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "import scipy.io as sio\n",
    "\n",
    "from vehicle_model_variant import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200 \n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "#     actor_model.load_weights(\"./DDPG1_trial1/actor_model_checkpoint\")\n",
    "#     critic_model.load_weights(\"./DDPG1_trial1/critic_model_checkpoint\")\n",
    "#     target_actor.load_weights(\"./DDPG1_trial1/target_actor_checkpoint\")\n",
    "#     target_critic.load_weights(\"./DDPG1_trial1/target_critic_checkpoint\")\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    if not os.path.exists(root): \n",
    "        os.makedirs(root)\n",
    "        \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor):\n",
    "#     test_cycle = driver.get_cycle() \n",
    "    test_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "    test_cycle = sio.loadmat(test_cycle_path)\n",
    "    test_cycle = test_cycle[\"sch_cycle\"][:, 1]\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 14.995\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -654.067536675542 SOC: 1.0000 Cumulative_SOC_deviation: 500.7182 Fuel Consumption: 153.3493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.954\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -645.3713033938169 SOC: 1.0000 Cumulative_SOC_deviation: 492.8165 Fuel Consumption: 152.5548\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 14.269\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -645.9060113530802 SOC: 1.0000 Cumulative_SOC_deviation: 497.0967 Fuel Consumption: 148.8094\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 39.673\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -644.5998559169105 SOC: 1.0000 Cumulative_SOC_deviation: 491.3433 Fuel Consumption: 153.2565\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.933\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -642.2171582456282 SOC: 1.0000 Cumulative_SOC_deviation: 492.6133 Fuel Consumption: 149.6039\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.564\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -641.3320152796172 SOC: 1.0000 Cumulative_SOC_deviation: 496.5777 Fuel Consumption: 144.7543\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.795\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -627.3425113859188 SOC: 1.0000 Cumulative_SOC_deviation: 487.3345 Fuel Consumption: 140.0080\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.824\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -630.2168752806016 SOC: 1.0000 Cumulative_SOC_deviation: 489.1564 Fuel Consumption: 141.0604\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.653\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -609.2408841925786 SOC: 1.0000 Cumulative_SOC_deviation: 477.3739 Fuel Consumption: 131.8670\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.877\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -603.7919077472867 SOC: 1.0000 Cumulative_SOC_deviation: 469.0152 Fuel Consumption: 134.7767\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.909\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -612.1135310921794 SOC: 1.0000 Cumulative_SOC_deviation: 480.9688 Fuel Consumption: 131.1447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.277\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -585.9318758868743 SOC: 1.0000 Cumulative_SOC_deviation: 461.0400 Fuel Consumption: 124.8919\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.094\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -585.5352198508848 SOC: 1.0000 Cumulative_SOC_deviation: 461.0664 Fuel Consumption: 124.4689\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.682\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -568.2796472426055 SOC: 1.0000 Cumulative_SOC_deviation: 446.2252 Fuel Consumption: 122.0544\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.881\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -591.4604337344138 SOC: 1.0000 Cumulative_SOC_deviation: 467.4456 Fuel Consumption: 124.0149\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.889\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -579.6984026624698 SOC: 1.0000 Cumulative_SOC_deviation: 460.0172 Fuel Consumption: 119.6812\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.915\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -567.1418975437035 SOC: 1.0000 Cumulative_SOC_deviation: 452.8467 Fuel Consumption: 114.2952\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.310\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -548.0950850085833 SOC: 1.0000 Cumulative_SOC_deviation: 434.7698 Fuel Consumption: 113.3253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.859\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -549.5245053935438 SOC: 1.0000 Cumulative_SOC_deviation: 437.0660 Fuel Consumption: 112.4585\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.172\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -533.3351718916173 SOC: 1.0000 Cumulative_SOC_deviation: 422.7855 Fuel Consumption: 110.5497\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.803\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -511.45292170434703 SOC: 1.0000 Cumulative_SOC_deviation: 406.7536 Fuel Consumption: 104.6993\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.882\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -524.6521013007298 SOC: 1.0000 Cumulative_SOC_deviation: 419.2615 Fuel Consumption: 105.3906\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.071\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -532.9467981137359 SOC: 1.0000 Cumulative_SOC_deviation: 430.5278 Fuel Consumption: 102.4190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.328\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -507.0718721160625 SOC: 1.0000 Cumulative_SOC_deviation: 402.1868 Fuel Consumption: 104.8850\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.724\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -461.7339991084115 SOC: 1.0000 Cumulative_SOC_deviation: 363.3081 Fuel Consumption: 98.4259\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.869\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -484.65394021503346 SOC: 1.0000 Cumulative_SOC_deviation: 384.9383 Fuel Consumption: 99.7156\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.499\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -479.99507184027317 SOC: 1.0000 Cumulative_SOC_deviation: 381.1358 Fuel Consumption: 98.8592\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.357\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -452.5001815595476 SOC: 1.0000 Cumulative_SOC_deviation: 355.4982 Fuel Consumption: 97.0020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.575\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -461.61917747246326 SOC: 1.0000 Cumulative_SOC_deviation: 367.6301 Fuel Consumption: 93.9891\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.064\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -448.49482446506477 SOC: 1.0000 Cumulative_SOC_deviation: 354.5264 Fuel Consumption: 93.9684\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.050\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -455.07937756891 SOC: 1.0000 Cumulative_SOC_deviation: 362.9372 Fuel Consumption: 92.1421\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.823\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -384.30729192097743 SOC: 1.0000 Cumulative_SOC_deviation: 297.2417 Fuel Consumption: 87.0656\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.640\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -402.1385262588316 SOC: 1.0000 Cumulative_SOC_deviation: 310.6155 Fuel Consumption: 91.5230\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.241\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -355.78409836401863 SOC: 1.0000 Cumulative_SOC_deviation: 267.2224 Fuel Consumption: 88.5617\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.762\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -333.4100159602595 SOC: 1.0000 Cumulative_SOC_deviation: 248.0159 Fuel Consumption: 85.3941\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.866\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -359.3422571687896 SOC: 1.0000 Cumulative_SOC_deviation: 273.6386 Fuel Consumption: 85.7036\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.915\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -353.03288916094306 SOC: 1.0000 Cumulative_SOC_deviation: 267.9071 Fuel Consumption: 85.1258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.907\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -328.80529847483336 SOC: 1.0000 Cumulative_SOC_deviation: 243.6589 Fuel Consumption: 85.1464\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.903\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -299.998664048266 SOC: 0.9972 Cumulative_SOC_deviation: 216.6476 Fuel Consumption: 83.3511\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.672\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -252.09743722137034 SOC: 0.9326 Cumulative_SOC_deviation: 172.6672 Fuel Consumption: 79.4302\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.022\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -258.10595331276335 SOC: 0.9459 Cumulative_SOC_deviation: 177.6336 Fuel Consumption: 80.4723\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.207\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -214.4258770545451 SOC: 0.9108 Cumulative_SOC_deviation: 137.1006 Fuel Consumption: 77.3253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.844\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -232.30793288272 SOC: 0.9139 Cumulative_SOC_deviation: 154.5286 Fuel Consumption: 77.7793\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.664\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -168.9162055678501 SOC: 0.8562 Cumulative_SOC_deviation: 95.9761 Fuel Consumption: 72.9401\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.160\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -162.81390396295603 SOC: 0.8316 Cumulative_SOC_deviation: 91.2152 Fuel Consumption: 71.5987\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.363\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -177.2059976504702 SOC: 0.8642 Cumulative_SOC_deviation: 103.2032 Fuel Consumption: 74.0028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.476\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -156.06569273659787 SOC: 0.7686 Cumulative_SOC_deviation: 89.1927 Fuel Consumption: 66.8730\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.190\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -152.00921406293205 SOC: 0.7521 Cumulative_SOC_deviation: 86.0648 Fuel Consumption: 65.9444\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.489\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -137.0582361636016 SOC: 0.7095 Cumulative_SOC_deviation: 74.1680 Fuel Consumption: 62.8902\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.301\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -137.62191125663398 SOC: 0.7520 Cumulative_SOC_deviation: 72.3069 Fuel Consumption: 65.3150\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.485\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -134.07703711904594 SOC: 0.6898 Cumulative_SOC_deviation: 73.2711 Fuel Consumption: 60.8059\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.475\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -161.0935018636047 SOC: 0.6321 Cumulative_SOC_deviation: 103.7544 Fuel Consumption: 57.3391\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.626\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -153.7463110954508 SOC: 0.6888 Cumulative_SOC_deviation: 92.7134 Fuel Consumption: 61.0329\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.596\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -186.22332817799497 SOC: 0.5616 Cumulative_SOC_deviation: 134.3013 Fuel Consumption: 51.9220\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.396\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -186.97577170801628 SOC: 0.5647 Cumulative_SOC_deviation: 134.8577 Fuel Consumption: 52.1181\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.574\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -200.6225064706683 SOC: 0.5299 Cumulative_SOC_deviation: 151.7650 Fuel Consumption: 48.8575\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.571\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -170.43796721904067 SOC: 0.5955 Cumulative_SOC_deviation: 115.8023 Fuel Consumption: 54.6357\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.734\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -227.02425052627825 SOC: 0.4906 Cumulative_SOC_deviation: 180.5915 Fuel Consumption: 46.4328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.744\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -191.87796528480962 SOC: 0.5492 Cumulative_SOC_deviation: 140.9052 Fuel Consumption: 50.9728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.568\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -237.11860659536887 SOC: 0.4738 Cumulative_SOC_deviation: 191.8311 Fuel Consumption: 45.2875\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.117\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -246.41738293950092 SOC: 0.4569 Cumulative_SOC_deviation: 202.3371 Fuel Consumption: 44.0802\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.338\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -261.99908007714424 SOC: 0.4608 Cumulative_SOC_deviation: 217.6712 Fuel Consumption: 44.3279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.395\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -247.99052133280253 SOC: 0.4352 Cumulative_SOC_deviation: 205.5715 Fuel Consumption: 42.4190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.299\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -263.3189342271628 SOC: 0.4524 Cumulative_SOC_deviation: 219.5482 Fuel Consumption: 43.7707\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.282\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -286.548139424514 SOC: 0.4543 Cumulative_SOC_deviation: 242.1274 Fuel Consumption: 44.4207\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.288\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -323.891064565812 SOC: 0.3688 Cumulative_SOC_deviation: 286.4247 Fuel Consumption: 37.4663\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.298\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -290.56724706345034 SOC: 0.4179 Cumulative_SOC_deviation: 249.2626 Fuel Consumption: 41.3047\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.438\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -278.96362522173695 SOC: 0.3847 Cumulative_SOC_deviation: 239.8774 Fuel Consumption: 39.0863\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.771\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -339.0889219233242 SOC: 0.3406 Cumulative_SOC_deviation: 303.2116 Fuel Consumption: 35.8773\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.400\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -350.8245401728578 SOC: 0.3684 Cumulative_SOC_deviation: 312.3883 Fuel Consumption: 38.4362\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.310\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -361.74351380809355 SOC: 0.2820 Cumulative_SOC_deviation: 330.5197 Fuel Consumption: 31.2238\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.649\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -375.0597432194836 SOC: 0.2610 Cumulative_SOC_deviation: 344.6923 Fuel Consumption: 30.3674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.419\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -351.6975150670546 SOC: 0.3293 Cumulative_SOC_deviation: 316.5837 Fuel Consumption: 35.1138\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.918\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -364.873997030851 SOC: 0.2819 Cumulative_SOC_deviation: 333.0827 Fuel Consumption: 31.7913\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.548\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -331.8224131435217 SOC: 0.3073 Cumulative_SOC_deviation: 298.2460 Fuel Consumption: 33.5764\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.775\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -350.1032449758665 SOC: 0.3057 Cumulative_SOC_deviation: 316.7332 Fuel Consumption: 33.3700\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.987\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -359.6057055783038 SOC: 0.3235 Cumulative_SOC_deviation: 325.0388 Fuel Consumption: 34.5669\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.157\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -375.96049842764154 SOC: 0.2968 Cumulative_SOC_deviation: 342.7143 Fuel Consumption: 33.2462\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.383\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -422.57003174494406 SOC: 0.1799 Cumulative_SOC_deviation: 397.7847 Fuel Consumption: 24.7853\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.626\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -436.8081675481014 SOC: 0.1794 Cumulative_SOC_deviation: 412.3427 Fuel Consumption: 24.4655\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.641\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -419.5311615340945 SOC: 0.2166 Cumulative_SOC_deviation: 392.0838 Fuel Consumption: 27.4474\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.057\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -335.83407818581406 SOC: 0.2913 Cumulative_SOC_deviation: 303.6816 Fuel Consumption: 32.1525\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.782\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -445.9691953353644 SOC: 0.1823 Cumulative_SOC_deviation: 420.6061 Fuel Consumption: 25.3631\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.429\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -451.3417114050797 SOC: 0.1305 Cumulative_SOC_deviation: 429.8272 Fuel Consumption: 21.5145\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.434\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -461.38636243586683 SOC: 0.1261 Cumulative_SOC_deviation: 440.1092 Fuel Consumption: 21.2772\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.293\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -452.66683913927096 SOC: 0.1436 Cumulative_SOC_deviation: 430.4714 Fuel Consumption: 22.1955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.053\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -429.67532930701594 SOC: 0.1746 Cumulative_SOC_deviation: 405.3543 Fuel Consumption: 24.3210\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.280\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -455.74076783866235 SOC: 0.1294 Cumulative_SOC_deviation: 434.5874 Fuel Consumption: 21.1533\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.726\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -472.59642556261304 SOC: 0.1410 Cumulative_SOC_deviation: 450.1224 Fuel Consumption: 22.4741\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.990\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -444.92196976000986 SOC: 0.1452 Cumulative_SOC_deviation: 422.7575 Fuel Consumption: 22.1645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.774\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -463.7684735442284 SOC: 0.1198 Cumulative_SOC_deviation: 442.9453 Fuel Consumption: 20.8232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.361\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -500.350253402591 SOC: 0.0728 Cumulative_SOC_deviation: 482.5709 Fuel Consumption: 17.7793\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.347\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -492.40937547027914 SOC: 0.0969 Cumulative_SOC_deviation: 472.8863 Fuel Consumption: 19.5231\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.787\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -484.87302399351273 SOC: 0.0880 Cumulative_SOC_deviation: 466.3302 Fuel Consumption: 18.5429\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.928\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -498.6171474576254 SOC: 0.0793 Cumulative_SOC_deviation: 480.8482 Fuel Consumption: 17.7690\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.911\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -518.1224443169567 SOC: 0.0603 Cumulative_SOC_deviation: 501.1067 Fuel Consumption: 17.0158\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.950\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -472.51345748970715 SOC: 0.0799 Cumulative_SOC_deviation: 454.7445 Fuel Consumption: 17.7690\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.803\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -506.04172481133696 SOC: 0.1107 Cumulative_SOC_deviation: 485.4249 Fuel Consumption: 20.6168\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.060\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -516.224087505476 SOC: 0.0914 Cumulative_SOC_deviation: 497.2376 Fuel Consumption: 18.9865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.932\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -477.3372819902152 SOC: 0.0844 Cumulative_SOC_deviation: 459.2278 Fuel Consumption: 18.1095\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.032\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -487.33119385701525 SOC: 0.0690 Cumulative_SOC_deviation: 469.9130 Fuel Consumption: 17.4182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.859\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -499.84881662718925 SOC: 0.0694 Cumulative_SOC_deviation: 482.6164 Fuel Consumption: 17.2324\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.061\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -516.5359372167945 SOC: 0.0481 Cumulative_SOC_deviation: 500.7893 Fuel Consumption: 15.7466\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.121\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -510.1588122334739 SOC: 0.0554 Cumulative_SOC_deviation: 494.1645 Fuel Consumption: 15.9943\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.001\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -546.5596056444874 SOC: 0.0422 Cumulative_SOC_deviation: 530.8233 Fuel Consumption: 15.7363\n",
      "\n",
      "battery power is 3655.3643776957547(+) but condition is not avail\n",
      "elapsed_time: 87.836\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -1502.6557062446423 SOC: -0.0011 Cumulative_SOC_deviation: 490.5959 Fuel Consumption: 12.6609\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.056\n",
      "Episode: 107 Exploration P: 0.0680 Total reward: -499.33797254750556 SOC: 0.0549 Cumulative_SOC_deviation: 483.0857 Fuel Consumption: 16.2522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.224\n",
      "Episode: 108 Exploration P: 0.0665 Total reward: -504.45208132583537 SOC: 0.0488 Cumulative_SOC_deviation: 488.9015 Fuel Consumption: 15.5506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.929\n",
      "Episode: 109 Exploration P: 0.0649 Total reward: -507.5695665521245 SOC: 0.0704 Cumulative_SOC_deviation: 489.9038 Fuel Consumption: 17.6658\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.261\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -530.6093231988131 SOC: 0.0170 Cumulative_SOC_deviation: 516.8747 Fuel Consumption: 13.7346\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.585\n",
      "Episode: 111 Exploration P: 0.0620 Total reward: -535.1037961566425 SOC: 0.0139 Cumulative_SOC_deviation: 521.8232 Fuel Consumption: 13.2806\n",
      "\n",
      "battery power is 7139.380133788138(+) but condition is not avail\n",
      "elapsed_time: 90.321\n",
      "Episode: 112 Exploration P: 0.0606 Total reward: -1542.0689579718978 SOC: -0.0001 Cumulative_SOC_deviation: 529.3061 Fuel Consumption: 13.3630\n",
      "\n",
      "battery power is 5967.407130477593(+) but condition is not avail\n",
      "elapsed_time: 85.092\n",
      "Episode: 113 Exploration P: 0.0593 Total reward: -1498.4579397952903 SOC: -0.0001 Cumulative_SOC_deviation: 488.1824 Fuel Consumption: 10.8757\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.258\n",
      "Episode: 114 Exploration P: 0.0580 Total reward: -532.8582485047749 SOC: 0.0233 Cumulative_SOC_deviation: 518.3395 Fuel Consumption: 14.5188\n",
      "\n",
      "battery power is 5967.407130477593(+) but condition is not avail\n",
      "elapsed_time: 85.100\n",
      "Episode: 115 Exploration P: 0.0568 Total reward: -1506.1893161089004 SOC: -0.0013 Cumulative_SOC_deviation: 496.0388 Fuel Consumption: 10.7518\n",
      "\n",
      "battery power is 6096.252213667332(+) but condition is not avail\n",
      "elapsed_time: 84.233\n",
      "Episode: 116 Exploration P: 0.0556 Total reward: -1491.5672538283668 SOC: -0.0010 Cumulative_SOC_deviation: 481.1791 Fuel Consumption: 10.9892\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.399\n",
      "Episode: 117 Exploration P: 0.0544 Total reward: -545.7670451547212 SOC: 0.0164 Cumulative_SOC_deviation: 531.9396 Fuel Consumption: 13.8275\n",
      "\n",
      "battery power is 4630.42179071836(+) but condition is not avail\n",
      "elapsed_time: 90.409\n",
      "Episode: 118 Exploration P: 0.0532 Total reward: -1540.4350662395095 SOC: -0.0007 Cumulative_SOC_deviation: 527.8792 Fuel Consumption: 13.1566\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.534\n",
      "Episode: 119 Exploration P: 0.0520 Total reward: -553.2047610294163 SOC: 0.0131 Cumulative_SOC_deviation: 539.3154 Fuel Consumption: 13.8894\n",
      "\n",
      "battery power is 4874.784648177997(+) but condition is not avail\n",
      "elapsed_time: 87.522\n",
      "Episode: 120 Exploration P: 0.0509 Total reward: -1505.821781496035 SOC: -0.0004 Cumulative_SOC_deviation: 494.4217 Fuel Consumption: 12.0005\n",
      "\n",
      "battery power is 1108.3759136997508(+) but condition is not avail\n",
      "elapsed_time: 88.996\n",
      "Episode: 121 Exploration P: 0.0499 Total reward: -1512.943395250661 SOC: -0.0015 Cumulative_SOC_deviation: 500.5844 Fuel Consumption: 12.9605\n",
      "\n",
      "battery power is 7740.857214091175(+) but condition is not avail\n",
      "elapsed_time: 74.795\n",
      "Episode: 122 Exploration P: 0.0490 Total reward: -1411.0965652088782 SOC: -0.0006 Cumulative_SOC_deviation: 403.7429 Fuel Consumption: 7.9543\n",
      "\n",
      "battery power is 9054.264064879882(+) but condition is not avail\n",
      "elapsed_time: 81.050\n",
      "Episode: 123 Exploration P: 0.0480 Total reward: -1481.7443497254217 SOC: -0.0003 Cumulative_SOC_deviation: 472.2537 Fuel Consumption: 10.0910\n",
      "\n",
      "battery power is 3166.30880951183(+) but condition is not avail\n",
      "elapsed_time: 74.585\n",
      "Episode: 124 Exploration P: 0.0472 Total reward: -1417.4794686910777 SOC: -0.0006 Cumulative_SOC_deviation: 409.1248 Fuel Consumption: 8.9553\n",
      "\n",
      "battery power is 13127.960802209038(+) but condition is not avail\n",
      "elapsed_time: 86.872\n",
      "Episode: 125 Exploration P: 0.0462 Total reward: -1518.270071548616 SOC: -0.0001 Cumulative_SOC_deviation: 506.3124 Fuel Consumption: 12.5577\n",
      "\n",
      "battery power is 2427.3413585361527(+) but condition is not avail\n",
      "elapsed_time: 81.617\n",
      "Episode: 126 Exploration P: 0.0454 Total reward: -1477.4470075792378 SOC: -0.0006 Cumulative_SOC_deviation: 467.5025 Fuel Consumption: 10.5450\n",
      "\n",
      "battery power is 7575.488724445846(+) but condition is not avail\n",
      "elapsed_time: 81.450\n",
      "Episode: 127 Exploration P: 0.0445 Total reward: -1469.534469437079 SOC: -0.0013 Cumulative_SOC_deviation: 460.1067 Fuel Consumption: 10.0291\n",
      "\n",
      "battery power is 4244.303456832675(+) but condition is not avail\n",
      "elapsed_time: 86.790\n",
      "Episode: 128 Exploration P: 0.0436 Total reward: -1493.846579342972 SOC: -0.0005 Cumulative_SOC_deviation: 482.3124 Fuel Consumption: 12.1347\n",
      "\n",
      "battery power is 6389.012279833689(+) but condition is not avail\n",
      "elapsed_time: 85.121\n",
      "Episode: 129 Exploration P: 0.0428 Total reward: -1512.0214426342818 SOC: -0.0008 Cumulative_SOC_deviation: 501.1068 Fuel Consumption: 11.5154\n",
      "\n",
      "battery power is 7798.224226085201(+) but condition is not avail\n",
      "elapsed_time: 71.366\n",
      "Episode: 130 Exploration P: 0.0421 Total reward: -1385.9124430857946 SOC: -0.0005 Cumulative_SOC_deviation: 379.2091 Fuel Consumption: 7.3039\n",
      "\n",
      "battery power is 5059.565524123393(+) but condition is not avail\n",
      "elapsed_time: 75.688\n",
      "Episode: 131 Exploration P: 0.0414 Total reward: -1427.2814198335946 SOC: -0.0003 Cumulative_SOC_deviation: 418.9884 Fuel Consumption: 8.8933\n",
      "\n",
      "battery power is 6795.419827853896(+) but condition is not avail\n",
      "elapsed_time: 74.962\n",
      "Episode: 132 Exploration P: 0.0407 Total reward: -1417.8509467955055 SOC: -0.0010 Cumulative_SOC_deviation: 410.5595 Fuel Consumption: 7.8924\n",
      "\n",
      "battery power is 9649.296144334441(+) but condition is not avail\n",
      "elapsed_time: 69.958\n",
      "Episode: 133 Exploration P: 0.0400 Total reward: -1392.9301781723489 SOC: -0.0004 Cumulative_SOC_deviation: 386.7324 Fuel Consumption: 6.7982\n",
      "\n",
      "battery power is 7798.224226085201(+) but condition is not avail\n",
      "elapsed_time: 72.008\n",
      "Episode: 134 Exploration P: 0.0394 Total reward: -1393.2463696083432 SOC: -0.0005 Cumulative_SOC_deviation: 386.5121 Fuel Consumption: 7.3348\n",
      "\n",
      "battery power is 4361.155321061076(+) but condition is not avail\n",
      "elapsed_time: 75.098\n",
      "Episode: 135 Exploration P: 0.0387 Total reward: -1422.5782136508255 SOC: -0.0011 Cumulative_SOC_deviation: 414.8432 Fuel Consumption: 8.3361\n",
      "\n",
      "battery power is 5487.512149474795(+) but condition is not avail\n",
      "elapsed_time: 75.736\n",
      "Episode: 136 Exploration P: 0.0381 Total reward: -1415.9651327660404 SOC: -0.0006 Cumulative_SOC_deviation: 407.8685 Fuel Consumption: 8.6973\n",
      "\n",
      "battery power is 4361.155321061076(+) but condition is not avail\n",
      "elapsed_time: 75.252\n",
      "Episode: 137 Exploration P: 0.0375 Total reward: -1429.630794034267 SOC: -0.0005 Cumulative_SOC_deviation: 421.8333 Fuel Consumption: 8.3980\n",
      "\n",
      "battery power is 6829.007597550478(+) but condition is not avail\n",
      "elapsed_time: 71.391\n",
      "Episode: 138 Exploration P: 0.0369 Total reward: -1387.138218377853 SOC: -0.0006 Cumulative_SOC_deviation: 380.8270 Fuel Consumption: 6.9118\n",
      "\n",
      "battery power is 3262.287183941105(+) but condition is not avail\n",
      "elapsed_time: 74.909\n",
      "Episode: 139 Exploration P: 0.0363 Total reward: -1405.8926672677665 SOC: -0.0004 Cumulative_SOC_deviation: 398.7761 Fuel Consumption: 7.7170\n",
      "\n",
      "battery power is 6829.007597550478(+) but condition is not avail\n",
      "elapsed_time: 71.840\n",
      "Episode: 140 Exploration P: 0.0357 Total reward: -1392.0971411460155 SOC: -0.0005 Cumulative_SOC_deviation: 385.7446 Fuel Consumption: 6.9530\n",
      "\n",
      "battery power is 5623.904326151556(+) but condition is not avail\n",
      "elapsed_time: 67.214\n",
      "Episode: 141 Exploration P: 0.0352 Total reward: -1350.7788133337556 SOC: -0.0003 Cumulative_SOC_deviation: 345.7886 Fuel Consumption: 5.5905\n",
      "\n",
      "battery power is 8196.414194400148(+) but condition is not avail\n",
      "elapsed_time: 63.882\n",
      "Episode: 142 Exploration P: 0.0347 Total reward: -1348.5169192822593 SOC: -0.0004 Cumulative_SOC_deviation: 344.7034 Fuel Consumption: 4.4140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.804\n",
      "Episode: 143 Exploration P: 0.0341 Total reward: -287.81261140910976 SOC: 0.3889 Cumulative_SOC_deviation: 253.9587 Fuel Consumption: 33.8540\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.182\n",
      "Episode: 144 Exploration P: 0.0334 Total reward: -355.35764589743957 SOC: 0.3136 Cumulative_SOC_deviation: 325.2063 Fuel Consumption: 30.1514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.216\n",
      "Episode: 145 Exploration P: 0.0328 Total reward: -327.8497488176062 SOC: 0.3321 Cumulative_SOC_deviation: 296.2166 Fuel Consumption: 31.6331\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.080\n",
      "Episode: 146 Exploration P: 0.0322 Total reward: -359.3869089264185 SOC: 0.2839 Cumulative_SOC_deviation: 330.1365 Fuel Consumption: 29.2504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.918\n",
      "Episode: 147 Exploration P: 0.0316 Total reward: -428.6135056983125 SOC: 0.2559 Cumulative_SOC_deviation: 401.5473 Fuel Consumption: 27.0662\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.716\n",
      "Episode: 148 Exploration P: 0.0310 Total reward: -428.9358232371271 SOC: 0.2312 Cumulative_SOC_deviation: 403.0457 Fuel Consumption: 25.8901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.170\n",
      "Episode: 149 Exploration P: 0.0304 Total reward: -446.4501045727574 SOC: 0.2241 Cumulative_SOC_deviation: 420.0961 Fuel Consumption: 26.3540\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.188\n",
      "Episode: 150 Exploration P: 0.0299 Total reward: -442.220091582241 SOC: 0.2110 Cumulative_SOC_deviation: 417.5212 Fuel Consumption: 24.6989\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.076\n",
      "Episode: 151 Exploration P: 0.0293 Total reward: -484.273704315926 SOC: 0.1653 Cumulative_SOC_deviation: 462.6853 Fuel Consumption: 21.5884\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.271\n",
      "Episode: 152 Exploration P: 0.0288 Total reward: -453.64854940943184 SOC: 0.2556 Cumulative_SOC_deviation: 425.5860 Fuel Consumption: 28.0626\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.955\n",
      "Episode: 153 Exploration P: 0.0283 Total reward: -472.3410220370353 SOC: 0.1679 Cumulative_SOC_deviation: 449.3539 Fuel Consumption: 22.9871\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.173\n",
      "Episode: 154 Exploration P: 0.0278 Total reward: -442.9870462631392 SOC: 0.3052 Cumulative_SOC_deviation: 409.4974 Fuel Consumption: 33.4896\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.364\n",
      "Episode: 155 Exploration P: 0.0273 Total reward: -450.237707208665 SOC: 0.1797 Cumulative_SOC_deviation: 425.1686 Fuel Consumption: 25.0691\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.846\n",
      "Episode: 156 Exploration P: 0.0268 Total reward: -481.90485441896533 SOC: 0.2343 Cumulative_SOC_deviation: 452.2274 Fuel Consumption: 29.6774\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.830\n",
      "Episode: 157 Exploration P: 0.0264 Total reward: -466.6442161939353 SOC: 0.1309 Cumulative_SOC_deviation: 446.1154 Fuel Consumption: 20.5288\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.190\n",
      "Episode: 158 Exploration P: 0.0259 Total reward: -395.52734194466535 SOC: 0.5312 Cumulative_SOC_deviation: 342.3046 Fuel Consumption: 53.2227\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.967\n",
      "Episode: 159 Exploration P: 0.0255 Total reward: -304.25347005492824 SOC: 0.2310 Cumulative_SOC_deviation: 276.6503 Fuel Consumption: 27.6032\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.340\n",
      "Episode: 160 Exploration P: 0.0251 Total reward: -463.82183012832314 SOC: 0.2938 Cumulative_SOC_deviation: 429.7143 Fuel Consumption: 34.1075\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.292\n",
      "Episode: 161 Exploration P: 0.0247 Total reward: -538.3816994519083 SOC: 0.1127 Cumulative_SOC_deviation: 517.9173 Fuel Consumption: 20.4644\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.432\n",
      "Episode: 162 Exploration P: 0.0243 Total reward: -370.36189332220636 SOC: 0.2505 Cumulative_SOC_deviation: 340.3975 Fuel Consumption: 29.9644\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.216\n",
      "Episode: 163 Exploration P: 0.0239 Total reward: -528.1742314065579 SOC: 0.1226 Cumulative_SOC_deviation: 506.2762 Fuel Consumption: 21.8980\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.622\n",
      "Episode: 164 Exploration P: 0.0235 Total reward: -519.560795923873 SOC: 0.1955 Cumulative_SOC_deviation: 493.3968 Fuel Consumption: 26.1640\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.744\n",
      "Episode: 165 Exploration P: 0.0232 Total reward: -481.64930418013665 SOC: 0.1820 Cumulative_SOC_deviation: 456.5757 Fuel Consumption: 25.0736\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.479\n",
      "Episode: 166 Exploration P: 0.0228 Total reward: -492.25175924794496 SOC: 0.2074 Cumulative_SOC_deviation: 465.4390 Fuel Consumption: 26.8128\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.848\n",
      "Episode: 167 Exploration P: 0.0225 Total reward: -530.9913480169962 SOC: 0.0993 Cumulative_SOC_deviation: 512.0572 Fuel Consumption: 18.9342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.577\n",
      "Episode: 168 Exploration P: 0.0221 Total reward: -489.60518027288595 SOC: 0.1924 Cumulative_SOC_deviation: 463.7865 Fuel Consumption: 25.8186\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.766\n",
      "Episode: 169 Exploration P: 0.0218 Total reward: -441.73439731301113 SOC: 0.3040 Cumulative_SOC_deviation: 409.5374 Fuel Consumption: 32.1970\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.900\n",
      "Episode: 170 Exploration P: 0.0215 Total reward: -478.88683871843716 SOC: 0.1982 Cumulative_SOC_deviation: 454.3049 Fuel Consumption: 24.5819\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.050\n",
      "Episode: 171 Exploration P: 0.0212 Total reward: -473.54540453298654 SOC: 0.2234 Cumulative_SOC_deviation: 447.0653 Fuel Consumption: 26.4801\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.248\n",
      "Episode: 172 Exploration P: 0.0209 Total reward: -510.8442767154614 SOC: 0.2037 Cumulative_SOC_deviation: 485.8078 Fuel Consumption: 25.0365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.081\n",
      "Episode: 173 Exploration P: 0.0206 Total reward: -489.8506589278525 SOC: 0.2258 Cumulative_SOC_deviation: 463.3987 Fuel Consumption: 26.4519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.106\n",
      "Episode: 174 Exploration P: 0.0203 Total reward: -397.3827626167352 SOC: 0.3735 Cumulative_SOC_deviation: 361.9523 Fuel Consumption: 35.4305\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.317\n",
      "Episode: 175 Exploration P: 0.0200 Total reward: -481.0848194958808 SOC: 0.2836 Cumulative_SOC_deviation: 451.8607 Fuel Consumption: 29.2242\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.880\n",
      "Episode: 176 Exploration P: 0.0197 Total reward: -447.91930988821923 SOC: 0.2122 Cumulative_SOC_deviation: 423.5795 Fuel Consumption: 24.3398\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.559\n",
      "Episode: 177 Exploration P: 0.0195 Total reward: -496.62590528225735 SOC: 0.2554 Cumulative_SOC_deviation: 468.9564 Fuel Consumption: 27.6695\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.445\n",
      "Episode: 178 Exploration P: 0.0192 Total reward: -463.7024250847364 SOC: 0.2561 Cumulative_SOC_deviation: 435.7243 Fuel Consumption: 27.9781\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.604\n",
      "Episode: 179 Exploration P: 0.0190 Total reward: -411.6738783727394 SOC: 0.3476 Cumulative_SOC_deviation: 377.7709 Fuel Consumption: 33.9029\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.977\n",
      "Episode: 180 Exploration P: 0.0187 Total reward: -411.5551292812934 SOC: 0.4059 Cumulative_SOC_deviation: 374.2334 Fuel Consumption: 37.3218\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.872\n",
      "Episode: 181 Exploration P: 0.0185 Total reward: -430.91645298183846 SOC: 0.3174 Cumulative_SOC_deviation: 399.1445 Fuel Consumption: 31.7720\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.640\n",
      "Episode: 182 Exploration P: 0.0183 Total reward: -430.8359123941602 SOC: 0.2866 Cumulative_SOC_deviation: 400.4631 Fuel Consumption: 30.3728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.684\n",
      "Episode: 183 Exploration P: 0.0180 Total reward: -438.37866212989456 SOC: 0.1668 Cumulative_SOC_deviation: 415.5193 Fuel Consumption: 22.8594\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.747\n",
      "Episode: 184 Exploration P: 0.0178 Total reward: -460.09958129960245 SOC: 0.8073 Cumulative_SOC_deviation: 387.8066 Fuel Consumption: 72.2930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.396\n",
      "Episode: 185 Exploration P: 0.0176 Total reward: -384.1264983128498 SOC: 0.3050 Cumulative_SOC_deviation: 353.1754 Fuel Consumption: 30.9511\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.783\n",
      "Episode: 186 Exploration P: 0.0174 Total reward: -431.43428313938654 SOC: 0.2508 Cumulative_SOC_deviation: 403.6585 Fuel Consumption: 27.7758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.435\n",
      "Episode: 187 Exploration P: 0.0172 Total reward: -456.6884967482324 SOC: 0.3103 Cumulative_SOC_deviation: 424.9699 Fuel Consumption: 31.7186\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.068\n",
      "Episode: 188 Exploration P: 0.0170 Total reward: -352.58330987036516 SOC: 0.3750 Cumulative_SOC_deviation: 316.6912 Fuel Consumption: 35.8921\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.916\n",
      "Episode: 189 Exploration P: 0.0168 Total reward: -464.2074004804843 SOC: 0.2226 Cumulative_SOC_deviation: 438.4781 Fuel Consumption: 25.7293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.022\n",
      "Episode: 190 Exploration P: 0.0166 Total reward: -438.42071485751995 SOC: 0.1575 Cumulative_SOC_deviation: 416.5535 Fuel Consumption: 21.8672\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.234\n",
      "Episode: 191 Exploration P: 0.0164 Total reward: -475.8289333716386 SOC: 0.2766 Cumulative_SOC_deviation: 445.3534 Fuel Consumption: 30.4756\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.693\n",
      "Episode: 192 Exploration P: 0.0163 Total reward: -442.4676300908389 SOC: 0.2471 Cumulative_SOC_deviation: 413.7622 Fuel Consumption: 28.7054\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.178\n",
      "Episode: 193 Exploration P: 0.0161 Total reward: -440.6924266589001 SOC: 0.2946 Cumulative_SOC_deviation: 406.8481 Fuel Consumption: 33.8443\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.675\n",
      "Episode: 194 Exploration P: 0.0159 Total reward: -435.1563395661729 SOC: 0.1860 Cumulative_SOC_deviation: 410.2059 Fuel Consumption: 24.9504\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.101\n",
      "Episode: 195 Exploration P: 0.0158 Total reward: -519.6003085989719 SOC: 0.1459 Cumulative_SOC_deviation: 496.9677 Fuel Consumption: 22.6326\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.611\n",
      "Episode: 196 Exploration P: 0.0156 Total reward: -426.31505752861875 SOC: 0.3547 Cumulative_SOC_deviation: 388.5336 Fuel Consumption: 37.7814\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.784\n",
      "Episode: 197 Exploration P: 0.0155 Total reward: -387.42271376305956 SOC: 0.3031 Cumulative_SOC_deviation: 353.8309 Fuel Consumption: 33.5918\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.230\n",
      "Episode: 198 Exploration P: 0.0153 Total reward: -446.91504614732145 SOC: 0.2623 Cumulative_SOC_deviation: 415.8006 Fuel Consumption: 31.1145\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.724\n",
      "Episode: 199 Exploration P: 0.0152 Total reward: -416.6749446656306 SOC: 0.2986 Cumulative_SOC_deviation: 382.1261 Fuel Consumption: 34.5488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.552\n",
      "Episode: 200 Exploration P: 0.0150 Total reward: -454.2814789209106 SOC: 0.2484 Cumulative_SOC_deviation: 421.7061 Fuel Consumption: 32.5754\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 2\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.740\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -1125.897438075976 SOC: 1.0000 Cumulative_SOC_deviation: 488.2190 Fuel Consumption: 149.4594\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.397\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -1140.372598101664 SOC: 1.0000 Cumulative_SOC_deviation: 494.3164 Fuel Consumption: 151.7397\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.982\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -1142.6046446779008 SOC: 1.0000 Cumulative_SOC_deviation: 494.7670 Fuel Consumption: 153.0707\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 41.797\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -1134.6357173067818 SOC: 1.0000 Cumulative_SOC_deviation: 492.7017 Fuel Consumption: 149.2324\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.403\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -1132.6191269516928 SOC: 1.0000 Cumulative_SOC_deviation: 493.0863 Fuel Consumption: 146.4465\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.559\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -1117.8874530944145 SOC: 1.0000 Cumulative_SOC_deviation: 487.2734 Fuel Consumption: 143.3407\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.804\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -1116.9427280069397 SOC: 1.0000 Cumulative_SOC_deviation: 486.6204 Fuel Consumption: 143.7019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.049\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -1118.9878179831303 SOC: 1.0000 Cumulative_SOC_deviation: 488.4942 Fuel Consumption: 141.9994\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.804\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -1097.188267390763 SOC: 1.0000 Cumulative_SOC_deviation: 481.5721 Fuel Consumption: 134.0441\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.195\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -1115.9987065654227 SOC: 1.0000 Cumulative_SOC_deviation: 488.7331 Fuel Consumption: 138.5325\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.118\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -1072.703981985995 SOC: 1.0000 Cumulative_SOC_deviation: 472.2293 Fuel Consumption: 128.2453\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.354\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -1062.870462452894 SOC: 1.0000 Cumulative_SOC_deviation: 468.4579 Fuel Consumption: 125.9547\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.485\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -1061.080967431507 SOC: 1.0000 Cumulative_SOC_deviation: 465.2209 Fuel Consumption: 130.6391\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.510\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -1058.7004802442707 SOC: 1.0000 Cumulative_SOC_deviation: 467.0384 Fuel Consumption: 124.6236\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.917\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -1014.1695272404218 SOC: 1.0000 Cumulative_SOC_deviation: 447.2183 Fuel Consumption: 119.7328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.656\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -1050.253434637234 SOC: 1.0000 Cumulative_SOC_deviation: 465.9258 Fuel Consumption: 118.4018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.905\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -1008.4723460061131 SOC: 1.0000 Cumulative_SOC_deviation: 445.1333 Fuel Consumption: 118.2058\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.980\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1020.2843361708899 SOC: 1.0000 Cumulative_SOC_deviation: 453.7581 Fuel Consumption: 112.7681\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.528\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -982.3058165886298 SOC: 1.0000 Cumulative_SOC_deviation: 435.4395 Fuel Consumption: 111.4267\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.924\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -979.2528915571799 SOC: 1.0000 Cumulative_SOC_deviation: 434.2381 Fuel Consumption: 110.7767\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.874\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -926.9571564982734 SOC: 1.0000 Cumulative_SOC_deviation: 409.4935 Fuel Consumption: 107.9702\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.933\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -896.7067466801817 SOC: 1.0000 Cumulative_SOC_deviation: 396.3752 Fuel Consumption: 103.9564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.719\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -850.3181482969346 SOC: 1.0000 Cumulative_SOC_deviation: 375.3167 Fuel Consumption: 99.6847\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.915\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -899.4258085990683 SOC: 1.0000 Cumulative_SOC_deviation: 399.9995 Fuel Consumption: 99.4267\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.931\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -909.2795021089951 SOC: 1.0000 Cumulative_SOC_deviation: 403.1929 Fuel Consumption: 102.8936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.813\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -860.3267509185397 SOC: 1.0000 Cumulative_SOC_deviation: 380.2798 Fuel Consumption: 99.7672\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.646\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -860.0948309763733 SOC: 1.0000 Cumulative_SOC_deviation: 380.3805 Fuel Consumption: 99.3339\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.529\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -798.9374892316179 SOC: 1.0000 Cumulative_SOC_deviation: 351.4579 Fuel Consumption: 96.0218\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.023\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -820.7349854295871 SOC: 1.0000 Cumulative_SOC_deviation: 361.0978 Fuel Consumption: 98.5394\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.107\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -787.942629884531 SOC: 1.0000 Cumulative_SOC_deviation: 347.0954 Fuel Consumption: 93.7518\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.092\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -723.4467628574799 SOC: 1.0000 Cumulative_SOC_deviation: 315.2447 Fuel Consumption: 92.9573\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.184\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -668.7487251952156 SOC: 1.0000 Cumulative_SOC_deviation: 289.1442 Fuel Consumption: 90.4603\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.715\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -727.8073600924138 SOC: 1.0000 Cumulative_SOC_deviation: 319.3081 Fuel Consumption: 89.1911\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.971\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -673.8566569159402 SOC: 1.0000 Cumulative_SOC_deviation: 292.7300 Fuel Consumption: 88.3967\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.549\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -559.5516047788566 SOC: 1.0000 Cumulative_SOC_deviation: 237.3780 Fuel Consumption: 84.7956\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.130\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -443.4363304612297 SOC: 0.9684 Cumulative_SOC_deviation: 180.9300 Fuel Consumption: 81.5764\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.007\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -507.9516085493411 SOC: 0.9869 Cumulative_SOC_deviation: 212.6872 Fuel Consumption: 82.5772\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.827\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -398.1112702585329 SOC: 0.9497 Cumulative_SOC_deviation: 159.0104 Fuel Consumption: 80.0905\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.619\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -383.1877286093374 SOC: 0.9295 Cumulative_SOC_deviation: 151.9974 Fuel Consumption: 79.1929\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.545\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -295.11691440167493 SOC: 0.8718 Cumulative_SOC_deviation: 110.0721 Fuel Consumption: 74.9728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.173\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -485.1741618567901 SOC: 0.9759 Cumulative_SOC_deviation: 201.4894 Fuel Consumption: 82.1954\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.056\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -388.9709927512483 SOC: 0.9332 Cumulative_SOC_deviation: 154.6672 Fuel Consumption: 79.6366\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.784\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -242.6723951617475 SOC: 0.8213 Cumulative_SOC_deviation: 86.0218 Fuel Consumption: 70.6288\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.436\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -257.3137616436496 SOC: 0.7154 Cumulative_SOC_deviation: 97.2015 Fuel Consumption: 62.9108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.432\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -334.78420175758885 SOC: 0.8773 Cumulative_SOC_deviation: 129.6839 Fuel Consumption: 75.4164\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.034\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -271.1734666457051 SOC: 0.8150 Cumulative_SOC_deviation: 100.6489 Fuel Consumption: 69.8756\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.006\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -264.5962605360864 SOC: 0.7877 Cumulative_SOC_deviation: 97.9846 Fuel Consumption: 68.6271\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.135\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -255.12881791541548 SOC: 0.7206 Cumulative_SOC_deviation: 95.6292 Fuel Consumption: 63.8704\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.703\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -221.88121079666428 SOC: 0.6919 Cumulative_SOC_deviation: 80.4345 Fuel Consumption: 61.0123\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.858\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -236.47611663544424 SOC: 0.7546 Cumulative_SOC_deviation: 85.2194 Fuel Consumption: 66.0372\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.213\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -207.40712157933612 SOC: 0.6695 Cumulative_SOC_deviation: 73.9661 Fuel Consumption: 59.4749\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.130\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -179.00844345314013 SOC: 0.7127 Cumulative_SOC_deviation: 58.1004 Fuel Consumption: 62.8077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.423\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -288.16295186807054 SOC: 0.6409 Cumulative_SOC_deviation: 115.3036 Fuel Consumption: 57.5557\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.859\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -355.7666726539431 SOC: 0.5516 Cumulative_SOC_deviation: 152.3402 Fuel Consumption: 51.0863\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.374\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -216.2001328165322 SOC: 0.6556 Cumulative_SOC_deviation: 78.8579 Fuel Consumption: 58.4844\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.978\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -247.93114224639834 SOC: 0.5942 Cumulative_SOC_deviation: 97.2049 Fuel Consumption: 53.5213\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.642\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -205.28651320809587 SOC: 0.6107 Cumulative_SOC_deviation: 75.1294 Fuel Consumption: 55.0278\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.476\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -347.2694749806034 SOC: 0.5316 Cumulative_SOC_deviation: 148.7932 Fuel Consumption: 49.6830\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.304\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -351.1969314016972 SOC: 0.5242 Cumulative_SOC_deviation: 151.3606 Fuel Consumption: 48.4758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.446\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -303.88771314974804 SOC: 0.5676 Cumulative_SOC_deviation: 125.6681 Fuel Consumption: 52.5514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.490\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -516.7553323338266 SOC: 0.4693 Cumulative_SOC_deviation: 235.7081 Fuel Consumption: 45.3391\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.209\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -384.9645636604439 SOC: 0.5121 Cumulative_SOC_deviation: 168.6623 Fuel Consumption: 47.6400\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.472\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -456.6483624342444 SOC: 0.4538 Cumulative_SOC_deviation: 206.6710 Fuel Consumption: 43.3064\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.374\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -475.54280180719144 SOC: 0.4289 Cumulative_SOC_deviation: 216.8456 Fuel Consumption: 41.8515\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.943\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -573.6642419470811 SOC: 0.4147 Cumulative_SOC_deviation: 266.2417 Fuel Consumption: 41.1808\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.584\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -567.0198055782367 SOC: 0.3885 Cumulative_SOC_deviation: 263.9358 Fuel Consumption: 39.1482\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.751\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -334.1147777536104 SOC: 0.4973 Cumulative_SOC_deviation: 143.8513 Fuel Consumption: 46.4121\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.427\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -631.6949482607077 SOC: 0.3315 Cumulative_SOC_deviation: 298.3731 Fuel Consumption: 34.9487\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.374\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -556.6883529891696 SOC: 0.4149 Cumulative_SOC_deviation: 257.8157 Fuel Consumption: 41.0570\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.251\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -709.6646678686086 SOC: 0.3100 Cumulative_SOC_deviation: 337.7243 Fuel Consumption: 34.2161\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.545\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -659.4674469574097 SOC: 0.2867 Cumulative_SOC_deviation: 313.6988 Fuel Consumption: 32.0699\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.646\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -657.1888365415457 SOC: 0.3148 Cumulative_SOC_deviation: 311.5483 Fuel Consumption: 34.0923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.475\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -683.2171250139836 SOC: 0.2972 Cumulative_SOC_deviation: 325.1867 Fuel Consumption: 32.8438\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.488\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -669.90083966385 SOC: 0.3168 Cumulative_SOC_deviation: 317.8217 Fuel Consumption: 34.2574\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.674\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -680.8069952774765 SOC: 0.2926 Cumulative_SOC_deviation: 324.4408 Fuel Consumption: 31.9255\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.648\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -563.8421796060467 SOC: 0.3230 Cumulative_SOC_deviation: 265.0297 Fuel Consumption: 33.7827\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.633\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -674.0621798253917 SOC: 0.2600 Cumulative_SOC_deviation: 322.0641 Fuel Consumption: 29.9341\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.602\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -747.243516199517 SOC: 0.2490 Cumulative_SOC_deviation: 358.8611 Fuel Consumption: 29.5214\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.722\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -807.1184605332674 SOC: 0.2195 Cumulative_SOC_deviation: 389.6601 Fuel Consumption: 27.7982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.139\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -815.6693965491799 SOC: 0.2048 Cumulative_SOC_deviation: 394.5547 Fuel Consumption: 26.5600\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.514\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -713.3610112900748 SOC: 0.2517 Cumulative_SOC_deviation: 341.6619 Fuel Consumption: 30.0373\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.484\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -807.772184392649 SOC: 0.1886 Cumulative_SOC_deviation: 391.2097 Fuel Consumption: 25.3528\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.659\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -921.9845752019273 SOC: 0.1133 Cumulative_SOC_deviation: 450.6890 Fuel Consumption: 20.6065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.187\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -849.9400306121129 SOC: 0.1647 Cumulative_SOC_deviation: 413.1139 Fuel Consumption: 23.7122\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.755\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -870.8364690538516 SOC: 0.1587 Cumulative_SOC_deviation: 423.8510 Fuel Consumption: 23.1344\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.675\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -951.431848720772 SOC: 0.0967 Cumulative_SOC_deviation: 465.9234 Fuel Consumption: 19.5850\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.319\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -782.7681831531069 SOC: 0.2084 Cumulative_SOC_deviation: 378.2279 Fuel Consumption: 26.3124\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.895\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -859.3522374486079 SOC: 0.1796 Cumulative_SOC_deviation: 417.1596 Fuel Consumption: 25.0330\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.869\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -901.9750476918234 SOC: 0.1317 Cumulative_SOC_deviation: 440.2561 Fuel Consumption: 21.4629\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.559\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -890.4105554732491 SOC: 0.1472 Cumulative_SOC_deviation: 433.9734 Fuel Consumption: 22.4637\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.640\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -946.525004452816 SOC: 0.0875 Cumulative_SOC_deviation: 463.9292 Fuel Consumption: 18.6667\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.086\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -859.781125101139 SOC: 0.1753 Cumulative_SOC_deviation: 417.4876 Fuel Consumption: 24.8060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.523\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -913.0540536287725 SOC: 0.1335 Cumulative_SOC_deviation: 445.5841 Fuel Consumption: 21.8859\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.749\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -958.9960449506136 SOC: 0.1094 Cumulative_SOC_deviation: 469.2206 Fuel Consumption: 20.5549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.400\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -992.1632364228036 SOC: 0.0645 Cumulative_SOC_deviation: 487.5686 Fuel Consumption: 17.0261\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.056\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -913.2677222437641 SOC: 0.1006 Cumulative_SOC_deviation: 447.0168 Fuel Consumption: 19.2342\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.141\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -973.8374224118223 SOC: 0.0808 Cumulative_SOC_deviation: 477.8227 Fuel Consumption: 18.1920\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.052\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -888.0919776232247 SOC: 0.1115 Cumulative_SOC_deviation: 433.9233 Fuel Consumption: 20.2453\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.553\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -1046.5855393424504 SOC: 0.0550 Cumulative_SOC_deviation: 515.0635 Fuel Consumption: 16.4586\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.166\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -968.4340230107385 SOC: 0.1059 Cumulative_SOC_deviation: 474.1769 Fuel Consumption: 20.0803\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.632\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -884.9491654359588 SOC: 0.1397 Cumulative_SOC_deviation: 431.3614 Fuel Consumption: 22.2264\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.640\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -1064.4040089509258 SOC: 0.0117 Cumulative_SOC_deviation: 525.5204 Fuel Consumption: 13.3631\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.311\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -994.1550486937817 SOC: 0.0511 Cumulative_SOC_deviation: 489.1526 Fuel Consumption: 15.8498\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.064\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -1017.6944734675197 SOC: 0.0313 Cumulative_SOC_deviation: 501.4124 Fuel Consumption: 14.8696\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.953\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -1068.4222297127014 SOC: 0.0131 Cumulative_SOC_deviation: 527.3645 Fuel Consumption: 13.6933\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.929\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -1057.212534197585 SOC: 0.0671 Cumulative_SOC_deviation: 519.8043 Fuel Consumption: 17.6039\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.498\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -1065.4472624479858 SOC: 0.0320 Cumulative_SOC_deviation: 525.2269 Fuel Consumption: 14.9934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.620\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -1081.1306343280728 SOC: 0.0136 Cumulative_SOC_deviation: 533.6103 Fuel Consumption: 13.9100\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.751\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -1045.6320898005854 SOC: 0.0322 Cumulative_SOC_deviation: 515.1904 Fuel Consumption: 15.2514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.440\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -1022.7899700868817 SOC: 0.0446 Cumulative_SOC_deviation: 503.6506 Fuel Consumption: 15.4887\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.683\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -1059.7187472216292 SOC: 0.0236 Cumulative_SOC_deviation: 522.8270 Fuel Consumption: 14.0648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.141\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -1032.005129587223 SOC: 0.0365 Cumulative_SOC_deviation: 508.3769 Fuel Consumption: 15.2514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.036\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -1076.2139131477616 SOC: 0.0279 Cumulative_SOC_deviation: 530.6412 Fuel Consumption: 14.9315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.826\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -1012.5362669615763 SOC: 0.0331 Cumulative_SOC_deviation: 499.0449 Fuel Consumption: 14.4466\n",
      "\n",
      "battery power is 7107.928009405758(+) but condition is not avail\n",
      "elapsed_time: 78.742\n",
      "Episode: 115 Exploration P: 0.0566 Total reward: -1996.1786350918017 SOC: -0.0004 Cumulative_SOC_deviation: 492.6688 Fuel Consumption: 12.0418\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.066\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -1072.85132799153 SOC: 0.0304 Cumulative_SOC_deviation: 528.8774 Fuel Consumption: 15.0966\n",
      "\n",
      "battery power is 7107.928009405758(+) but condition is not avail\n",
      "elapsed_time: 78.591\n",
      "Episode: 117 Exploration P: 0.0542 Total reward: -2032.7718871141126 SOC: -0.0004 Cumulative_SOC_deviation: 510.8262 Fuel Consumption: 12.3204\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.440\n",
      "Episode: 118 Exploration P: 0.0530 Total reward: -1065.9565555492002 SOC: 0.0322 Cumulative_SOC_deviation: 525.5383 Fuel Consumption: 14.8799\n",
      "\n",
      "battery power is 5967.407130477593(+) but condition is not avail\n",
      "elapsed_time: 77.563\n",
      "Episode: 119 Exploration P: 0.0519 Total reward: -1979.6015328235194 SOC: -0.0006 Cumulative_SOC_deviation: 484.9120 Fuel Consumption: 10.9788\n",
      "\n",
      "battery power is 5687.527779835772(+) but condition is not avail\n",
      "elapsed_time: 77.846\n",
      "Episode: 120 Exploration P: 0.0508 Total reward: -1966.7509226762684 SOC: -0.0010 Cumulative_SOC_deviation: 478.3683 Fuel Consumption: 11.2162\n",
      "\n",
      "battery power is 7740.857214091175(+) but condition is not avail\n",
      "elapsed_time: 67.351\n",
      "Episode: 121 Exploration P: 0.0499 Total reward: -1842.0055830227175 SOC: -0.0005 Cumulative_SOC_deviation: 417.2031 Fuel Consumption: 8.8004\n",
      "\n",
      "battery power is 3166.30880951183(+) but condition is not avail\n",
      "elapsed_time: 68.782\n",
      "Episode: 122 Exploration P: 0.0490 Total reward: -1855.78108567415 SOC: -0.0002 Cumulative_SOC_deviation: 423.3940 Fuel Consumption: 10.1935\n",
      "\n",
      "battery power is 3986.119664329538(+) but condition is not avail\n",
      "elapsed_time: 64.927\n",
      "Episode: 123 Exploration P: 0.0482 Total reward: -1786.512502993576 SOC: -0.0010 Cumulative_SOC_deviation: 390.1228 Fuel Consumption: 7.4690\n",
      "\n",
      "battery power is 13127.960802209038(+) but condition is not avail\n",
      "elapsed_time: 78.782\n",
      "Episode: 124 Exploration P: 0.0472 Total reward: -1954.1770703625089 SOC: -0.0004 Cumulative_SOC_deviation: 471.6319 Fuel Consumption: 12.1140\n",
      "\n",
      "battery power is 2920.3968960421703(+) but condition is not avail\n",
      "elapsed_time: 68.355\n",
      "Episode: 125 Exploration P: 0.0464 Total reward: -1824.4937112933603 SOC: -0.0000 Cumulative_SOC_deviation: 408.5344 Fuel Consumption: 8.6250\n",
      "\n",
      "battery power is 4683.758077049461(+) but condition is not avail\n",
      "elapsed_time: 73.962\n",
      "Episode: 126 Exploration P: 0.0455 Total reward: -1947.2959815760191 SOC: -0.0002 Cumulative_SOC_deviation: 469.0840 Fuel Consumption: 10.3283\n",
      "\n",
      "battery power is 5692.786734617356(+) but condition is not avail\n",
      "elapsed_time: 67.636\n",
      "Episode: 127 Exploration P: 0.0447 Total reward: -1835.0728125840083 SOC: -0.0009 Cumulative_SOC_deviation: 414.2014 Fuel Consumption: 7.8717\n",
      "\n",
      "battery power is 7107.928009405758(+) but condition is not avail\n",
      "elapsed_time: 79.013\n",
      "Episode: 128 Exploration P: 0.0438 Total reward: -1992.477462388625 SOC: -0.0004 Cumulative_SOC_deviation: 490.7563 Fuel Consumption: 12.1656\n",
      "\n",
      "battery power is 4896.724091333236(+) but condition is not avail\n",
      "elapsed_time: 68.879\n",
      "Episode: 129 Exploration P: 0.0431 Total reward: -1842.1978078487239 SOC: -0.0001 Cumulative_SOC_deviation: 417.1646 Fuel Consumption: 9.0688\n",
      "\n",
      "battery power is 7678.588641419948(+) but condition is not avail\n",
      "elapsed_time: 64.903\n",
      "Episode: 130 Exploration P: 0.0424 Total reward: -1770.4311998556823 SOC: -0.0012 Cumulative_SOC_deviation: 382.2680 Fuel Consumption: 7.0975\n",
      "\n",
      "battery power is 5687.527779835772(+) but condition is not avail\n",
      "elapsed_time: 77.938\n",
      "Episode: 131 Exploration P: 0.0416 Total reward: -1986.0963934192916 SOC: -0.0008 Cumulative_SOC_deviation: 488.0409 Fuel Consumption: 11.2162\n",
      "\n",
      "battery power is 8883.14402613377(+) but condition is not avail\n",
      "elapsed_time: 64.917\n",
      "Episode: 132 Exploration P: 0.0409 Total reward: -1772.3310531049935 SOC: -0.0003 Cumulative_SOC_deviation: 383.5215 Fuel Consumption: 6.4887\n",
      "\n",
      "battery power is 9176.02872117076(+) but condition is not avail\n",
      "elapsed_time: 65.118\n",
      "Episode: 133 Exploration P: 0.0403 Total reward: -1779.721045665843 SOC: -0.0012 Cumulative_SOC_deviation: 387.0059 Fuel Consumption: 6.9117\n",
      "\n",
      "battery power is 10549.085687990506(+) but condition is not avail\n",
      "elapsed_time: 59.215\n",
      "Episode: 134 Exploration P: 0.0397 Total reward: -1690.1258500893737 SOC: -0.0008 Cumulative_SOC_deviation: 343.1575 Fuel Consumption: 5.0124\n",
      "\n",
      "battery power is 8593.399190081254(+) but condition is not avail\n",
      "elapsed_time: 65.294\n",
      "Episode: 135 Exploration P: 0.0390 Total reward: -1789.5082701654694 SOC: -0.0003 Cumulative_SOC_deviation: 391.8470 Fuel Consumption: 7.0149\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery power is 3023.017414106708(+) but condition is not avail\n",
      "elapsed_time: 68.249\n",
      "Episode: 136 Exploration P: 0.0384 Total reward: -1821.5619380139212 SOC: -0.0007 Cumulative_SOC_deviation: 407.4716 Fuel Consumption: 7.8201\n",
      "\n",
      "battery power is 5727.992250018656(+) but condition is not avail\n",
      "elapsed_time: 67.758\n",
      "Episode: 137 Exploration P: 0.0378 Total reward: -1820.3449844857219 SOC: -0.0002 Cumulative_SOC_deviation: 406.7440 Fuel Consumption: 8.0575\n",
      "\n",
      "battery power is 8593.399190081254(+) but condition is not avail\n",
      "elapsed_time: 64.918\n",
      "Episode: 138 Exploration P: 0.0372 Total reward: -1786.1354934000992 SOC: -0.0001 Cumulative_SOC_deviation: 390.1862 Fuel Consumption: 6.9633\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.521\n",
      "Episode: 139 Exploration P: 0.0365 Total reward: -680.9479152780656 SOC: 0.4458 Cumulative_SOC_deviation: 320.2579 Fuel Consumption: 40.4322\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.463\n",
      "Episode: 140 Exploration P: 0.0357 Total reward: -438.7381123140906 SOC: 0.4348 Cumulative_SOC_deviation: 200.3296 Fuel Consumption: 38.0789\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.342\n",
      "Episode: 141 Exploration P: 0.0350 Total reward: -537.628265557227 SOC: 0.4062 Cumulative_SOC_deviation: 249.2240 Fuel Consumption: 39.1803\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.451\n",
      "Episode: 142 Exploration P: 0.0344 Total reward: -605.8833753698889 SOC: 0.3783 Cumulative_SOC_deviation: 284.0569 Fuel Consumption: 37.7696\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.340\n",
      "Episode: 143 Exploration P: 0.0337 Total reward: -715.9043482588181 SOC: 0.4245 Cumulative_SOC_deviation: 336.7231 Fuel Consumption: 42.4582\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.946\n",
      "Episode: 144 Exploration P: 0.0331 Total reward: -574.1386970237884 SOC: 0.3123 Cumulative_SOC_deviation: 272.7484 Fuel Consumption: 28.6419\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.615\n",
      "Episode: 145 Exploration P: 0.0324 Total reward: -851.6898371853887 SOC: 0.2673 Cumulative_SOC_deviation: 409.3333 Fuel Consumption: 33.0232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.872\n",
      "Episode: 146 Exploration P: 0.0318 Total reward: -734.9409020248274 SOC: 0.2184 Cumulative_SOC_deviation: 353.9594 Fuel Consumption: 27.0221\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.360\n",
      "Episode: 147 Exploration P: 0.0312 Total reward: -1027.960815347642 SOC: 0.1333 Cumulative_SOC_deviation: 504.0593 Fuel Consumption: 19.8422\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.449\n",
      "Episode: 148 Exploration P: 0.0307 Total reward: -872.4408962285515 SOC: 0.2321 Cumulative_SOC_deviation: 421.8236 Fuel Consumption: 28.7936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.376\n",
      "Episode: 149 Exploration P: 0.0301 Total reward: -1045.240220102107 SOC: 0.1108 Cumulative_SOC_deviation: 512.7810 Fuel Consumption: 19.6783\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.226\n",
      "Episode: 150 Exploration P: 0.0296 Total reward: -657.3771485207309 SOC: 0.3372 Cumulative_SOC_deviation: 311.3459 Fuel Consumption: 34.6854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.859\n",
      "Episode: 151 Exploration P: 0.0290 Total reward: -769.663530287162 SOC: 0.3175 Cumulative_SOC_deviation: 367.6430 Fuel Consumption: 34.3775\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.177\n",
      "Episode: 152 Exploration P: 0.0285 Total reward: -768.1335602019304 SOC: 0.2629 Cumulative_SOC_deviation: 368.6743 Fuel Consumption: 30.7850\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.034\n",
      "Episode: 153 Exploration P: 0.0280 Total reward: -948.4292640840026 SOC: 0.2073 Cumulative_SOC_deviation: 460.7799 Fuel Consumption: 26.8695\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.017\n",
      "Episode: 154 Exploration P: 0.0275 Total reward: -972.91661843052 SOC: 0.1845 Cumulative_SOC_deviation: 473.3635 Fuel Consumption: 26.1896\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.309\n",
      "Episode: 155 Exploration P: 0.0270 Total reward: -997.3726818316032 SOC: 0.1865 Cumulative_SOC_deviation: 486.3837 Fuel Consumption: 24.6052\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.637\n",
      "Episode: 156 Exploration P: 0.0266 Total reward: -988.4903047891455 SOC: 0.1461 Cumulative_SOC_deviation: 483.4111 Fuel Consumption: 21.6681\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.682\n",
      "Episode: 157 Exploration P: 0.0261 Total reward: -974.1970470892259 SOC: 0.2237 Cumulative_SOC_deviation: 474.1712 Fuel Consumption: 25.8546\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.636\n",
      "Episode: 158 Exploration P: 0.0257 Total reward: -975.3428971480707 SOC: 0.1196 Cumulative_SOC_deviation: 478.2187 Fuel Consumption: 18.9056\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.450\n",
      "Episode: 159 Exploration P: 0.0253 Total reward: -980.4380352474949 SOC: 0.1709 Cumulative_SOC_deviation: 478.8273 Fuel Consumption: 22.7835\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.546\n",
      "Episode: 160 Exploration P: 0.0249 Total reward: -984.9536172207701 SOC: 0.1315 Cumulative_SOC_deviation: 482.6845 Fuel Consumption: 19.5846\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.814\n",
      "Episode: 161 Exploration P: 0.0245 Total reward: -1016.2279421858051 SOC: 0.1575 Cumulative_SOC_deviation: 497.7761 Fuel Consumption: 20.6757\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.372\n",
      "Episode: 162 Exploration P: 0.0241 Total reward: -1033.3613644280038 SOC: 0.1322 Cumulative_SOC_deviation: 507.2322 Fuel Consumption: 18.8969\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.513\n",
      "Episode: 163 Exploration P: 0.0237 Total reward: -1065.456945235856 SOC: 0.1497 Cumulative_SOC_deviation: 522.4241 Fuel Consumption: 20.6087\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.695\n",
      "Episode: 164 Exploration P: 0.0233 Total reward: -1069.3688773379722 SOC: 0.1199 Cumulative_SOC_deviation: 524.9023 Fuel Consumption: 19.5642\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.851\n",
      "Episode: 165 Exploration P: 0.0230 Total reward: -1060.8342837019834 SOC: 0.1330 Cumulative_SOC_deviation: 520.0601 Fuel Consumption: 20.7141\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.346\n",
      "Episode: 166 Exploration P: 0.0226 Total reward: -1131.7663570226591 SOC: 0.0919 Cumulative_SOC_deviation: 556.4881 Fuel Consumption: 18.7901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.091\n",
      "Episode: 167 Exploration P: 0.0223 Total reward: -1125.274794447513 SOC: 0.0532 Cumulative_SOC_deviation: 555.0240 Fuel Consumption: 15.2267\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.858\n",
      "Episode: 168 Exploration P: 0.0219 Total reward: -1007.7870615726745 SOC: 0.2904 Cumulative_SOC_deviation: 487.4789 Fuel Consumption: 32.8293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.408\n",
      "Episode: 169 Exploration P: 0.0216 Total reward: -798.817868432077 SOC: 0.2786 Cumulative_SOC_deviation: 385.5054 Fuel Consumption: 27.8070\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.689\n",
      "Episode: 170 Exploration P: 0.0213 Total reward: -877.5555006567195 SOC: 0.2339 Cumulative_SOC_deviation: 426.0762 Fuel Consumption: 25.4031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.593\n",
      "Episode: 171 Exploration P: 0.0210 Total reward: -890.7154370756393 SOC: 0.2405 Cumulative_SOC_deviation: 432.6471 Fuel Consumption: 25.4212\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.032\n",
      "Episode: 172 Exploration P: 0.0207 Total reward: -906.8141923938214 SOC: 0.2185 Cumulative_SOC_deviation: 441.7396 Fuel Consumption: 23.3350\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.782\n",
      "Episode: 173 Exploration P: 0.0204 Total reward: -945.8797749722922 SOC: 0.1762 Cumulative_SOC_deviation: 462.5305 Fuel Consumption: 20.8188\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.465\n",
      "Episode: 174 Exploration P: 0.0201 Total reward: -976.2207874407185 SOC: 0.1409 Cumulative_SOC_deviation: 478.7637 Fuel Consumption: 18.6934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.925\n",
      "Episode: 175 Exploration P: 0.0198 Total reward: -1080.8112567787994 SOC: 0.0993 Cumulative_SOC_deviation: 532.0262 Fuel Consumption: 16.7588\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.813\n",
      "Episode: 176 Exploration P: 0.0196 Total reward: -1098.1998361250335 SOC: 0.0861 Cumulative_SOC_deviation: 540.7258 Fuel Consumption: 16.7482\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.937\n",
      "Episode: 177 Exploration P: 0.0193 Total reward: -1080.2031320153935 SOC: 0.1327 Cumulative_SOC_deviation: 530.1923 Fuel Consumption: 19.8185\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.677\n",
      "Episode: 178 Exploration P: 0.0191 Total reward: -1051.64020264841 SOC: 0.0887 Cumulative_SOC_deviation: 517.7751 Fuel Consumption: 16.0901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.942\n",
      "Episode: 179 Exploration P: 0.0188 Total reward: -1070.9764560932674 SOC: 0.1249 Cumulative_SOC_deviation: 525.7363 Fuel Consumption: 19.5038\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.965\n",
      "Episode: 180 Exploration P: 0.0186 Total reward: -1117.6383584127263 SOC: 0.1558 Cumulative_SOC_deviation: 547.9492 Fuel Consumption: 21.7400\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.584\n",
      "Episode: 181 Exploration P: 0.0183 Total reward: -1071.3538932733277 SOC: 0.1107 Cumulative_SOC_deviation: 526.0819 Fuel Consumption: 19.1901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.343\n",
      "Episode: 182 Exploration P: 0.0181 Total reward: -1052.1553330810925 SOC: 0.1606 Cumulative_SOC_deviation: 514.5514 Fuel Consumption: 23.0526\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.681\n",
      "Episode: 183 Exploration P: 0.0179 Total reward: -1090.896441086896 SOC: 0.1784 Cumulative_SOC_deviation: 533.2158 Fuel Consumption: 24.4648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.912\n",
      "Episode: 184 Exploration P: 0.0177 Total reward: -371.5858364814151 SOC: 0.5359 Cumulative_SOC_deviation: 163.8010 Fuel Consumption: 43.9838\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.589\n",
      "Episode: 185 Exploration P: 0.0175 Total reward: -576.4480892823666 SOC: 0.2194 Cumulative_SOC_deviation: 277.0451 Fuel Consumption: 22.3579\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.012\n",
      "Episode: 186 Exploration P: 0.0173 Total reward: -1032.8772494007035 SOC: 0.1459 Cumulative_SOC_deviation: 506.0095 Fuel Consumption: 20.8582\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.954\n",
      "Episode: 187 Exploration P: 0.0171 Total reward: -936.0231931602862 SOC: 0.2415 Cumulative_SOC_deviation: 454.2023 Fuel Consumption: 27.6187\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.906\n",
      "Episode: 188 Exploration P: 0.0169 Total reward: -771.5604289308504 SOC: 0.2725 Cumulative_SOC_deviation: 372.2380 Fuel Consumption: 27.0845\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.927\n",
      "Episode: 189 Exploration P: 0.0167 Total reward: -224.85771248466799 SOC: 0.5197 Cumulative_SOC_deviation: 92.2955 Fuel Consumption: 40.2668\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.257\n",
      "Episode: 190 Exploration P: 0.0165 Total reward: -246.0342447532176 SOC: 0.5286 Cumulative_SOC_deviation: 102.8653 Fuel Consumption: 40.3037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.749\n",
      "Episode: 191 Exploration P: 0.0163 Total reward: -473.1212749581748 SOC: 0.2683 Cumulative_SOC_deviation: 224.2174 Fuel Consumption: 24.6865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.021\n",
      "Episode: 192 Exploration P: 0.0162 Total reward: -936.9663755476433 SOC: 0.3081 Cumulative_SOC_deviation: 453.0497 Fuel Consumption: 30.8671\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.799\n",
      "Episode: 193 Exploration P: 0.0160 Total reward: -282.28019981321677 SOC: 0.5130 Cumulative_SOC_deviation: 121.3942 Fuel Consumption: 39.4918\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.643\n",
      "Episode: 194 Exploration P: 0.0158 Total reward: -753.2029723627157 SOC: 0.4137 Cumulative_SOC_deviation: 358.6615 Fuel Consumption: 35.8799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.579\n",
      "Episode: 195 Exploration P: 0.0157 Total reward: -293.7982787445025 SOC: 0.4998 Cumulative_SOC_deviation: 127.7162 Fuel Consumption: 38.3659\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.864\n",
      "Episode: 196 Exploration P: 0.0155 Total reward: -658.6598030224575 SOC: 0.2542 Cumulative_SOC_deviation: 317.3955 Fuel Consumption: 23.8688\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.011\n",
      "Episode: 197 Exploration P: 0.0154 Total reward: -494.70654982007574 SOC: 0.2690 Cumulative_SOC_deviation: 235.1573 Fuel Consumption: 24.3920\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.758\n",
      "Episode: 198 Exploration P: 0.0152 Total reward: -942.6734718934995 SOC: 0.2342 Cumulative_SOC_deviation: 457.8850 Fuel Consumption: 26.9035\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.642\n",
      "Episode: 199 Exploration P: 0.0151 Total reward: -896.5599048093693 SOC: 0.2447 Cumulative_SOC_deviation: 434.4556 Fuel Consumption: 27.6487\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.836\n",
      "Episode: 200 Exploration P: 0.0150 Total reward: -712.2805786892103 SOC: 0.3023 Cumulative_SOC_deviation: 340.5398 Fuel Consumption: 31.2010\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 3\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.248\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -1646.9164641151608 SOC: 1.0000 Cumulative_SOC_deviation: 498.7465 Fuel Consumption: 150.6769\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.891\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -1638.9228023747041 SOC: 1.0000 Cumulative_SOC_deviation: 496.5875 Fuel Consumption: 149.1602\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.876\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -1632.7517785046066 SOC: 1.0000 Cumulative_SOC_deviation: 494.1900 Fuel Consumption: 150.1817\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 40.265\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -1645.8120453949514 SOC: 1.0000 Cumulative_SOC_deviation: 498.8427 Fuel Consumption: 149.2840\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.177\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -1624.6289328205758 SOC: 1.0000 Cumulative_SOC_deviation: 491.7232 Fuel Consumption: 149.4594\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.588\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -1638.3077405948281 SOC: 1.0000 Cumulative_SOC_deviation: 498.1263 Fuel Consumption: 143.9289\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.842\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -1613.371922134036 SOC: 1.0000 Cumulative_SOC_deviation: 490.2064 Fuel Consumption: 142.7526\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.568\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -1586.6748923501566 SOC: 1.0000 Cumulative_SOC_deviation: 482.2429 Fuel Consumption: 139.9461\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.577\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -1585.622917978187 SOC: 1.0000 Cumulative_SOC_deviation: 483.3299 Fuel Consumption: 135.6331\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.605\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -1559.1249359825124 SOC: 1.0000 Cumulative_SOC_deviation: 474.8481 Fuel Consumption: 134.5806\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.173\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -1541.5407398774748 SOC: 1.0000 Cumulative_SOC_deviation: 470.3934 Fuel Consumption: 130.3605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.716\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -1529.230560398801 SOC: 1.0000 Cumulative_SOC_deviation: 467.7999 Fuel Consumption: 125.8309\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.085\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -1514.2099666801948 SOC: 1.0000 Cumulative_SOC_deviation: 463.6907 Fuel Consumption: 123.1378\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.453\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -1510.5754229145014 SOC: 1.0000 Cumulative_SOC_deviation: 462.0355 Fuel Consumption: 124.4689\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.527\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -1461.058063051897 SOC: 1.0000 Cumulative_SOC_deviation: 446.3517 Fuel Consumption: 122.0028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.555\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -1463.948262376496 SOC: 1.0000 Cumulative_SOC_deviation: 448.9729 Fuel Consumption: 117.0295\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.435\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -1467.4201171344498 SOC: 1.0000 Cumulative_SOC_deviation: 450.5670 Fuel Consumption: 115.7191\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.678\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1429.5844976164324 SOC: 1.0000 Cumulative_SOC_deviation: 438.9422 Fuel Consumption: 112.7578\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.895\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -1448.9530344996 SOC: 1.0000 Cumulative_SOC_deviation: 447.4345 Fuel Consumption: 106.6494\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.587\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1415.158214162889 SOC: 1.0000 Cumulative_SOC_deviation: 434.5015 Fuel Consumption: 111.6537\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.446\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1356.17678947704 SOC: 1.0000 Cumulative_SOC_deviation: 416.2099 Fuel Consumption: 107.5471\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.627\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1349.6151012653359 SOC: 1.0000 Cumulative_SOC_deviation: 414.8103 Fuel Consumption: 105.1843\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.646\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1372.7059630323224 SOC: 1.0000 Cumulative_SOC_deviation: 423.5150 Fuel Consumption: 102.1610\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.592\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1256.6836622515173 SOC: 1.0000 Cumulative_SOC_deviation: 385.0300 Fuel Consumption: 101.5935\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.650\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1319.63515134967 SOC: 1.0000 Cumulative_SOC_deviation: 405.5220 Fuel Consumption: 103.0690\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.566\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1213.418072999677 SOC: 1.0000 Cumulative_SOC_deviation: 370.7629 Fuel Consumption: 101.1292\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.980\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1258.9849485499067 SOC: 1.0000 Cumulative_SOC_deviation: 387.6544 Fuel Consumption: 96.0218\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.992\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -1125.6798830811638 SOC: 1.0000 Cumulative_SOC_deviation: 342.6003 Fuel Consumption: 97.8790\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.085\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -1107.3587851105156 SOC: 1.0000 Cumulative_SOC_deviation: 337.2224 Fuel Consumption: 95.6916\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.523\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -1041.8490366551007 SOC: 1.0000 Cumulative_SOC_deviation: 317.0574 Fuel Consumption: 90.6770\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.577\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -1110.8364648349657 SOC: 1.0000 Cumulative_SOC_deviation: 339.3550 Fuel Consumption: 92.7715\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.561\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -1051.8645723763877 SOC: 1.0000 Cumulative_SOC_deviation: 320.6779 Fuel Consumption: 89.8309\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.928\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1071.5687009115682 SOC: 1.0000 Cumulative_SOC_deviation: 326.9330 Fuel Consumption: 90.7698\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.759\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -839.724411599962 SOC: 1.0000 Cumulative_SOC_deviation: 250.6765 Fuel Consumption: 87.6950\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.538\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -857.6976152517838 SOC: 1.0000 Cumulative_SOC_deviation: 257.4723 Fuel Consumption: 85.2806\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.988\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -915.2764121265885 SOC: 1.0000 Cumulative_SOC_deviation: 276.0599 Fuel Consumption: 87.0966\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.706\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -858.4669130073974 SOC: 1.0000 Cumulative_SOC_deviation: 257.1785 Fuel Consumption: 86.9315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.169\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -620.8853045174905 SOC: 0.9667 Cumulative_SOC_deviation: 179.9485 Fuel Consumption: 81.0398\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.349\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -597.3069073636033 SOC: 0.9738 Cumulative_SOC_deviation: 171.7141 Fuel Consumption: 82.1645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.038\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -629.4200530467019 SOC: 0.9541 Cumulative_SOC_deviation: 182.9035 Fuel Consumption: 80.7096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.039\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -614.3329611490959 SOC: 0.9639 Cumulative_SOC_deviation: 177.6612 Fuel Consumption: 81.3494\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.431\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -610.318039721953 SOC: 0.9360 Cumulative_SOC_deviation: 176.9454 Fuel Consumption: 79.4818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.819\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -562.3570244235991 SOC: 0.9245 Cumulative_SOC_deviation: 161.1820 Fuel Consumption: 78.8111\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.047\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -457.62984369523076 SOC: 0.8704 Cumulative_SOC_deviation: 127.7209 Fuel Consumption: 74.4672\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.924\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -504.4627865444278 SOC: 0.8968 Cumulative_SOC_deviation: 142.6130 Fuel Consumption: 76.6237\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.209\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -323.2365562671972 SOC: 0.7605 Cumulative_SOC_deviation: 85.5508 Fuel Consumption: 66.5841\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.365\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -280.4623061257783 SOC: 0.7430 Cumulative_SOC_deviation: 71.8774 Fuel Consumption: 64.8300\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.746\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -351.58030471274134 SOC: 0.8301 Cumulative_SOC_deviation: 93.1931 Fuel Consumption: 72.0011\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.212\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -284.23082931678834 SOC: 0.7318 Cumulative_SOC_deviation: 73.1852 Fuel Consumption: 64.6752\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.239\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -323.2748631064489 SOC: 0.7030 Cumulative_SOC_deviation: 87.0597 Fuel Consumption: 62.0957\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.787\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -281.8601649106652 SOC: 0.7235 Cumulative_SOC_deviation: 72.7217 Fuel Consumption: 63.6950\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.854\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -359.6114333162019 SOC: 0.6310 Cumulative_SOC_deviation: 100.8331 Fuel Consumption: 57.1121\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.446\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -246.97105874147698 SOC: 0.6796 Cumulative_SOC_deviation: 62.3852 Fuel Consumption: 59.8154\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.616\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -356.6563405150879 SOC: 0.6285 Cumulative_SOC_deviation: 99.9994 Fuel Consumption: 56.6581\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.043\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -281.50140229557985 SOC: 0.6515 Cumulative_SOC_deviation: 74.4456 Fuel Consumption: 58.1645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.932\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -423.2337378548561 SOC: 0.6005 Cumulative_SOC_deviation: 122.8007 Fuel Consumption: 54.8317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.883\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -480.94682714174144 SOC: 0.5560 Cumulative_SOC_deviation: 143.2284 Fuel Consumption: 51.2617\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.734\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -445.84662705913183 SOC: 0.5879 Cumulative_SOC_deviation: 130.6134 Fuel Consumption: 54.0063\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.841\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -669.1102147274296 SOC: 0.4658 Cumulative_SOC_deviation: 208.2333 Fuel Consumption: 44.4104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.808\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -500.6183333731344 SOC: 0.5247 Cumulative_SOC_deviation: 150.3840 Fuel Consumption: 49.4663\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.675\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -509.63568220296725 SOC: 0.5337 Cumulative_SOC_deviation: 153.3692 Fuel Consumption: 49.5282\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.720\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -784.5808065405258 SOC: 0.4053 Cumulative_SOC_deviation: 248.2333 Fuel Consumption: 39.8808\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.303\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -696.8984555660074 SOC: 0.4247 Cumulative_SOC_deviation: 218.4178 Fuel Consumption: 41.6452\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.677\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -790.055212377046 SOC: 0.4359 Cumulative_SOC_deviation: 249.0745 Fuel Consumption: 42.8318\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.686\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -825.1893242827304 SOC: 0.4024 Cumulative_SOC_deviation: 261.6595 Fuel Consumption: 40.2109\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.827\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -748.6810160724519 SOC: 0.4196 Cumulative_SOC_deviation: 235.5858 Fuel Consumption: 41.9238\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.550\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -887.2885769940845 SOC: 0.3941 Cumulative_SOC_deviation: 282.4693 Fuel Consumption: 39.8808\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.966\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -927.3852217763699 SOC: 0.3131 Cumulative_SOC_deviation: 297.9948 Fuel Consumption: 33.4010\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.674\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -888.1877035864673 SOC: 0.3711 Cumulative_SOC_deviation: 283.4397 Fuel Consumption: 37.8687\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.273\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -979.2949824386776 SOC: 0.3240 Cumulative_SOC_deviation: 314.8474 Fuel Consumption: 34.7526\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.189\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -1069.739410230573 SOC: 0.2743 Cumulative_SOC_deviation: 346.1753 Fuel Consumption: 31.2135\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.501\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -965.7361555478607 SOC: 0.3252 Cumulative_SOC_deviation: 310.3450 Fuel Consumption: 34.7011\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.649\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -936.1569028341237 SOC: 0.3102 Cumulative_SOC_deviation: 300.9427 Fuel Consumption: 33.3287\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.549\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -959.3961236198469 SOC: 0.2878 Cumulative_SOC_deviation: 309.2532 Fuel Consumption: 31.6366\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.771\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -1157.4708919165787 SOC: 0.2568 Cumulative_SOC_deviation: 375.7046 Fuel Consumption: 30.3571\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.638\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -1067.795290305486 SOC: 0.2668 Cumulative_SOC_deviation: 345.6958 Fuel Consumption: 30.7079\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.007\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -889.4350223982168 SOC: 0.3227 Cumulative_SOC_deviation: 285.0592 Fuel Consumption: 34.2574\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.682\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -1076.5485894652768 SOC: 0.2739 Cumulative_SOC_deviation: 348.4278 Fuel Consumption: 31.2651\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.294\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -1116.350463847336 SOC: 0.2431 Cumulative_SOC_deviation: 362.4036 Fuel Consumption: 29.1396\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.524\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -1199.4988603610616 SOC: 0.2248 Cumulative_SOC_deviation: 390.4740 Fuel Consumption: 28.0768\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.854\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -1225.7938432219473 SOC: 0.2121 Cumulative_SOC_deviation: 399.5898 Fuel Consumption: 27.0244\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.294\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -1220.307811373838 SOC: 0.2014 Cumulative_SOC_deviation: 398.0535 Fuel Consumption: 26.1473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.902\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -1067.5719738226414 SOC: 0.2744 Cumulative_SOC_deviation: 345.4253 Fuel Consumption: 31.2961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.097\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -1146.0086930349153 SOC: 0.2433 Cumulative_SOC_deviation: 372.1693 Fuel Consumption: 29.5007\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.178\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -1235.0824601382856 SOC: 0.1635 Cumulative_SOC_deviation: 403.9896 Fuel Consumption: 23.1138\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.128\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -1258.5924740812836 SOC: 0.1819 Cumulative_SOC_deviation: 411.1040 Fuel Consumption: 25.2806\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.724\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -1357.042389825524 SOC: 0.1316 Cumulative_SOC_deviation: 445.0659 Fuel Consumption: 21.8447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.897\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -1298.2341904470968 SOC: 0.1330 Cumulative_SOC_deviation: 425.6592 Fuel Consumption: 21.2565\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.904\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -1329.562550196723 SOC: 0.1694 Cumulative_SOC_deviation: 435.0289 Fuel Consumption: 24.4758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.909\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -1323.126426012379 SOC: 0.1340 Cumulative_SOC_deviation: 433.8225 Fuel Consumption: 21.6589\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.610\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -1304.8079742936957 SOC: 0.1624 Cumulative_SOC_deviation: 427.0525 Fuel Consumption: 23.6503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.769\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -1380.490263910958 SOC: 0.1249 Cumulative_SOC_deviation: 452.9369 Fuel Consumption: 21.6796\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.686\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -1373.5517928564022 SOC: 0.1078 Cumulative_SOC_deviation: 451.1331 Fuel Consumption: 20.1525\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.375\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -1355.6755657872634 SOC: 0.1307 Cumulative_SOC_deviation: 444.6172 Fuel Consumption: 21.8240\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.998\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -1426.1664027229654 SOC: 0.0773 Cumulative_SOC_deviation: 469.5449 Fuel Consumption: 17.5317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.273\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -1467.1826936389637 SOC: 0.0695 Cumulative_SOC_deviation: 483.2239 Fuel Consumption: 17.5110\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.992\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -1545.1568365497183 SOC: 0.0693 Cumulative_SOC_deviation: 509.1155 Fuel Consumption: 17.8103\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.034\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -1510.9272600269428 SOC: 0.0640 Cumulative_SOC_deviation: 497.9464 Fuel Consumption: 17.0880\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.367\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -1511.6938435261004 SOC: 0.0750 Cumulative_SOC_deviation: 497.8064 Fuel Consumption: 18.2746\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.550\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -1532.3022093992017 SOC: 0.0630 Cumulative_SOC_deviation: 505.1368 Fuel Consumption: 16.8919\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.654\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -1573.8742565469986 SOC: 0.0402 Cumulative_SOC_deviation: 519.4240 Fuel Consumption: 15.6022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.509\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -1542.4242152118466 SOC: 0.0327 Cumulative_SOC_deviation: 509.1642 Fuel Consumption: 14.9315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.405\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -1430.2011730337042 SOC: 0.1051 Cumulative_SOC_deviation: 470.0781 Fuel Consumption: 19.9668\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.213\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -1507.0186453278761 SOC: 0.0641 Cumulative_SOC_deviation: 496.6057 Fuel Consumption: 17.2015\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.361\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -1514.3328073660637 SOC: 0.0663 Cumulative_SOC_deviation: 499.0128 Fuel Consumption: 17.2944\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.490\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -1430.5722351031798 SOC: 0.1065 Cumulative_SOC_deviation: 470.2431 Fuel Consumption: 19.8429\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.372\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -1598.1188264368052 SOC: 0.0151 Cumulative_SOC_deviation: 528.0730 Fuel Consumption: 13.8997\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.585\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -1631.7874040675445 SOC: 0.0348 Cumulative_SOC_deviation: 538.7697 Fuel Consumption: 15.4784\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.613\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -1523.5776806555227 SOC: 0.0650 Cumulative_SOC_deviation: 502.0635 Fuel Consumption: 17.3872\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.784\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -1539.791031176117 SOC: 0.0440 Cumulative_SOC_deviation: 508.0389 Fuel Consumption: 15.6744\n",
      "\n",
      "battery power is 4652.633673326141(+) but condition is not avail\n",
      "elapsed_time: 81.121\n",
      "Episode: 111 Exploration P: 0.0620 Total reward: -2495.894929772426 SOC: -0.0001 Cumulative_SOC_deviation: 495.0148 Fuel Consumption: 12.6506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.447\n",
      "Episode: 112 Exploration P: 0.0606 Total reward: -1501.7623284923402 SOC: 0.0390 Cumulative_SOC_deviation: 495.4693 Fuel Consumption: 15.3545\n",
      "\n",
      "battery power is 2519.560807434138(+) but condition is not avail\n",
      "elapsed_time: 72.897\n",
      "Episode: 113 Exploration P: 0.0594 Total reward: -2338.0607057688057 SOC: -0.0004 Cumulative_SOC_deviation: 443.4084 Fuel Consumption: 9.6367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.665\n",
      "Episode: 114 Exploration P: 0.0581 Total reward: -1481.971495445479 SOC: 0.0624 Cumulative_SOC_deviation: 488.3461 Fuel Consumption: 16.9332\n",
      "\n",
      "battery power is 4054.1977015910556(+) but condition is not avail\n",
      "elapsed_time: 80.525\n",
      "Episode: 115 Exploration P: 0.0568 Total reward: -2475.6776732221815 SOC: -0.0003 Cumulative_SOC_deviation: 488.6303 Fuel Consumption: 11.5878\n",
      "\n",
      "battery power is 3655.3643776957547(+) but condition is not avail\n",
      "elapsed_time: 80.919\n",
      "Episode: 116 Exploration P: 0.0556 Total reward: -2506.46182598714 SOC: -0.0003 Cumulative_SOC_deviation: 498.5099 Fuel Consumption: 12.7332\n",
      "\n",
      "battery power is 4244.303456832675(+) but condition is not avail\n",
      "elapsed_time: 80.845\n",
      "Episode: 117 Exploration P: 0.0545 Total reward: -2500.92676335908 SOC: -0.0006 Cumulative_SOC_deviation: 496.7649 Fuel Consumption: 12.4339\n",
      "\n",
      "battery power is 3655.3643776957547(+) but condition is not avail\n",
      "elapsed_time: 81.164\n",
      "Episode: 118 Exploration P: 0.0533 Total reward: -2489.863053940793 SOC: -0.0017 Cumulative_SOC_deviation: 493.0712 Fuel Consumption: 12.4546\n",
      "\n",
      "battery power is 2792.248321928586(+) but condition is not avail\n",
      "elapsed_time: 70.553\n",
      "Episode: 119 Exploration P: 0.0523 Total reward: -2250.854734683083 SOC: -0.0004 Cumulative_SOC_deviation: 414.6047 Fuel Consumption: 8.8418\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.269\n",
      "Episode: 120 Exploration P: 0.0512 Total reward: -1592.6058021661247 SOC: 0.0204 Cumulative_SOC_deviation: 526.0772 Fuel Consumption: 14.3743\n",
      "\n",
      "battery power is 6389.012279833689(+) but condition is not avail\n",
      "elapsed_time: 79.333\n",
      "Episode: 121 Exploration P: 0.0502 Total reward: -2493.5394130921513 SOC: -0.0011 Cumulative_SOC_deviation: 494.6572 Fuel Consumption: 11.3710\n",
      "\n",
      "battery power is 8843.832174244031(+) but condition is not avail\n",
      "elapsed_time: 75.190\n",
      "Episode: 122 Exploration P: 0.0492 Total reward: -2383.9393907119957 SOC: -0.0005 Cumulative_SOC_deviation: 458.6773 Fuel Consumption: 9.7092\n",
      "\n",
      "battery power is 5514.450688412365(+) but condition is not avail\n",
      "elapsed_time: 80.196\n",
      "Episode: 123 Exploration P: 0.0482 Total reward: -2470.4805845153296 SOC: -0.0006 Cumulative_SOC_deviation: 486.9223 Fuel Consumption: 11.5155\n",
      "\n",
      "battery power is 7107.928009405758(+) but condition is not avail\n",
      "elapsed_time: 80.266\n",
      "Episode: 124 Exploration P: 0.0472 Total reward: -2500.7606159444713 SOC: -0.0001 Cumulative_SOC_deviation: 496.8948 Fuel Consumption: 11.8767\n",
      "\n",
      "battery power is 4355.228047361836(+) but condition is not avail\n",
      "elapsed_time: 79.716\n",
      "Episode: 125 Exploration P: 0.0463 Total reward: -2456.3524469269996 SOC: -0.0007 Cumulative_SOC_deviation: 482.1614 Fuel Consumption: 11.6703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "battery power is 7909.022371714286(+) but condition is not avail\n",
      "elapsed_time: 82.790\n",
      "Episode: 126 Exploration P: 0.0453 Total reward: -2600.7760654769445 SOC: -0.0007 Cumulative_SOC_deviation: 529.9723 Fuel Consumption: 12.6613\n",
      "\n",
      "battery power is 13127.960802209038(+) but condition is not avail\n",
      "elapsed_time: 80.787\n",
      "Episode: 127 Exploration P: 0.0444 Total reward: -2479.626433390107 SOC: -0.0003 Cumulative_SOC_deviation: 489.7470 Fuel Consumption: 12.1863\n",
      "\n",
      "battery power is 7575.488724445846(+) but condition is not avail\n",
      "elapsed_time: 75.474\n",
      "Episode: 128 Exploration P: 0.0436 Total reward: -2386.388592215527 SOC: -0.0006 Cumulative_SOC_deviation: 459.4319 Fuel Consumption: 9.8949\n",
      "\n",
      "battery power is 6921.582308501251(+) but condition is not avail\n",
      "elapsed_time: 69.853\n",
      "Episode: 129 Exploration P: 0.0428 Total reward: -2227.7623052691542 SOC: -0.0001 Cumulative_SOC_deviation: 407.1614 Fuel Consumption: 8.0782\n",
      "\n",
      "battery power is 3262.287183941105(+) but condition is not avail\n",
      "elapsed_time: 69.123\n",
      "Episode: 130 Exploration P: 0.0421 Total reward: -2238.2661551263636 SOC: -0.0003 Cumulative_SOC_deviation: 410.7146 Fuel Consumption: 7.9233\n",
      "\n",
      "battery power is 5354.556455920319(+) but condition is not avail\n",
      "elapsed_time: 70.066\n",
      "Episode: 131 Exploration P: 0.0414 Total reward: -2252.8029600156265 SOC: -0.0001 Cumulative_SOC_deviation: 415.3054 Fuel Consumption: 8.6870\n",
      "\n",
      "battery power is 3166.30880951183(+) but condition is not avail\n",
      "elapsed_time: 70.528\n",
      "Episode: 132 Exploration P: 0.0407 Total reward: -2230.3169644795726 SOC: -0.0005 Cumulative_SOC_deviation: 407.8001 Fuel Consumption: 8.7180\n",
      "\n",
      "battery power is 7678.588641419948(+) but condition is not avail\n",
      "elapsed_time: 66.302\n",
      "Episode: 133 Exploration P: 0.0400 Total reward: -2150.5973252896456 SOC: -0.0015 Cumulative_SOC_deviation: 381.9057 Fuel Consumption: 6.6848\n",
      "\n",
      "battery power is 6795.419827853896(+) but condition is not avail\n",
      "elapsed_time: 69.430\n",
      "Episode: 134 Exploration P: 0.0394 Total reward: -2212.2411906489538 SOC: -0.0002 Cumulative_SOC_deviation: 402.0498 Fuel Consumption: 7.8924\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.544\n",
      "Episode: 135 Exploration P: 0.0386 Total reward: -1301.332775291792 SOC: 0.3997 Cumulative_SOC_deviation: 420.3740 Fuel Consumption: 40.2108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.787\n",
      "Episode: 136 Exploration P: 0.0378 Total reward: -814.4757579737711 SOC: 0.3674 Cumulative_SOC_deviation: 260.7749 Fuel Consumption: 32.1510\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.779\n",
      "Episode: 137 Exploration P: 0.0370 Total reward: -731.373989135809 SOC: 0.4116 Cumulative_SOC_deviation: 231.3250 Fuel Consumption: 37.3990\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.831\n",
      "Episode: 138 Exploration P: 0.0363 Total reward: -799.9148002422382 SOC: 0.3580 Cumulative_SOC_deviation: 255.5588 Fuel Consumption: 33.2383\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.602\n",
      "Episode: 139 Exploration P: 0.0356 Total reward: -889.9251121418763 SOC: 0.3557 Cumulative_SOC_deviation: 286.0886 Fuel Consumption: 31.6594\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.485\n",
      "Episode: 140 Exploration P: 0.0349 Total reward: -904.5645983475818 SOC: 0.4245 Cumulative_SOC_deviation: 288.0666 Fuel Consumption: 40.3647\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.150\n",
      "Episode: 141 Exploration P: 0.0342 Total reward: -984.5005845436812 SOC: 0.3679 Cumulative_SOC_deviation: 315.9658 Fuel Consumption: 36.6032\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.413\n",
      "Episode: 142 Exploration P: 0.0336 Total reward: -937.5336604260224 SOC: 0.2721 Cumulative_SOC_deviation: 303.2879 Fuel Consumption: 27.6699\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.546\n",
      "Episode: 143 Exploration P: 0.0329 Total reward: -767.4433342863641 SOC: 0.4261 Cumulative_SOC_deviation: 242.4958 Fuel Consumption: 39.9558\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.140\n",
      "Episode: 144 Exploration P: 0.0323 Total reward: -898.4369798685939 SOC: 0.3666 Cumulative_SOC_deviation: 287.4379 Fuel Consumption: 36.1232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.796\n",
      "Episode: 145 Exploration P: 0.0317 Total reward: -977.6411575071489 SOC: 0.3576 Cumulative_SOC_deviation: 313.4047 Fuel Consumption: 37.4271\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.138\n",
      "Episode: 146 Exploration P: 0.0311 Total reward: -866.7595280291808 SOC: 0.3723 Cumulative_SOC_deviation: 276.3198 Fuel Consumption: 37.8002\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.508\n",
      "Episode: 147 Exploration P: 0.0306 Total reward: -1059.783093873369 SOC: 0.2969 Cumulative_SOC_deviation: 342.7115 Fuel Consumption: 31.6485\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.355\n",
      "Episode: 148 Exploration P: 0.0300 Total reward: -959.9695940254381 SOC: 0.2808 Cumulative_SOC_deviation: 309.6366 Fuel Consumption: 31.0598\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.613\n",
      "Episode: 149 Exploration P: 0.0295 Total reward: -950.2096301020039 SOC: 0.4128 Cumulative_SOC_deviation: 302.6820 Fuel Consumption: 42.1636\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.933\n",
      "Episode: 150 Exploration P: 0.0289 Total reward: -528.8075586283726 SOC: 0.4877 Cumulative_SOC_deviation: 162.2665 Fuel Consumption: 42.0081\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.611\n",
      "Episode: 151 Exploration P: 0.0284 Total reward: -205.71001338026642 SOC: 0.5865 Cumulative_SOC_deviation: 52.5745 Fuel Consumption: 47.9865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.428\n",
      "Episode: 152 Exploration P: 0.0279 Total reward: -159.3465133568506 SOC: 0.5994 Cumulative_SOC_deviation: 36.7416 Fuel Consumption: 49.1217\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.641\n",
      "Episode: 153 Exploration P: 0.0274 Total reward: -308.6935716509015 SOC: 0.5223 Cumulative_SOC_deviation: 87.9720 Fuel Consumption: 44.7775\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.876\n",
      "Episode: 154 Exploration P: 0.0270 Total reward: -1428.7022235170668 SOC: 0.2274 Cumulative_SOC_deviation: 467.0892 Fuel Consumption: 27.4347\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.872\n",
      "Episode: 155 Exploration P: 0.0265 Total reward: -210.68343910012536 SOC: 0.5606 Cumulative_SOC_deviation: 55.0444 Fuel Consumption: 45.5503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.127\n",
      "Episode: 156 Exploration P: 0.0261 Total reward: -189.6930291185291 SOC: 0.5743 Cumulative_SOC_deviation: 48.0177 Fuel Consumption: 45.6399\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.600\n",
      "Episode: 157 Exploration P: 0.0256 Total reward: -201.7682650972923 SOC: 0.5759 Cumulative_SOC_deviation: 52.4554 Fuel Consumption: 44.4020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.649\n",
      "Episode: 158 Exploration P: 0.0252 Total reward: -144.78110763318512 SOC: 0.6112 Cumulative_SOC_deviation: 32.6733 Fuel Consumption: 46.7612\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.077\n",
      "Episode: 159 Exploration P: 0.0248 Total reward: -82.02125932883375 SOC: 0.6149 Cumulative_SOC_deviation: 11.3603 Fuel Consumption: 47.9404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.474\n",
      "Episode: 160 Exploration P: 0.0244 Total reward: -161.87187475419395 SOC: 0.6258 Cumulative_SOC_deviation: 37.4862 Fuel Consumption: 49.4134\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.213\n",
      "Episode: 161 Exploration P: 0.0240 Total reward: -611.1934250882947 SOC: 0.3821 Cumulative_SOC_deviation: 192.0386 Fuel Consumption: 35.0777\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.618\n",
      "Episode: 162 Exploration P: 0.0236 Total reward: -262.5335121756655 SOC: 0.5961 Cumulative_SOC_deviation: 69.9965 Fuel Consumption: 52.5441\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.717\n",
      "Episode: 163 Exploration P: 0.0232 Total reward: -618.3433833015129 SOC: 0.4838 Cumulative_SOC_deviation: 192.1388 Fuel Consumption: 41.9269\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.609\n",
      "Episode: 164 Exploration P: 0.0229 Total reward: -948.4806774213012 SOC: 0.2073 Cumulative_SOC_deviation: 309.1199 Fuel Consumption: 21.1210\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.701\n",
      "Episode: 165 Exploration P: 0.0225 Total reward: -725.883583160372 SOC: 0.2623 Cumulative_SOC_deviation: 233.8469 Fuel Consumption: 24.3430\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.754\n",
      "Episode: 166 Exploration P: 0.0222 Total reward: -509.41862829957404 SOC: 0.4813 Cumulative_SOC_deviation: 156.0275 Fuel Consumption: 41.3360\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.772\n",
      "Episode: 167 Exploration P: 0.0219 Total reward: -339.23225828832176 SOC: 0.5305 Cumulative_SOC_deviation: 97.3677 Fuel Consumption: 47.1292\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.425\n",
      "Episode: 168 Exploration P: 0.0215 Total reward: -523.8138929274267 SOC: 0.4243 Cumulative_SOC_deviation: 161.0507 Fuel Consumption: 40.6618\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.995\n",
      "Episode: 169 Exploration P: 0.0212 Total reward: -609.3819156218705 SOC: 0.4110 Cumulative_SOC_deviation: 190.3457 Fuel Consumption: 38.3447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.742\n",
      "Episode: 170 Exploration P: 0.0209 Total reward: -603.9831643062676 SOC: 0.4681 Cumulative_SOC_deviation: 187.3433 Fuel Consumption: 41.9531\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.443\n",
      "Episode: 171 Exploration P: 0.0206 Total reward: -420.2876215001429 SOC: 0.5197 Cumulative_SOC_deviation: 125.7190 Fuel Consumption: 43.1308\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.300\n",
      "Episode: 172 Exploration P: 0.0203 Total reward: -460.94890307938437 SOC: 0.4876 Cumulative_SOC_deviation: 138.3997 Fuel Consumption: 45.7498\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.759\n",
      "Episode: 173 Exploration P: 0.0201 Total reward: -505.11441690505745 SOC: 0.4341 Cumulative_SOC_deviation: 154.4067 Fuel Consumption: 41.8944\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.493\n",
      "Episode: 174 Exploration P: 0.0198 Total reward: -510.8200395707154 SOC: 0.4701 Cumulative_SOC_deviation: 154.4625 Fuel Consumption: 47.4327\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.626\n",
      "Episode: 175 Exploration P: 0.0195 Total reward: -753.639490016363 SOC: 0.4527 Cumulative_SOC_deviation: 236.0478 Fuel Consumption: 45.4960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.477\n",
      "Episode: 176 Exploration P: 0.0193 Total reward: -1099.7624240309542 SOC: 0.2695 Cumulative_SOC_deviation: 355.9994 Fuel Consumption: 31.7644\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.202\n",
      "Episode: 177 Exploration P: 0.0190 Total reward: -617.1600034036918 SOC: 0.4806 Cumulative_SOC_deviation: 189.7883 Fuel Consumption: 47.7952\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.148\n",
      "Episode: 178 Exploration P: 0.0188 Total reward: -623.0092034701154 SOC: 0.4168 Cumulative_SOC_deviation: 194.9335 Fuel Consumption: 38.2088\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.738\n",
      "Episode: 179 Exploration P: 0.0185 Total reward: -924.4966961925356 SOC: 0.2600 Cumulative_SOC_deviation: 299.0499 Fuel Consumption: 27.3470\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.273\n",
      "Episode: 180 Exploration P: 0.0183 Total reward: -695.178106298452 SOC: 0.4617 Cumulative_SOC_deviation: 218.7627 Fuel Consumption: 38.8901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.727\n",
      "Episode: 181 Exploration P: 0.0181 Total reward: -744.0416120094859 SOC: 0.3777 Cumulative_SOC_deviation: 236.2728 Fuel Consumption: 35.2233\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.605\n",
      "Episode: 182 Exploration P: 0.0179 Total reward: -473.75620553370067 SOC: 0.5060 Cumulative_SOC_deviation: 144.5696 Fuel Consumption: 40.0473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.928\n",
      "Episode: 183 Exploration P: 0.0176 Total reward: -934.4373673060056 SOC: 0.2648 Cumulative_SOC_deviation: 302.5630 Fuel Consumption: 26.7485\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.250\n",
      "Episode: 184 Exploration P: 0.0174 Total reward: -998.4261624243694 SOC: 0.3916 Cumulative_SOC_deviation: 319.0976 Fuel Consumption: 41.1333\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.872\n",
      "Episode: 185 Exploration P: 0.0172 Total reward: -909.108436304108 SOC: 0.3112 Cumulative_SOC_deviation: 291.8081 Fuel Consumption: 33.6842\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.497\n",
      "Episode: 186 Exploration P: 0.0170 Total reward: -442.29675963801986 SOC: 0.5925 Cumulative_SOC_deviation: 132.1881 Fuel Consumption: 45.7325\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.939\n",
      "Episode: 187 Exploration P: 0.0169 Total reward: -446.6427199229205 SOC: 0.5810 Cumulative_SOC_deviation: 133.9846 Fuel Consumption: 44.6891\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.906\n",
      "Episode: 188 Exploration P: 0.0167 Total reward: -482.7084754858623 SOC: 0.4972 Cumulative_SOC_deviation: 147.9605 Fuel Consumption: 38.8269\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.969\n",
      "Episode: 189 Exploration P: 0.0165 Total reward: -600.6118610209826 SOC: 0.2784 Cumulative_SOC_deviation: 191.7036 Fuel Consumption: 25.5012\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.328\n",
      "Episode: 190 Exploration P: 0.0163 Total reward: -550.3583413839168 SOC: 0.3898 Cumulative_SOC_deviation: 172.7943 Fuel Consumption: 31.9754\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.320\n",
      "Episode: 191 Exploration P: 0.0161 Total reward: -945.95634630553 SOC: 0.1876 Cumulative_SOC_deviation: 308.5879 Fuel Consumption: 20.1925\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.425\n",
      "Episode: 192 Exploration P: 0.0160 Total reward: -593.0690508291793 SOC: 0.4830 Cumulative_SOC_deviation: 184.9165 Fuel Consumption: 38.3196\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.163\n",
      "Episode: 193 Exploration P: 0.0158 Total reward: -547.9946124513247 SOC: 0.5241 Cumulative_SOC_deviation: 168.9962 Fuel Consumption: 41.0060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.634\n",
      "Episode: 194 Exploration P: 0.0157 Total reward: -541.2545853049152 SOC: 0.5792 Cumulative_SOC_deviation: 165.3011 Fuel Consumption: 45.3514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.028\n",
      "Episode: 195 Exploration P: 0.0155 Total reward: -490.56689756136893 SOC: 0.5859 Cumulative_SOC_deviation: 148.3531 Fuel Consumption: 45.5077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.815\n",
      "Episode: 196 Exploration P: 0.0154 Total reward: -627.8980682511801 SOC: 0.4635 Cumulative_SOC_deviation: 196.8584 Fuel Consumption: 37.3228\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.861\n",
      "Episode: 197 Exploration P: 0.0152 Total reward: -774.332487507576 SOC: 0.4101 Cumulative_SOC_deviation: 246.9333 Fuel Consumption: 33.5327\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.337\n",
      "Episode: 198 Exploration P: 0.0151 Total reward: -746.8416759574328 SOC: 0.2677 Cumulative_SOC_deviation: 240.4983 Fuel Consumption: 25.3468\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.546\n",
      "Episode: 199 Exploration P: 0.0149 Total reward: -1233.9065493812761 SOC: 0.2861 Cumulative_SOC_deviation: 400.9954 Fuel Consumption: 30.9203\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.599\n",
      "Episode: 200 Exploration P: 0.0148 Total reward: -1358.0190899121474 SOC: 0.1560 Cumulative_SOC_deviation: 445.8535 Fuel Consumption: 20.4586\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "# num_trials = 1\n",
    "reward_factors = [1, 2, 3]\n",
    "results_dict = {} \n",
    "driving_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "driving_cycle = sio.loadmat(driving_cycle_path)\n",
    "driving_cycle = driving_cycle[\"sch_cycle\"][:, 1]\n",
    "\n",
    "for reward_factor in reward_factors: \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(reward_factor))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "#         driving_cycle = driver.get_cycle() \n",
    "        env = initialization_env(driving_cycle, reward_factor)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "#             history = test_agent(actor_model, reward_factor)\n",
    "            history = env.history \n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "#         if (ep + 1) % 200 == 0:             \n",
    "    root = \"DDPG_cycleOne_reward_factor{}\".format(reward_factor)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "            \n",
    "    \n",
    "    results_dict[reward_factor] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG_cycleOne_1to3.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
