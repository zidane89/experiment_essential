{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "import scipy.io as sio\n",
    "\n",
    "from vehicle_model_variant import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200 \n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "#     actor_model.load_weights(\"./DDPG1_trial1/actor_model_checkpoint\")\n",
    "#     critic_model.load_weights(\"./DDPG1_trial1/critic_model_checkpoint\")\n",
    "#     target_actor.load_weights(\"./DDPG1_trial1/target_actor_checkpoint\")\n",
    "#     target_critic.load_weights(\"./DDPG1_trial1/target_critic_checkpoint\")\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    if not os.path.exists(root): \n",
    "        os.makedirs(root)\n",
    "        \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor):\n",
    "#     test_cycle = driver.get_cycle() \n",
    "    test_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "    test_cycle = sio.loadmat(test_cycle_path)\n",
    "    test_cycle = test_cycle[\"sch_cycle\"][:, 1]\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 4\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 15.105\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2142.471166421791 SOC: 1.0000 Cumulative_SOC_deviation: 496.9890 Fuel Consumption: 154.5153\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 13.956\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2140.3879371382764 SOC: 1.0000 Cumulative_SOC_deviation: 496.3443 Fuel Consumption: 155.0106\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 14.226\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2139.7106312414744 SOC: 1.0000 Cumulative_SOC_deviation: 497.2842 Fuel Consumption: 150.5738\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 39.445\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2143.017501541629 SOC: 1.0000 Cumulative_SOC_deviation: 497.3113 Fuel Consumption: 153.7724\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.830\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2125.363209834095 SOC: 1.0000 Cumulative_SOC_deviation: 494.2932 Fuel Consumption: 148.1903\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.446\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2120.578345013098 SOC: 1.0000 Cumulative_SOC_deviation: 493.6594 Fuel Consumption: 145.9409\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.385\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2093.7851467574646 SOC: 1.0000 Cumulative_SOC_deviation: 488.4856 Fuel Consumption: 139.8429\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.774\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2112.5581091626295 SOC: 1.0000 Cumulative_SOC_deviation: 493.1556 Fuel Consumption: 139.9358\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.145\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2058.59815197377 SOC: 1.0000 Cumulative_SOC_deviation: 481.0714 Fuel Consumption: 134.3124\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.493\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2040.24802259295 SOC: 1.0000 Cumulative_SOC_deviation: 476.5458 Fuel Consumption: 134.0647\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.951\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2007.4488329717408 SOC: 1.0000 Cumulative_SOC_deviation: 470.2575 Fuel Consumption: 126.4190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.166\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2014.4886449646247 SOC: 1.0000 Cumulative_SOC_deviation: 471.2848 Fuel Consumption: 129.3493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.013\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -1990.930058940081 SOC: 1.0000 Cumulative_SOC_deviation: 466.5070 Fuel Consumption: 124.9022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.587\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2034.759582783652 SOC: 1.0000 Cumulative_SOC_deviation: 476.8324 Fuel Consumption: 127.4302\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.760\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -1969.2913133825593 SOC: 1.0000 Cumulative_SOC_deviation: 461.9408 Fuel Consumption: 121.5282\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.894\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -1922.2590513735415 SOC: 1.0000 Cumulative_SOC_deviation: 450.9746 Fuel Consumption: 118.3605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.950\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -1884.9043617958512 SOC: 1.0000 Cumulative_SOC_deviation: 442.6188 Fuel Consumption: 114.4293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.539\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -1871.022095776209 SOC: 1.0000 Cumulative_SOC_deviation: 438.8464 Fuel Consumption: 115.6365\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.079\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -1833.110896656633 SOC: 1.0000 Cumulative_SOC_deviation: 429.7787 Fuel Consumption: 113.9960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.890\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -1800.6340725837135 SOC: 1.0000 Cumulative_SOC_deviation: 422.5778 Fuel Consumption: 110.3227\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.940\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -1710.0171577836393 SOC: 1.0000 Cumulative_SOC_deviation: 401.1257 Fuel Consumption: 105.5144\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.019\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -1825.3675334481902 SOC: 1.0000 Cumulative_SOC_deviation: 429.3597 Fuel Consumption: 107.9289\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.250\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -1804.8316907999929 SOC: 1.0000 Cumulative_SOC_deviation: 425.1053 Fuel Consumption: 104.4104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.412\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1609.9216846884367 SOC: 1.0000 Cumulative_SOC_deviation: 377.0562 Fuel Consumption: 101.6967\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.424\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -1674.207974084152 SOC: 1.0000 Cumulative_SOC_deviation: 393.2516 Fuel Consumption: 101.2015\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.704\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1558.409258207365 SOC: 1.0000 Cumulative_SOC_deviation: 365.3596 Fuel Consumption: 96.9710\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.385\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1729.9528145464956 SOC: 1.0000 Cumulative_SOC_deviation: 407.5902 Fuel Consumption: 99.5918\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.822\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -1512.5793457638638 SOC: 1.0000 Cumulative_SOC_deviation: 354.3819 Fuel Consumption: 95.0518\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.694\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -1308.757098543579 SOC: 1.0000 Cumulative_SOC_deviation: 303.8365 Fuel Consumption: 93.4113\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.088\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -1410.8530032757517 SOC: 1.0000 Cumulative_SOC_deviation: 329.7061 Fuel Consumption: 92.0286\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.714\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -1516.8545617813675 SOC: 1.0000 Cumulative_SOC_deviation: 355.5255 Fuel Consumption: 94.7526\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.549\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -1148.2398595315412 SOC: 1.0000 Cumulative_SOC_deviation: 265.1001 Fuel Consumption: 87.8395\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.083\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1148.5143607881407 SOC: 1.0000 Cumulative_SOC_deviation: 264.9624 Fuel Consumption: 88.6649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.245\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1290.4008209509802 SOC: 1.0000 Cumulative_SOC_deviation: 300.1270 Fuel Consumption: 89.8928\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.700\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -921.9502179538226 SOC: 0.9889 Cumulative_SOC_deviation: 209.7478 Fuel Consumption: 82.9590\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.869\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -979.7133087066551 SOC: 1.0000 Cumulative_SOC_deviation: 223.9513 Fuel Consumption: 83.9083\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.679\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -842.218557518214 SOC: 0.9881 Cumulative_SOC_deviation: 189.7478 Fuel Consumption: 83.2273\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.763\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -986.3242325937014 SOC: 1.0000 Cumulative_SOC_deviation: 225.6014 Fuel Consumption: 83.9186\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.893\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -719.855197759607 SOC: 0.9318 Cumulative_SOC_deviation: 160.2094 Fuel Consumption: 79.0175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.676\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -725.4146125711698 SOC: 0.9492 Cumulative_SOC_deviation: 161.3078 Fuel Consumption: 80.1834\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.880\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -775.2288905305453 SOC: 0.9399 Cumulative_SOC_deviation: 174.0064 Fuel Consumption: 79.2032\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.772\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -770.5216218486659 SOC: 0.9664 Cumulative_SOC_deviation: 172.1873 Fuel Consumption: 81.7724\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.839\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -669.822609703984 SOC: 0.9385 Cumulative_SOC_deviation: 147.6265 Fuel Consumption: 79.3167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.176\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -399.59811554138145 SOC: 0.7793 Cumulative_SOC_deviation: 82.8769 Fuel Consumption: 68.0906\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.182\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -445.11344708607004 SOC: 0.8075 Cumulative_SOC_deviation: 93.8249 Fuel Consumption: 69.8137\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.331\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -608.5723258643924 SOC: 0.8940 Cumulative_SOC_deviation: 133.0310 Fuel Consumption: 76.4482\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.648\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -465.7447481114604 SOC: 0.8088 Cumulative_SOC_deviation: 98.9570 Fuel Consumption: 69.9169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.866\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -630.8559779110584 SOC: 0.8765 Cumulative_SOC_deviation: 139.0301 Fuel Consumption: 74.7354\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.167\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -466.0606191385758 SOC: 0.7894 Cumulative_SOC_deviation: 99.4177 Fuel Consumption: 68.3898\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.004\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -360.08021147258563 SOC: 0.7605 Cumulative_SOC_deviation: 73.4127 Fuel Consumption: 66.4293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.300\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -464.9608742892914 SOC: 0.6361 Cumulative_SOC_deviation: 102.0551 Fuel Consumption: 56.7406\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.362\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -348.2190481639911 SOC: 0.7310 Cumulative_SOC_deviation: 71.0020 Fuel Consumption: 64.2109\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.114\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -430.83004558304043 SOC: 0.6684 Cumulative_SOC_deviation: 92.7743 Fuel Consumption: 59.7329\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.429\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -575.4156573867506 SOC: 0.6163 Cumulative_SOC_deviation: 129.8854 Fuel Consumption: 55.8739\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.289\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -654.3391244119294 SOC: 0.5808 Cumulative_SOC_deviation: 150.2767 Fuel Consumption: 53.2324\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.489\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -474.57429037361567 SOC: 0.6551 Cumulative_SOC_deviation: 103.8987 Fuel Consumption: 58.9796\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.600\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -622.3790145258082 SOC: 0.5530 Cumulative_SOC_deviation: 142.9032 Fuel Consumption: 50.7664\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.809\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -602.4202738781726 SOC: 0.5701 Cumulative_SOC_deviation: 137.4053 Fuel Consumption: 52.7991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.788\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -494.63128718651626 SOC: 0.6058 Cumulative_SOC_deviation: 109.9421 Fuel Consumption: 54.8627\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.958\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -808.8611980540285 SOC: 0.4899 Cumulative_SOC_deviation: 190.5942 Fuel Consumption: 46.4844\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.088\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -772.1383432994359 SOC: 0.5432 Cumulative_SOC_deviation: 180.3017 Fuel Consumption: 50.9315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.236\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -664.9064586835184 SOC: 0.5514 Cumulative_SOC_deviation: 153.4035 Fuel Consumption: 51.2926\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.520\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -890.2439970525867 SOC: 0.4727 Cumulative_SOC_deviation: 211.2366 Fuel Consumption: 45.2978\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.660\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -1036.8076875954685 SOC: 0.3855 Cumulative_SOC_deviation: 249.5929 Fuel Consumption: 38.4362\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.591\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -849.2630769163155 SOC: 0.4479 Cumulative_SOC_deviation: 201.4840 Fuel Consumption: 43.3270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.406\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -903.5716344462974 SOC: 0.4763 Cumulative_SOC_deviation: 214.4756 Fuel Consumption: 45.6692\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.276\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -1234.3491537495916 SOC: 0.3410 Cumulative_SOC_deviation: 299.6695 Fuel Consumption: 35.6710\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.395\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -1170.4381277839861 SOC: 0.3723 Cumulative_SOC_deviation: 283.0804 Fuel Consumption: 38.1164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.448\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -1001.4112774469431 SOC: 0.4085 Cumulative_SOC_deviation: 240.1531 Fuel Consumption: 40.7991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.730\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -1003.8005587557944 SOC: 0.3798 Cumulative_SOC_deviation: 241.2998 Fuel Consumption: 38.6013\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.281\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -1094.1020715379666 SOC: 0.3740 Cumulative_SOC_deviation: 264.1151 Fuel Consumption: 37.6417\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.643\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -1344.3586265624795 SOC: 0.3289 Cumulative_SOC_deviation: 327.2932 Fuel Consumption: 35.1860\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.470\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -1312.9258580877502 SOC: 0.2856 Cumulative_SOC_deviation: 320.2733 Fuel Consumption: 31.8326\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.660\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -1389.0265781398844 SOC: 0.2937 Cumulative_SOC_deviation: 339.1411 Fuel Consumption: 32.4620\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.664\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -1348.2616785174541 SOC: 0.2886 Cumulative_SOC_deviation: 328.9938 Fuel Consumption: 32.2866\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.386\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -1239.279119250612 SOC: 0.3315 Cumulative_SOC_deviation: 300.9356 Fuel Consumption: 35.5368\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 106.308\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -1283.185567968779 SOC: 0.3292 Cumulative_SOC_deviation: 312.0566 Fuel Consumption: 34.9590\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.700\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -1465.9812955206103 SOC: 0.2370 Cumulative_SOC_deviation: 359.3265 Fuel Consumption: 28.6753\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.975\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -1274.803427422593 SOC: 0.2736 Cumulative_SOC_deviation: 310.9336 Fuel Consumption: 31.0691\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.328\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -1410.8436147422876 SOC: 0.2557 Cumulative_SOC_deviation: 345.2351 Fuel Consumption: 29.9031\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.770\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -1628.6230709897548 SOC: 0.2033 Cumulative_SOC_deviation: 400.5106 Fuel Consumption: 26.5807\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.746\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -1776.1385774853545 SOC: 0.1334 Cumulative_SOC_deviation: 438.6277 Fuel Consumption: 21.6280\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.827\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -1555.3889979517332 SOC: 0.1950 Cumulative_SOC_deviation: 382.5452 Fuel Consumption: 25.2084\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.419\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -1501.4626783254405 SOC: 0.2195 Cumulative_SOC_deviation: 368.5374 Fuel Consumption: 27.3133\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.507\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -1559.3051579671542 SOC: 0.1895 Cumulative_SOC_deviation: 383.4313 Fuel Consumption: 25.5798\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.173\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -1851.2816766591768 SOC: 0.1098 Cumulative_SOC_deviation: 457.7513 Fuel Consumption: 20.2763\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.942\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -1671.6837255917894 SOC: 0.1398 Cumulative_SOC_deviation: 412.4288 Fuel Consumption: 21.9685\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.791\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -1737.4748388251228 SOC: 0.1443 Cumulative_SOC_deviation: 428.8379 Fuel Consumption: 22.1232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.486\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -1692.578938965085 SOC: 0.1734 Cumulative_SOC_deviation: 416.9948 Fuel Consumption: 24.5996\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.868\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -1806.1959510737063 SOC: 0.1401 Cumulative_SOC_deviation: 446.0440 Fuel Consumption: 22.0201\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.865\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -1726.3975188781867 SOC: 0.1555 Cumulative_SOC_deviation: 425.8132 Fuel Consumption: 23.1447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.805\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -1934.3332681409192 SOC: 0.0766 Cumulative_SOC_deviation: 479.1101 Fuel Consumption: 17.8928\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.184\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -1624.9213709420742 SOC: 0.1719 Cumulative_SOC_deviation: 400.2120 Fuel Consumption: 24.0734\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.751\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -1896.517905837043 SOC: 0.1235 Cumulative_SOC_deviation: 468.7896 Fuel Consumption: 21.3597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.747\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -1806.2458245543917 SOC: 0.1202 Cumulative_SOC_deviation: 446.2705 Fuel Consumption: 21.1637\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.175\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -1794.6279988857577 SOC: 0.1182 Cumulative_SOC_deviation: 443.5157 Fuel Consumption: 20.5652\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.061\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -1871.4937750637812 SOC: 0.1127 Cumulative_SOC_deviation: 462.7321 Fuel Consumption: 20.5652\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.841\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -2020.1891036253608 SOC: 0.0547 Cumulative_SOC_deviation: 500.9326 Fuel Consumption: 16.4586\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.928\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -1769.2972840921577 SOC: 0.1353 Cumulative_SOC_deviation: 436.8632 Fuel Consumption: 21.8447\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.678\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -1901.6113140006087 SOC: 0.0878 Cumulative_SOC_deviation: 470.7955 Fuel Consumption: 18.4294\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.411\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -2016.566990608354 SOC: 0.0843 Cumulative_SOC_deviation: 499.5396 Fuel Consumption: 18.4087\n",
      "\n",
      "battery power is 1108.3759136997508(+) but condition is not avail\n",
      "elapsed_time: 89.483\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -3108.638765149688 SOC: -0.0004 Cumulative_SOC_deviation: 524.5200 Fuel Consumption: 12.9605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.943\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -1948.6281140399608 SOC: 0.0809 Cumulative_SOC_deviation: 482.5832 Fuel Consumption: 18.2952\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.092\n",
      "Episode: 104 Exploration P: 0.0730 Total reward: -2039.9307158210731 SOC: 0.0274 Cumulative_SOC_deviation: 506.4072 Fuel Consumption: 14.3021\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.509\n",
      "Episode: 105 Exploration P: 0.0713 Total reward: -1885.7119111693794 SOC: 0.0988 Cumulative_SOC_deviation: 466.6298 Fuel Consumption: 19.1929\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.847\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -2111.6204723292963 SOC: 0.0228 Cumulative_SOC_deviation: 524.3605 Fuel Consumption: 14.1783\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.089\n",
      "Episode: 107 Exploration P: 0.0680 Total reward: -2013.3285756068906 SOC: 0.0581 Cumulative_SOC_deviation: 499.1840 Fuel Consumption: 16.5927\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.023\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -2022.9529081135042 SOC: 0.0491 Cumulative_SOC_deviation: 501.6803 Fuel Consumption: 16.2316\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.752\n",
      "Episode: 109 Exploration P: 0.0649 Total reward: -2055.788824817752 SOC: 0.0335 Cumulative_SOC_deviation: 510.1885 Fuel Consumption: 15.0347\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.547\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -2142.5845036863775 SOC: 0.0166 Cumulative_SOC_deviation: 532.1299 Fuel Consumption: 14.0648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.207\n",
      "Episode: 111 Exploration P: 0.0620 Total reward: -2143.2070829995887 SOC: 0.0068 Cumulative_SOC_deviation: 532.4403 Fuel Consumption: 13.4457\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.696\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -2182.1574108855243 SOC: 0.0173 Cumulative_SOC_deviation: 542.0515 Fuel Consumption: 13.9513\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.700\n",
      "Episode: 113 Exploration P: 0.0592 Total reward: -2063.134998341341 SOC: 0.0296 Cumulative_SOC_deviation: 512.1231 Fuel Consumption: 14.6426\n",
      "\n",
      "battery power is 11289.612604841715(+) but condition is not avail\n",
      "elapsed_time: 87.419\n",
      "Episode: 114 Exploration P: 0.0579 Total reward: -3002.598669306116 SOC: -0.0004 Cumulative_SOC_deviation: 498.1287 Fuel Consumption: 12.4855\n",
      "\n",
      "battery power is 2519.560807434138(+) but condition is not avail\n",
      "elapsed_time: 79.033\n",
      "Episode: 115 Exploration P: 0.0568 Total reward: -2763.927929072998 SOC: -0.0006 Cumulative_SOC_deviation: 439.2070 Fuel Consumption: 9.5025\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.480\n",
      "Episode: 116 Exploration P: 0.0555 Total reward: -1188.451118582964 SOC: 0.5986 Cumulative_SOC_deviation: 283.2571 Fuel Consumption: 55.4228\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.406\n",
      "Episode: 117 Exploration P: 0.0543 Total reward: -108.97433150500312 SOC: 0.5959 Cumulative_SOC_deviation: 15.6600 Fuel Consumption: 46.3345\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.960\n",
      "Episode: 118 Exploration P: 0.0531 Total reward: -128.3033006408059 SOC: 0.5872 Cumulative_SOC_deviation: 20.6160 Fuel Consumption: 45.8394\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.909\n",
      "Episode: 119 Exploration P: 0.0519 Total reward: -163.88493672284227 SOC: 0.5737 Cumulative_SOC_deviation: 29.4795 Fuel Consumption: 45.9669\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.413\n",
      "Episode: 120 Exploration P: 0.0508 Total reward: -148.92504799086737 SOC: 0.5842 Cumulative_SOC_deviation: 25.5922 Fuel Consumption: 46.5563\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.459\n",
      "Episode: 121 Exploration P: 0.0497 Total reward: -165.41408089843085 SOC: 0.5907 Cumulative_SOC_deviation: 29.3617 Fuel Consumption: 47.9674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.966\n",
      "Episode: 122 Exploration P: 0.0486 Total reward: -971.0810884417176 SOC: 0.3709 Cumulative_SOC_deviation: 234.6188 Fuel Consumption: 32.6059\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.616\n",
      "Episode: 123 Exploration P: 0.0476 Total reward: -1203.5238161593074 SOC: 0.4745 Cumulative_SOC_deviation: 290.6208 Fuel Consumption: 41.0406\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.790\n",
      "Episode: 124 Exploration P: 0.0466 Total reward: -269.13391244242166 SOC: 0.5900 Cumulative_SOC_deviation: 55.8828 Fuel Consumption: 45.6027\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.965\n",
      "Episode: 125 Exploration P: 0.0456 Total reward: -155.53699265286764 SOC: 0.5882 Cumulative_SOC_deviation: 27.5800 Fuel Consumption: 45.2168\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.574\n",
      "Episode: 126 Exploration P: 0.0446 Total reward: -179.571928755036 SOC: 0.5499 Cumulative_SOC_deviation: 34.1005 Fuel Consumption: 43.1699\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.907\n",
      "Episode: 127 Exploration P: 0.0437 Total reward: -214.4131483764522 SOC: 0.5535 Cumulative_SOC_deviation: 42.2836 Fuel Consumption: 45.2788\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.451\n",
      "Episode: 128 Exploration P: 0.0427 Total reward: -747.615889105328 SOC: 0.4743 Cumulative_SOC_deviation: 177.2870 Fuel Consumption: 38.4677\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.054\n",
      "Episode: 129 Exploration P: 0.0419 Total reward: -579.012472989907 SOC: 0.5064 Cumulative_SOC_deviation: 134.8371 Fuel Consumption: 39.6640\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.609\n",
      "Episode: 130 Exploration P: 0.0410 Total reward: -158.3685341917972 SOC: 0.5873 Cumulative_SOC_deviation: 28.0312 Fuel Consumption: 46.2437\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.725\n",
      "Episode: 131 Exploration P: 0.0402 Total reward: -148.81074251195218 SOC: 0.5842 Cumulative_SOC_deviation: 25.7594 Fuel Consumption: 45.7731\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.172\n",
      "Episode: 132 Exploration P: 0.0393 Total reward: -181.4229265194079 SOC: 0.5665 Cumulative_SOC_deviation: 34.0923 Fuel Consumption: 45.0536\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.108\n",
      "Episode: 133 Exploration P: 0.0385 Total reward: -177.42847694583162 SOC: 0.5845 Cumulative_SOC_deviation: 32.8996 Fuel Consumption: 45.8301\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.161\n",
      "Episode: 134 Exploration P: 0.0378 Total reward: -154.35547636028787 SOC: 0.5808 Cumulative_SOC_deviation: 27.2228 Fuel Consumption: 45.4645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.881\n",
      "Episode: 135 Exploration P: 0.0370 Total reward: -162.36241758861507 SOC: 0.5798 Cumulative_SOC_deviation: 29.2381 Fuel Consumption: 45.4100\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.902\n",
      "Episode: 136 Exploration P: 0.0363 Total reward: -169.95239928528648 SOC: 0.5802 Cumulative_SOC_deviation: 31.1133 Fuel Consumption: 45.4991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.165\n",
      "Episode: 137 Exploration P: 0.0356 Total reward: -182.82252337104742 SOC: 0.5690 Cumulative_SOC_deviation: 34.6164 Fuel Consumption: 44.3569\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.505\n",
      "Episode: 138 Exploration P: 0.0349 Total reward: -398.6226517881529 SOC: 0.4364 Cumulative_SOC_deviation: 90.6463 Fuel Consumption: 36.0376\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.206\n",
      "Episode: 139 Exploration P: 0.0342 Total reward: -238.21550780238502 SOC: 0.5675 Cumulative_SOC_deviation: 48.3587 Fuel Consumption: 44.7807\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.940\n",
      "Episode: 140 Exploration P: 0.0336 Total reward: -218.67492578371701 SOC: 0.5740 Cumulative_SOC_deviation: 43.4652 Fuel Consumption: 44.8140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.212\n",
      "Episode: 141 Exploration P: 0.0329 Total reward: -218.888425275119 SOC: 0.5667 Cumulative_SOC_deviation: 43.7193 Fuel Consumption: 44.0113\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.824\n",
      "Episode: 142 Exploration P: 0.0323 Total reward: -257.52854961508194 SOC: 0.5416 Cumulative_SOC_deviation: 53.5704 Fuel Consumption: 43.2469\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.486\n",
      "Episode: 143 Exploration P: 0.0317 Total reward: -322.7366055367555 SOC: 0.5578 Cumulative_SOC_deviation: 69.5041 Fuel Consumption: 44.7204\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.938\n",
      "Episode: 144 Exploration P: 0.0311 Total reward: -281.7255857547322 SOC: 0.5639 Cumulative_SOC_deviation: 59.4354 Fuel Consumption: 43.9840\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.643\n",
      "Episode: 145 Exploration P: 0.0305 Total reward: -275.26171364343617 SOC: 0.5601 Cumulative_SOC_deviation: 57.6587 Fuel Consumption: 44.6270\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.846\n",
      "Episode: 146 Exploration P: 0.0300 Total reward: -253.71876714078047 SOC: 0.5641 Cumulative_SOC_deviation: 52.1367 Fuel Consumption: 45.1718\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.124\n",
      "Episode: 147 Exploration P: 0.0294 Total reward: -261.0643884844791 SOC: 0.5611 Cumulative_SOC_deviation: 54.1916 Fuel Consumption: 44.2979\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.278\n",
      "Episode: 148 Exploration P: 0.0289 Total reward: -250.57887030697964 SOC: 0.5608 Cumulative_SOC_deviation: 51.4906 Fuel Consumption: 44.6164\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.001\n",
      "Episode: 149 Exploration P: 0.0284 Total reward: -253.5276620543875 SOC: 0.5617 Cumulative_SOC_deviation: 52.2508 Fuel Consumption: 44.5244\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.985\n",
      "Episode: 150 Exploration P: 0.0279 Total reward: -287.91680829715114 SOC: 0.5501 Cumulative_SOC_deviation: 60.9856 Fuel Consumption: 43.9743\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.913\n",
      "Episode: 151 Exploration P: 0.0274 Total reward: -296.56973462301175 SOC: 0.5651 Cumulative_SOC_deviation: 62.8946 Fuel Consumption: 44.9915\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.206\n",
      "Episode: 152 Exploration P: 0.0269 Total reward: -579.6660053358207 SOC: 0.3553 Cumulative_SOC_deviation: 137.2315 Fuel Consumption: 30.7402\n",
      "\n",
      "battery power is 2943.195327219531(+) but condition is not avail\n",
      "elapsed_time: 74.770\n",
      "Episode: 153 Exploration P: 0.0266 Total reward: -2687.1472958609347 SOC: -0.0003 Cumulative_SOC_deviation: 420.2457 Fuel Consumption: 8.5681\n",
      "\n",
      "battery power is 6231.497041857457(+) but condition is not avail\n",
      "elapsed_time: 85.320\n",
      "Episode: 154 Exploration P: 0.0261 Total reward: -2981.9552523382235 SOC: -0.0001 Cumulative_SOC_deviation: 493.3900 Fuel Consumption: 10.7968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.937\n",
      "Episode: 155 Exploration P: 0.0257 Total reward: -1108.2900124810649 SOC: 0.5615 Cumulative_SOC_deviation: 264.1067 Fuel Consumption: 51.8632\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.966\n",
      "Episode: 156 Exploration P: 0.0253 Total reward: -262.37541727729604 SOC: 0.5574 Cumulative_SOC_deviation: 54.5838 Fuel Consumption: 44.0401\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.963\n",
      "Episode: 157 Exploration P: 0.0249 Total reward: -269.3413836904909 SOC: 0.5640 Cumulative_SOC_deviation: 55.8450 Fuel Consumption: 45.9615\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.651\n",
      "Episode: 158 Exploration P: 0.0245 Total reward: -365.53007964961625 SOC: 0.5466 Cumulative_SOC_deviation: 80.4507 Fuel Consumption: 43.7271\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.964\n",
      "Episode: 159 Exploration P: 0.0241 Total reward: -324.27015547974395 SOC: 0.5657 Cumulative_SOC_deviation: 69.9877 Fuel Consumption: 44.3192\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.825\n",
      "Episode: 160 Exploration P: 0.0237 Total reward: -327.6991273505148 SOC: 0.5348 Cumulative_SOC_deviation: 71.0639 Fuel Consumption: 43.4437\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.582\n",
      "Episode: 161 Exploration P: 0.0233 Total reward: -348.6546752907722 SOC: 0.5358 Cumulative_SOC_deviation: 76.7061 Fuel Consumption: 41.8303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 98.132\n",
      "Episode: 162 Exploration P: 0.0230 Total reward: -1545.4275393075238 SOC: 0.1234 Cumulative_SOC_deviation: 382.0685 Fuel Consumption: 17.1537\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 104.972\n",
      "Episode: 163 Exploration P: 0.0226 Total reward: -345.98269640322064 SOC: 0.5419 Cumulative_SOC_deviation: 75.2149 Fuel Consumption: 45.1231\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 103.619\n",
      "Episode: 164 Exploration P: 0.0223 Total reward: -422.8550911585291 SOC: 0.5191 Cumulative_SOC_deviation: 94.9193 Fuel Consumption: 43.1779\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.921\n",
      "Episode: 165 Exploration P: 0.0219 Total reward: -487.68112378526627 SOC: 0.5204 Cumulative_SOC_deviation: 111.6139 Fuel Consumption: 41.2253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.931\n",
      "Episode: 166 Exploration P: 0.0216 Total reward: -518.2259606136778 SOC: 0.5113 Cumulative_SOC_deviation: 119.3573 Fuel Consumption: 40.7968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.973\n",
      "Episode: 167 Exploration P: 0.0213 Total reward: -477.1025679824888 SOC: 0.5056 Cumulative_SOC_deviation: 109.0186 Fuel Consumption: 41.0282\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.631\n",
      "Episode: 168 Exploration P: 0.0210 Total reward: -555.4455467664085 SOC: 0.4927 Cumulative_SOC_deviation: 128.7512 Fuel Consumption: 40.4408\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.748\n",
      "Episode: 169 Exploration P: 0.0207 Total reward: -927.135509221514 SOC: 0.2786 Cumulative_SOC_deviation: 225.0951 Fuel Consumption: 26.7553\n",
      "\n",
      "battery power is 9375.157511544401(+) but condition is not avail\n",
      "elapsed_time: 71.077\n",
      "Episode: 170 Exploration P: 0.0205 Total reward: -2549.688911733604 SOC: -0.0018 Cumulative_SOC_deviation: 386.4460 Fuel Consumption: 6.3148\n",
      "\n",
      "battery power is 1131.135576125273(+) but condition is not avail\n",
      "elapsed_time: 62.895\n",
      "Episode: 171 Exploration P: 0.0203 Total reward: -2326.1527259246814 SOC: -0.0001 Cumulative_SOC_deviation: 331.2441 Fuel Consumption: 3.5806\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 95.666\n",
      "Episode: 172 Exploration P: 0.0200 Total reward: -515.3527716021305 SOC: 0.5494 Cumulative_SOC_deviation: 116.5389 Fuel Consumption: 49.1973\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.627\n",
      "Episode: 173 Exploration P: 0.0197 Total reward: -327.882745866643 SOC: 0.5408 Cumulative_SOC_deviation: 70.9492 Fuel Consumption: 44.0861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.006\n",
      "Episode: 174 Exploration P: 0.0195 Total reward: -535.2999085029328 SOC: 0.4497 Cumulative_SOC_deviation: 124.4146 Fuel Consumption: 37.6417\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.910\n",
      "Episode: 175 Exploration P: 0.0192 Total reward: -769.2697732072432 SOC: 0.4488 Cumulative_SOC_deviation: 182.5503 Fuel Consumption: 39.0687\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.570\n",
      "Episode: 176 Exploration P: 0.0190 Total reward: -733.6073106922912 SOC: 0.4935 Cumulative_SOC_deviation: 172.1673 Fuel Consumption: 44.9380\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.942\n",
      "Episode: 177 Exploration P: 0.0187 Total reward: -621.5776636192454 SOC: 0.4291 Cumulative_SOC_deviation: 146.1859 Fuel Consumption: 36.8342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.602\n",
      "Episode: 178 Exploration P: 0.0185 Total reward: -852.9020688271628 SOC: 0.4469 Cumulative_SOC_deviation: 203.4250 Fuel Consumption: 39.2020\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.961\n",
      "Episode: 179 Exploration P: 0.0182 Total reward: -819.4706928077323 SOC: 0.4189 Cumulative_SOC_deviation: 195.8308 Fuel Consumption: 36.1476\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.942\n",
      "Episode: 180 Exploration P: 0.0180 Total reward: -860.6062654832814 SOC: 0.4368 Cumulative_SOC_deviation: 205.7603 Fuel Consumption: 37.5649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.954\n",
      "Episode: 181 Exploration P: 0.0178 Total reward: -843.1898796225879 SOC: 0.4370 Cumulative_SOC_deviation: 201.4083 Fuel Consumption: 37.5567\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.733\n",
      "Episode: 182 Exploration P: 0.0176 Total reward: -420.783652553998 SOC: 0.4777 Cumulative_SOC_deviation: 95.0280 Fuel Consumption: 40.6717\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.798\n",
      "Episode: 183 Exploration P: 0.0174 Total reward: -928.9551690310274 SOC: 0.4134 Cumulative_SOC_deviation: 223.4473 Fuel Consumption: 35.1658\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.559\n",
      "Episode: 184 Exploration P: 0.0172 Total reward: -925.4627793999324 SOC: 0.4167 Cumulative_SOC_deviation: 222.4801 Fuel Consumption: 35.5425\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.903\n",
      "Episode: 185 Exploration P: 0.0170 Total reward: -881.4677261272259 SOC: 0.3745 Cumulative_SOC_deviation: 212.2402 Fuel Consumption: 32.5069\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.113\n",
      "Episode: 186 Exploration P: 0.0168 Total reward: -1146.1924084650016 SOC: 0.3503 Cumulative_SOC_deviation: 278.4332 Fuel Consumption: 32.4595\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.746\n",
      "Episode: 187 Exploration P: 0.0166 Total reward: -1008.1974008130163 SOC: 0.3621 Cumulative_SOC_deviation: 243.5987 Fuel Consumption: 33.8028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.087\n",
      "Episode: 188 Exploration P: 0.0164 Total reward: -930.3628053187614 SOC: 0.4276 Cumulative_SOC_deviation: 223.3258 Fuel Consumption: 37.0596\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.813\n",
      "Episode: 189 Exploration P: 0.0163 Total reward: -1228.4501375719524 SOC: 0.3266 Cumulative_SOC_deviation: 299.6507 Fuel Consumption: 29.8474\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.591\n",
      "Episode: 190 Exploration P: 0.0161 Total reward: -1500.1654722428632 SOC: 0.3539 Cumulative_SOC_deviation: 366.4882 Fuel Consumption: 34.2126\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.933\n",
      "Episode: 191 Exploration P: 0.0159 Total reward: -1193.2135967090705 SOC: 0.3070 Cumulative_SOC_deviation: 291.3527 Fuel Consumption: 27.8030\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.742\n",
      "Episode: 192 Exploration P: 0.0158 Total reward: -309.0318804213021 SOC: 0.5781 Cumulative_SOC_deviation: 66.0505 Fuel Consumption: 44.8297\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.894\n",
      "Episode: 193 Exploration P: 0.0156 Total reward: -222.44846613211408 SOC: 0.5625 Cumulative_SOC_deviation: 44.7638 Fuel Consumption: 43.3932\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.720\n",
      "Episode: 194 Exploration P: 0.0155 Total reward: -120.77169504905999 SOC: 0.5789 Cumulative_SOC_deviation: 19.0982 Fuel Consumption: 44.3791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.968\n",
      "Episode: 195 Exploration P: 0.0153 Total reward: -253.67945354220834 SOC: 0.5522 Cumulative_SOC_deviation: 52.7559 Fuel Consumption: 42.6559\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.078\n",
      "Episode: 196 Exploration P: 0.0152 Total reward: -295.6657341298206 SOC: 0.5481 Cumulative_SOC_deviation: 63.1329 Fuel Consumption: 43.1342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.583\n",
      "Episode: 197 Exploration P: 0.0150 Total reward: -315.76552615019324 SOC: 0.5512 Cumulative_SOC_deviation: 67.8761 Fuel Consumption: 44.2611\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.813\n",
      "Episode: 198 Exploration P: 0.0149 Total reward: -351.8546819336117 SOC: 0.5411 Cumulative_SOC_deviation: 77.2524 Fuel Consumption: 42.8451\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.908\n",
      "Episode: 199 Exploration P: 0.0148 Total reward: -348.6462801400623 SOC: 0.5491 Cumulative_SOC_deviation: 76.3341 Fuel Consumption: 43.3100\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.030\n",
      "Episode: 200 Exploration P: 0.0146 Total reward: -336.83182417174737 SOC: 0.5434 Cumulative_SOC_deviation: 73.4842 Fuel Consumption: 42.8950\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 5\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.653\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -2656.4756920996047 SOC: 1.0000 Cumulative_SOC_deviation: 500.4395 Fuel Consumption: 154.2780\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.320\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -2645.02857459843 SOC: 1.0000 Cumulative_SOC_deviation: 499.0561 Fuel Consumption: 149.7483\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.280\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -2591.9405609170008 SOC: 1.0000 Cumulative_SOC_deviation: 488.6118 Fuel Consumption: 148.8816\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 44.460\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -2624.5735826696705 SOC: 1.0000 Cumulative_SOC_deviation: 495.7699 Fuel Consumption: 145.7242\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.903\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -2632.3557927550078 SOC: 1.0000 Cumulative_SOC_deviation: 496.4678 Fuel Consumption: 150.0166\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.374\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -2595.567227559473 SOC: 1.0000 Cumulative_SOC_deviation: 490.2905 Fuel Consumption: 144.1146\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.740\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -2599.987306355295 SOC: 1.0000 Cumulative_SOC_deviation: 490.6153 Fuel Consumption: 146.9108\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.607\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -2601.3526313811108 SOC: 1.0000 Cumulative_SOC_deviation: 492.4031 Fuel Consumption: 139.3373\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.492\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -2574.139095431742 SOC: 1.0000 Cumulative_SOC_deviation: 487.4371 Fuel Consumption: 136.9538\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.186\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -2525.458402406882 SOC: 1.0000 Cumulative_SOC_deviation: 478.4995 Fuel Consumption: 132.9607\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.151\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2495.111771640862 SOC: 1.0000 Cumulative_SOC_deviation: 473.0761 Fuel Consumption: 129.7311\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.305\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2480.1868531682053 SOC: 1.0000 Cumulative_SOC_deviation: 470.7928 Fuel Consumption: 126.2229\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.055\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2508.5422505281017 SOC: 1.0000 Cumulative_SOC_deviation: 476.1275 Fuel Consumption: 127.9048\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.694\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2448.1200590562994 SOC: 1.0000 Cumulative_SOC_deviation: 465.2441 Fuel Consumption: 121.8996\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.493\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2380.259863486324 SOC: 1.0000 Cumulative_SOC_deviation: 452.5429 Fuel Consumption: 117.5454\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.124\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2365.643805148287 SOC: 1.0000 Cumulative_SOC_deviation: 449.3906 Fuel Consumption: 118.6907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.133\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2335.666539418816 SOC: 1.0000 Cumulative_SOC_deviation: 443.5623 Fuel Consumption: 117.8549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.846\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -2354.9551997871104 SOC: 1.0000 Cumulative_SOC_deviation: 448.4581 Fuel Consumption: 112.6649\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.514\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -2241.8710356102147 SOC: 1.0000 Cumulative_SOC_deviation: 426.3778 Fuel Consumption: 109.9822\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.198\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -2114.276669867553 SOC: 1.0000 Cumulative_SOC_deviation: 401.4223 Fuel Consumption: 107.1653\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.299\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2156.895621680585 SOC: 1.0000 Cumulative_SOC_deviation: 410.1256 Fuel Consumption: 106.2677\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.619\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2169.093593164264 SOC: 1.0000 Cumulative_SOC_deviation: 412.7674 Fuel Consumption: 105.2565\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.982\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2180.1591593544085 SOC: 1.0000 Cumulative_SOC_deviation: 415.4118 Fuel Consumption: 103.1000\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.649\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -1985.9072679914448 SOC: 1.0000 Cumulative_SOC_deviation: 377.0753 Fuel Consumption: 100.5308\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.095\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -2068.9294172250593 SOC: 1.0000 Cumulative_SOC_deviation: 393.8386 Fuel Consumption: 99.7363\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.746\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -1978.664912242661 SOC: 1.0000 Cumulative_SOC_deviation: 375.9302 Fuel Consumption: 99.0140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.443\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -1977.8626095501943 SOC: 1.0000 Cumulative_SOC_deviation: 375.6934 Fuel Consumption: 99.3958\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.759\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -1739.0081933253748 SOC: 1.0000 Cumulative_SOC_deviation: 328.8098 Fuel Consumption: 94.9590\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.216\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -1613.5957677785818 SOC: 1.0000 Cumulative_SOC_deviation: 304.6292 Fuel Consumption: 90.4500\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.827\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -1814.9731734797251 SOC: 1.0000 Cumulative_SOC_deviation: 344.2773 Fuel Consumption: 93.5867\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.847\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -1625.465447112126 SOC: 1.0000 Cumulative_SOC_deviation: 307.4880 Fuel Consumption: 88.0252\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.691\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -1704.3681783817003 SOC: 1.0000 Cumulative_SOC_deviation: 322.9900 Fuel Consumption: 89.4181\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.965\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1539.9336617017036 SOC: 1.0000 Cumulative_SOC_deviation: 290.6169 Fuel Consumption: 86.8489\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.405\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1557.7660233741133 SOC: 1.0000 Cumulative_SOC_deviation: 293.8986 Fuel Consumption: 88.2728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.876\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1369.5156901095786 SOC: 1.0000 Cumulative_SOC_deviation: 256.1763 Fuel Consumption: 88.6340\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.142\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1434.1180929136717 SOC: 1.0000 Cumulative_SOC_deviation: 269.7881 Fuel Consumption: 85.1774\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.997\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -1163.126696636568 SOC: 1.0000 Cumulative_SOC_deviation: 215.6208 Fuel Consumption: 85.0226\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.259\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1258.7095088851195 SOC: 1.0000 Cumulative_SOC_deviation: 234.8385 Fuel Consumption: 84.5170\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.721\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1295.5419174461608 SOC: 1.0000 Cumulative_SOC_deviation: 242.4051 Fuel Consumption: 83.5162\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.846\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1330.7683702268323 SOC: 1.0000 Cumulative_SOC_deviation: 249.2977 Fuel Consumption: 84.2797\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.873\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -787.1159176347182 SOC: 0.8661 Cumulative_SOC_deviation: 142.5442 Fuel Consumption: 74.3949\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.921\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -916.5903425180933 SOC: 0.9569 Cumulative_SOC_deviation: 167.0255 Fuel Consumption: 81.4629\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.086\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -880.6172906775464 SOC: 0.9196 Cumulative_SOC_deviation: 160.4644 Fuel Consumption: 78.2952\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.941\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -642.1544954359259 SOC: 0.8767 Cumulative_SOC_deviation: 113.4446 Fuel Consumption: 74.9315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.937\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -658.6669644363444 SOC: 0.8761 Cumulative_SOC_deviation: 116.7244 Fuel Consumption: 75.0450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.058\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -769.5242815682 SOC: 0.8899 Cumulative_SOC_deviation: 138.6668 Fuel Consumption: 76.1903\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.189\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -473.96599005924605 SOC: 0.7854 Cumulative_SOC_deviation: 81.1462 Fuel Consumption: 68.2350\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.641\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -483.23909233872126 SOC: 0.7925 Cumulative_SOC_deviation: 82.9286 Fuel Consumption: 68.5961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.760\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -472.0133322981189 SOC: 0.7909 Cumulative_SOC_deviation: 80.7268 Fuel Consumption: 68.3795\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.745\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -430.5136931487769 SOC: 0.7106 Cumulative_SOC_deviation: 73.5660 Fuel Consumption: 62.6838\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.074\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -556.946686549515 SOC: 0.6795 Cumulative_SOC_deviation: 99.2323 Fuel Consumption: 60.7853\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.885\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -452.88793466012874 SOC: 0.7429 Cumulative_SOC_deviation: 77.5703 Fuel Consumption: 65.0364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.148\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -723.684465148003 SOC: 0.6175 Cumulative_SOC_deviation: 133.5724 Fuel Consumption: 55.8223\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.163\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -663.2622937890385 SOC: 0.6082 Cumulative_SOC_deviation: 121.7294 Fuel Consumption: 54.6151\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.276\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -416.6568748820125 SOC: 0.6200 Cumulative_SOC_deviation: 72.2041 Fuel Consumption: 55.6366\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.116\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -788.9650114587511 SOC: 0.5471 Cumulative_SOC_deviation: 147.6583 Fuel Consumption: 50.6735\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.022\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -861.2745741490006 SOC: 0.5143 Cumulative_SOC_deviation: 162.6568 Fuel Consumption: 47.9908\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.818\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -972.0168335280708 SOC: 0.4728 Cumulative_SOC_deviation: 185.3170 Fuel Consumption: 45.4319\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.122\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -1039.0989566623946 SOC: 0.4751 Cumulative_SOC_deviation: 198.7499 Fuel Consumption: 45.3494\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.999\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -944.1703830705922 SOC: 0.4840 Cumulative_SOC_deviation: 179.6363 Fuel Consumption: 45.9891\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.147\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -810.2613779228825 SOC: 0.5383 Cumulative_SOC_deviation: 152.0146 Fuel Consumption: 50.1886\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.997\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -893.1395240693337 SOC: 0.4955 Cumulative_SOC_deviation: 169.2175 Fuel Consumption: 47.0519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.389\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -1115.078191835599 SOC: 0.4509 Cumulative_SOC_deviation: 214.2491 Fuel Consumption: 43.8326\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.609\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -1241.3504146945786 SOC: 0.4073 Cumulative_SOC_deviation: 240.1536 Fuel Consumption: 40.5824\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.350\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -1218.5091228805893 SOC: 0.4293 Cumulative_SOC_deviation: 235.2861 Fuel Consumption: 42.0785\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.210\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -974.6579497573591 SOC: 0.4722 Cumulative_SOC_deviation: 185.9236 Fuel Consumption: 45.0398\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.325\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -1228.1810461757127 SOC: 0.3946 Cumulative_SOC_deviation: 237.8334 Fuel Consumption: 39.0140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.890\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -1234.6983185537163 SOC: 0.4079 Cumulative_SOC_deviation: 238.8665 Fuel Consumption: 40.3657\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.146\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -1459.9986779019368 SOC: 0.3198 Cumulative_SOC_deviation: 285.2102 Fuel Consumption: 33.9478\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.963\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -1457.6282449416537 SOC: 0.3694 Cumulative_SOC_deviation: 283.9148 Fuel Consumption: 38.0545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.209\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -1663.4779591766592 SOC: 0.3156 Cumulative_SOC_deviation: 325.9122 Fuel Consumption: 33.9169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.351\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -1763.743985974031 SOC: 0.2755 Cumulative_SOC_deviation: 346.5164 Fuel Consumption: 31.1619\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.151\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -1720.399208688137 SOC: 0.3165 Cumulative_SOC_deviation: 337.1892 Fuel Consumption: 34.4534\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.562\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -1560.917557646767 SOC: 0.3089 Cumulative_SOC_deviation: 305.5116 Fuel Consumption: 33.3597\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.214\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -1683.7774395239403 SOC: 0.2970 Cumulative_SOC_deviation: 330.2899 Fuel Consumption: 32.3279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.169\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -1982.0075570251756 SOC: 0.2553 Cumulative_SOC_deviation: 390.2393 Fuel Consumption: 30.8111\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.302\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -1827.1305004020567 SOC: 0.2555 Cumulative_SOC_deviation: 359.4248 Fuel Consumption: 30.0063\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.207\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -1801.7515078432646 SOC: 0.2774 Cumulative_SOC_deviation: 354.0436 Fuel Consumption: 31.5334\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.192\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -1718.4381745260782 SOC: 0.2670 Cumulative_SOC_deviation: 337.5873 Fuel Consumption: 30.5016\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.634\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -1972.516187995381 SOC: 0.1913 Cumulative_SOC_deviation: 389.3625 Fuel Consumption: 25.7036\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.132\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -1833.497428384188 SOC: 0.2066 Cumulative_SOC_deviation: 361.4267 Fuel Consumption: 26.3640\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.165\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -1933.8325826459497 SOC: 0.2112 Cumulative_SOC_deviation: 381.4318 Fuel Consumption: 26.6735\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.280\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -2097.7171255179887 SOC: 0.1801 Cumulative_SOC_deviation: 414.5389 Fuel Consumption: 25.0226\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.012\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -2003.3367791402654 SOC: 0.2034 Cumulative_SOC_deviation: 395.3780 Fuel Consumption: 26.4465\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.213\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -2218.396100515377 SOC: 0.1500 Cumulative_SOC_deviation: 439.1411 Fuel Consumption: 22.6907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.559\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -2063.579837518101 SOC: 0.1669 Cumulative_SOC_deviation: 407.9838 Fuel Consumption: 23.6606\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.431\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -2326.1868001642983 SOC: 0.1208 Cumulative_SOC_deviation: 461.0913 Fuel Consumption: 20.7303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.216\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -2326.951308269698 SOC: 0.1162 Cumulative_SOC_deviation: 461.3247 Fuel Consumption: 20.3279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.857\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -2268.897189146922 SOC: 0.1088 Cumulative_SOC_deviation: 449.8253 Fuel Consumption: 19.7707\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.113\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -2333.7775368280036 SOC: 0.1323 Cumulative_SOC_deviation: 462.3329 Fuel Consumption: 22.1129\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.611\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -2090.781442084839 SOC: 0.1674 Cumulative_SOC_deviation: 413.3891 Fuel Consumption: 23.8361\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.231\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -2235.0530795524987 SOC: 0.1161 Cumulative_SOC_deviation: 442.8996 Fuel Consumption: 20.5549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.346\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -2313.5114443610955 SOC: 0.0971 Cumulative_SOC_deviation: 458.8513 Fuel Consumption: 19.2548\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.756\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -2277.603875897841 SOC: 0.1347 Cumulative_SOC_deviation: 451.1003 Fuel Consumption: 22.1026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.377\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -2399.8910294171183 SOC: 0.1021 Cumulative_SOC_deviation: 476.0468 Fuel Consumption: 19.6572\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.790\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -2360.2210457494484 SOC: 0.1015 Cumulative_SOC_deviation: 468.1251 Fuel Consumption: 19.5953\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.113\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -2235.8526893415724 SOC: 0.1154 Cumulative_SOC_deviation: 443.0431 Fuel Consumption: 20.6374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.659\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -2505.52871715464 SOC: 0.0870 Cumulative_SOC_deviation: 497.3105 Fuel Consumption: 18.9762\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.358\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -2472.4352349830847 SOC: 0.0686 Cumulative_SOC_deviation: 491.0096 Fuel Consumption: 17.3872\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.234\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -2372.5895588332664 SOC: 0.0697 Cumulative_SOC_deviation: 471.1189 Fuel Consumption: 16.9951\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.662\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -2568.090731959146 SOC: 0.0286 Cumulative_SOC_deviation: 510.6814 Fuel Consumption: 14.6839\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.917\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -2587.746625695416 SOC: 0.0559 Cumulative_SOC_deviation: 514.2390 Fuel Consumption: 16.5515\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.079\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -2760.2501889822697 SOC: 0.0118 Cumulative_SOC_deviation: 549.2742 Fuel Consumption: 13.8791\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.461\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -2371.9763471315896 SOC: 0.0706 Cumulative_SOC_deviation: 470.8869 Fuel Consumption: 17.5420\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.384\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -2373.420271586062 SOC: 0.0838 Cumulative_SOC_deviation: 470.9693 Fuel Consumption: 18.5738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.290\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -2339.1844193113748 SOC: 0.0699 Cumulative_SOC_deviation: 464.4234 Fuel Consumption: 17.0674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.358\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -2609.9782904795848 SOC: 0.0189 Cumulative_SOC_deviation: 519.2983 Fuel Consumption: 13.4870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.951\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -2582.52080655189 SOC: 0.0436 Cumulative_SOC_deviation: 513.3610 Fuel Consumption: 15.7157\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.162\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -2556.617633838519 SOC: 0.0557 Cumulative_SOC_deviation: 507.9947 Fuel Consumption: 16.6443\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.001\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -2547.7900166363906 SOC: 0.0336 Cumulative_SOC_deviation: 506.5387 Fuel Consumption: 15.0966\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.830\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -2669.599233546034 SOC: 0.0257 Cumulative_SOC_deviation: 531.0636 Fuel Consumption: 14.2815\n",
      "\n",
      "battery power is 7139.380133788138(+) but condition is not avail\n",
      "elapsed_time: 81.647\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -3567.608614152121 SOC: -0.0003 Cumulative_SOC_deviation: 511.5733 Fuel Consumption: 12.7439\n",
      "\n",
      "battery power is 3655.3643776957547(+) but condition is not avail\n",
      "elapsed_time: 79.008\n",
      "Episode: 113 Exploration P: 0.0592 Total reward: -3475.7873470153713 SOC: -0.0017 Cumulative_SOC_deviation: 493.2662 Fuel Consumption: 12.4649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.151\n",
      "Episode: 114 Exploration P: 0.0579 Total reward: -2546.8269306295765 SOC: 0.0308 Cumulative_SOC_deviation: 506.4410 Fuel Consumption: 14.6220\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.192\n",
      "Episode: 115 Exploration P: 0.0566 Total reward: -2578.9685480658236 SOC: 0.0375 Cumulative_SOC_deviation: 512.7538 Fuel Consumption: 15.1998\n",
      "\n",
      "battery power is 5967.407130477593(+) but condition is not avail\n",
      "elapsed_time: 77.111\n",
      "Episode: 116 Exploration P: 0.0554 Total reward: -3481.8370004385433 SOC: -0.0001 Cumulative_SOC_deviation: 494.6912 Fuel Consumption: 11.3812\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.993\n",
      "Episode: 117 Exploration P: 0.0542 Total reward: -2630.1859179145326 SOC: 0.0366 Cumulative_SOC_deviation: 522.9477 Fuel Consumption: 15.4474\n",
      "\n",
      "battery power is 6389.012279833689(+) but condition is not avail\n",
      "elapsed_time: 76.570\n",
      "Episode: 118 Exploration P: 0.0531 Total reward: -3413.2641110743407 SOC: -0.0008 Cumulative_SOC_deviation: 481.0186 Fuel Consumption: 11.1749\n",
      "\n",
      "battery power is 7208.837406280526(+) but condition is not avail\n",
      "elapsed_time: 77.475\n",
      "Episode: 119 Exploration P: 0.0520 Total reward: -3465.8703605585615 SOC: -0.0001 Cumulative_SOC_deviation: 491.5536 Fuel Consumption: 11.1027\n",
      "\n",
      "battery power is 4683.758077049461(+) but condition is not avail\n",
      "elapsed_time: 73.678\n",
      "Episode: 120 Exploration P: 0.0510 Total reward: -3310.5160098886163 SOC: -0.0002 Cumulative_SOC_deviation: 460.6522 Fuel Consumption: 10.2561\n",
      "\n",
      "battery power is 4361.155321061076(+) but condition is not avail\n",
      "elapsed_time: 68.365\n",
      "Episode: 121 Exploration P: 0.0501 Total reward: -3078.0195241835067 SOC: -0.0001 Cumulative_SOC_deviation: 414.4996 Fuel Consumption: 8.5219\n",
      "\n",
      "battery power is 2519.560807434138(+) but condition is not avail\n",
      "elapsed_time: 71.304\n",
      "Episode: 122 Exploration P: 0.0491 Total reward: -3213.511356779271 SOC: -0.0004 Cumulative_SOC_deviation: 441.3671 Fuel Consumption: 9.6779\n",
      "\n",
      "battery power is 4361.155321061076(+) but condition is not avail\n",
      "elapsed_time: 68.126\n",
      "Episode: 123 Exploration P: 0.0483 Total reward: -3013.664236349451 SOC: -0.0010 Cumulative_SOC_deviation: 401.7037 Fuel Consumption: 8.1504\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.172\n",
      "Episode: 124 Exploration P: 0.0472 Total reward: -2557.514604963761 SOC: 0.0240 Cumulative_SOC_deviation: 508.6404 Fuel Consumption: 14.3124\n",
      "\n",
      "battery power is 10284.373943168403(+) but condition is not avail\n",
      "elapsed_time: 67.683\n",
      "Episode: 125 Exploration P: 0.0464 Total reward: -3022.155634734221 SOC: -0.0003 Cumulative_SOC_deviation: 403.5273 Fuel Consumption: 7.5209\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.452\n",
      "Episode: 126 Exploration P: 0.0454 Total reward: -2591.3211316536986 SOC: 0.0224 Cumulative_SOC_deviation: 515.4244 Fuel Consumption: 14.1989\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.482\n",
      "Episode: 127 Exploration P: 0.0445 Total reward: -1757.5907817149537 SOC: 0.5868 Cumulative_SOC_deviation: 340.0974 Fuel Consumption: 57.1037\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.514\n",
      "Episode: 128 Exploration P: 0.0435 Total reward: -109.86754744010292 SOC: 0.6020 Cumulative_SOC_deviation: 12.1217 Fuel Consumption: 49.2593\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.613\n",
      "Episode: 129 Exploration P: 0.0426 Total reward: -103.42623403432076 SOC: 0.6033 Cumulative_SOC_deviation: 10.7624 Fuel Consumption: 49.6142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.458\n",
      "Episode: 130 Exploration P: 0.0417 Total reward: -180.48144932033435 SOC: 0.5822 Cumulative_SOC_deviation: 26.3783 Fuel Consumption: 48.5899\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.090\n",
      "Episode: 131 Exploration P: 0.0409 Total reward: -184.88205985354324 SOC: 0.5780 Cumulative_SOC_deviation: 27.3220 Fuel Consumption: 48.2721\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.271\n",
      "Episode: 132 Exploration P: 0.0401 Total reward: -358.5627570412195 SOC: 0.5018 Cumulative_SOC_deviation: 63.0389 Fuel Consumption: 43.3684\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.018\n",
      "Episode: 133 Exploration P: 0.0392 Total reward: -536.9334698683141 SOC: 0.5448 Cumulative_SOC_deviation: 98.2961 Fuel Consumption: 45.4532\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.077\n",
      "Episode: 134 Exploration P: 0.0384 Total reward: -289.6528800391858 SOC: 0.5918 Cumulative_SOC_deviation: 48.5301 Fuel Consumption: 47.0026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.138\n",
      "Episode: 135 Exploration P: 0.0377 Total reward: -116.02894554996223 SOC: 0.5954 Cumulative_SOC_deviation: 13.7145 Fuel Consumption: 47.4564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.981\n",
      "Episode: 136 Exploration P: 0.0369 Total reward: -126.04713360489622 SOC: 0.5957 Cumulative_SOC_deviation: 15.8080 Fuel Consumption: 47.0070\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.114\n",
      "Episode: 137 Exploration P: 0.0362 Total reward: -172.19662924575908 SOC: 0.5845 Cumulative_SOC_deviation: 25.1291 Fuel Consumption: 46.5513\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.938\n",
      "Episode: 138 Exploration P: 0.0355 Total reward: -246.9720868070362 SOC: 0.5746 Cumulative_SOC_deviation: 40.0943 Fuel Consumption: 46.5005\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.719\n",
      "Episode: 139 Exploration P: 0.0348 Total reward: -156.00139523591412 SOC: 0.5788 Cumulative_SOC_deviation: 22.0092 Fuel Consumption: 45.9553\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.353\n",
      "Episode: 140 Exploration P: 0.0341 Total reward: -186.08034455548386 SOC: 0.5938 Cumulative_SOC_deviation: 27.8286 Fuel Consumption: 46.9373\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.511\n",
      "Episode: 141 Exploration P: 0.0335 Total reward: -212.62421303384517 SOC: 0.5776 Cumulative_SOC_deviation: 32.9928 Fuel Consumption: 47.6601\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.495\n",
      "Episode: 142 Exploration P: 0.0328 Total reward: -957.9551826214317 SOC: 0.4511 Cumulative_SOC_deviation: 183.3957 Fuel Consumption: 40.9769\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.290\n",
      "Episode: 143 Exploration P: 0.0322 Total reward: -895.31896506485 SOC: 0.4142 Cumulative_SOC_deviation: 171.2137 Fuel Consumption: 39.2507\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.075\n",
      "Episode: 144 Exploration P: 0.0316 Total reward: -795.071347622202 SOC: 0.3703 Cumulative_SOC_deviation: 151.9408 Fuel Consumption: 35.3676\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.847\n",
      "Episode: 145 Exploration P: 0.0310 Total reward: -348.1163735064891 SOC: 0.5479 Cumulative_SOC_deviation: 60.1268 Fuel Consumption: 47.4823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.915\n",
      "Episode: 146 Exploration P: 0.0305 Total reward: -729.8814391985709 SOC: 0.4477 Cumulative_SOC_deviation: 137.9135 Fuel Consumption: 40.3140\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.895\n",
      "Episode: 147 Exploration P: 0.0299 Total reward: -783.7159194772571 SOC: 0.5673 Cumulative_SOC_deviation: 147.1807 Fuel Consumption: 47.8123\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.310\n",
      "Episode: 148 Exploration P: 0.0294 Total reward: -374.79251348587655 SOC: 0.5432 Cumulative_SOC_deviation: 65.2596 Fuel Consumption: 48.4943\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.948\n",
      "Episode: 149 Exploration P: 0.0288 Total reward: -310.65236570130116 SOC: 0.5784 Cumulative_SOC_deviation: 52.0514 Fuel Consumption: 50.3955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.058\n",
      "Episode: 150 Exploration P: 0.0283 Total reward: -402.5590865883303 SOC: 0.5646 Cumulative_SOC_deviation: 70.9730 Fuel Consumption: 47.6941\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.990\n",
      "Episode: 151 Exploration P: 0.0278 Total reward: -773.2038798766373 SOC: 0.4303 Cumulative_SOC_deviation: 146.7613 Fuel Consumption: 39.3972\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.513\n",
      "Episode: 152 Exploration P: 0.0274 Total reward: -905.8155984728986 SOC: 0.4893 Cumulative_SOC_deviation: 171.9197 Fuel Consumption: 46.2170\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.602\n",
      "Episode: 153 Exploration P: 0.0269 Total reward: -1275.0695273401009 SOC: 0.3676 Cumulative_SOC_deviation: 247.9944 Fuel Consumption: 35.0974\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.155\n",
      "Episode: 154 Exploration P: 0.0264 Total reward: -1113.7071501574806 SOC: 0.5840 Cumulative_SOC_deviation: 212.4381 Fuel Consumption: 51.5165\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.201\n",
      "Episode: 155 Exploration P: 0.0260 Total reward: -181.13006185022476 SOC: 0.5839 Cumulative_SOC_deviation: 26.1770 Fuel Consumption: 50.2450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.295\n",
      "Episode: 156 Exploration P: 0.0255 Total reward: -1036.913069825337 SOC: 0.5144 Cumulative_SOC_deviation: 198.6520 Fuel Consumption: 43.6532\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.557\n",
      "Episode: 157 Exploration P: 0.0251 Total reward: -594.6860224932535 SOC: 0.5804 Cumulative_SOC_deviation: 108.7414 Fuel Consumption: 50.9788\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.044\n",
      "Episode: 158 Exploration P: 0.0247 Total reward: -399.8424926992604 SOC: 0.4769 Cumulative_SOC_deviation: 71.8178 Fuel Consumption: 40.7537\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.204\n",
      "Episode: 159 Exploration P: 0.0243 Total reward: -235.02973646773492 SOC: 0.5796 Cumulative_SOC_deviation: 36.7058 Fuel Consumption: 51.5006\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.714\n",
      "Episode: 160 Exploration P: 0.0239 Total reward: -610.6432537279697 SOC: 0.4330 Cumulative_SOC_deviation: 114.6041 Fuel Consumption: 37.6226\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.752\n",
      "Episode: 161 Exploration P: 0.0236 Total reward: -372.06653739735026 SOC: 0.5400 Cumulative_SOC_deviation: 65.2220 Fuel Consumption: 45.9563\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.608\n",
      "Episode: 162 Exploration P: 0.0232 Total reward: -597.5979378109456 SOC: 0.5649 Cumulative_SOC_deviation: 110.3452 Fuel Consumption: 45.8722\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.768\n",
      "Episode: 163 Exploration P: 0.0228 Total reward: -477.06876156850984 SOC: 0.5865 Cumulative_SOC_deviation: 85.2531 Fuel Consumption: 50.8030\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.029\n",
      "Episode: 164 Exploration P: 0.0225 Total reward: -560.6789510170678 SOC: 0.5911 Cumulative_SOC_deviation: 102.1541 Fuel Consumption: 49.9082\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.274\n",
      "Episode: 165 Exploration P: 0.0221 Total reward: -560.9911437950045 SOC: 0.4667 Cumulative_SOC_deviation: 104.3758 Fuel Consumption: 39.1120\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.785\n",
      "Episode: 166 Exploration P: 0.0218 Total reward: -840.3786896556194 SOC: 0.5649 Cumulative_SOC_deviation: 158.5423 Fuel Consumption: 47.6674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.484\n",
      "Episode: 167 Exploration P: 0.0215 Total reward: -347.0133690821025 SOC: 0.5758 Cumulative_SOC_deviation: 60.0117 Fuel Consumption: 46.9547\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.940\n",
      "Episode: 168 Exploration P: 0.0212 Total reward: -383.786526505324 SOC: 0.5401 Cumulative_SOC_deviation: 68.1724 Fuel Consumption: 42.9245\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.703\n",
      "Episode: 169 Exploration P: 0.0209 Total reward: -351.8935763889301 SOC: 0.5706 Cumulative_SOC_deviation: 61.3033 Fuel Consumption: 45.3771\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.368\n",
      "Episode: 170 Exploration P: 0.0206 Total reward: -479.5585399680437 SOC: 0.5095 Cumulative_SOC_deviation: 87.2755 Fuel Consumption: 43.1810\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.622\n",
      "Episode: 171 Exploration P: 0.0203 Total reward: -293.15057922524187 SOC: 0.5769 Cumulative_SOC_deviation: 49.2587 Fuel Consumption: 46.8572\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.781\n",
      "Episode: 172 Exploration P: 0.0200 Total reward: -752.1245022158126 SOC: 0.5740 Cumulative_SOC_deviation: 140.6222 Fuel Consumption: 49.0135\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.726\n",
      "Episode: 173 Exploration P: 0.0197 Total reward: -241.83524248179327 SOC: 0.5801 Cumulative_SOC_deviation: 39.1989 Fuel Consumption: 45.8406\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.530\n",
      "Episode: 174 Exploration P: 0.0195 Total reward: -264.7516263103247 SOC: 0.5707 Cumulative_SOC_deviation: 43.9777 Fuel Consumption: 44.8630\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.715\n",
      "Episode: 175 Exploration P: 0.0192 Total reward: -309.42457558898525 SOC: 0.5615 Cumulative_SOC_deviation: 52.7884 Fuel Consumption: 45.4823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.360\n",
      "Episode: 176 Exploration P: 0.0190 Total reward: -303.9783686858641 SOC: 0.5639 Cumulative_SOC_deviation: 51.7025 Fuel Consumption: 45.4659\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.802\n",
      "Episode: 177 Exploration P: 0.0187 Total reward: -333.97894989457944 SOC: 0.5587 Cumulative_SOC_deviation: 57.8561 Fuel Consumption: 44.6982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.272\n",
      "Episode: 178 Exploration P: 0.0185 Total reward: -326.90023427692773 SOC: 0.5608 Cumulative_SOC_deviation: 56.4851 Fuel Consumption: 44.4749\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.761\n",
      "Episode: 179 Exploration P: 0.0183 Total reward: -347.8145699035625 SOC: 0.5625 Cumulative_SOC_deviation: 60.5441 Fuel Consumption: 45.0939\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.621\n",
      "Episode: 180 Exploration P: 0.0180 Total reward: -598.7680393416542 SOC: 0.5121 Cumulative_SOC_deviation: 111.2892 Fuel Consumption: 42.3221\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.574\n",
      "Episode: 181 Exploration P: 0.0178 Total reward: -290.6955099274706 SOC: 0.5500 Cumulative_SOC_deviation: 49.2705 Fuel Consumption: 44.3432\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.449\n",
      "Episode: 182 Exploration P: 0.0176 Total reward: -273.0150177609702 SOC: 0.5615 Cumulative_SOC_deviation: 45.6322 Fuel Consumption: 44.8540\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.016\n",
      "Episode: 183 Exploration P: 0.0174 Total reward: -316.58858182140074 SOC: 0.5685 Cumulative_SOC_deviation: 54.4660 Fuel Consumption: 44.2586\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.225\n",
      "Episode: 184 Exploration P: 0.0172 Total reward: -291.9938047836299 SOC: 0.5712 Cumulative_SOC_deviation: 49.5273 Fuel Consumption: 44.3575\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.702\n",
      "Episode: 185 Exploration P: 0.0170 Total reward: -322.63727192059997 SOC: 0.5750 Cumulative_SOC_deviation: 55.2304 Fuel Consumption: 46.4854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.641\n",
      "Episode: 186 Exploration P: 0.0168 Total reward: -311.650974967043 SOC: 0.5410 Cumulative_SOC_deviation: 53.8112 Fuel Consumption: 42.5950\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.415\n",
      "Episode: 187 Exploration P: 0.0166 Total reward: -273.2298367165369 SOC: 0.5823 Cumulative_SOC_deviation: 45.6110 Fuel Consumption: 45.1750\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.337\n",
      "Episode: 188 Exploration P: 0.0165 Total reward: -285.98355545610355 SOC: 0.5563 Cumulative_SOC_deviation: 48.6195 Fuel Consumption: 42.8862\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.626\n",
      "Episode: 189 Exploration P: 0.0163 Total reward: -671.51808051008 SOC: 0.5495 Cumulative_SOC_deviation: 125.0328 Fuel Consumption: 46.3540\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.470\n",
      "Episode: 190 Exploration P: 0.0161 Total reward: -577.001443472895 SOC: 0.5076 Cumulative_SOC_deviation: 106.8485 Fuel Consumption: 42.7589\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.480\n",
      "Episode: 191 Exploration P: 0.0159 Total reward: -267.89100925216025 SOC: 0.5809 Cumulative_SOC_deviation: 44.3500 Fuel Consumption: 46.1410\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.752\n",
      "Episode: 192 Exploration P: 0.0158 Total reward: -245.88551571648182 SOC: 0.5766 Cumulative_SOC_deviation: 40.2306 Fuel Consumption: 44.7327\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.339\n",
      "Episode: 193 Exploration P: 0.0156 Total reward: -613.366719142989 SOC: 0.5352 Cumulative_SOC_deviation: 113.6454 Fuel Consumption: 45.1396\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.337\n",
      "Episode: 194 Exploration P: 0.0155 Total reward: -405.14904158673886 SOC: 0.5638 Cumulative_SOC_deviation: 71.9617 Fuel Consumption: 45.3405\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.224\n",
      "Episode: 195 Exploration P: 0.0153 Total reward: -614.8733940471027 SOC: 0.5814 Cumulative_SOC_deviation: 112.8295 Fuel Consumption: 50.7259\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.971\n",
      "Episode: 196 Exploration P: 0.0152 Total reward: -812.2147947565509 SOC: 0.5808 Cumulative_SOC_deviation: 151.9948 Fuel Consumption: 52.2406\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.750\n",
      "Episode: 197 Exploration P: 0.0150 Total reward: -228.4423234792171 SOC: 0.5774 Cumulative_SOC_deviation: 36.3305 Fuel Consumption: 46.7901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.301\n",
      "Episode: 198 Exploration P: 0.0149 Total reward: -220.9577142078788 SOC: 0.5822 Cumulative_SOC_deviation: 34.4844 Fuel Consumption: 48.5356\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.648\n",
      "Episode: 199 Exploration P: 0.0148 Total reward: -220.14218138126378 SOC: 0.5812 Cumulative_SOC_deviation: 34.9632 Fuel Consumption: 45.3261\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.590\n",
      "Episode: 200 Exploration P: 0.0146 Total reward: -361.0253756826912 SOC: 0.5015 Cumulative_SOC_deviation: 63.9941 Fuel Consumption: 41.0549\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 6\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.147\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3153.5979103202467 SOC: 1.0000 Cumulative_SOC_deviation: 500.2787 Fuel Consumption: 151.9254\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.807\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3145.1501455200105 SOC: 1.0000 Cumulative_SOC_deviation: 499.0084 Fuel Consumption: 151.1000\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 16.818\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3121.9532020323186 SOC: 1.0000 Cumulative_SOC_deviation: 495.5033 Fuel Consumption: 148.9332\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 39.928\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -3121.742511758988 SOC: 1.0000 Cumulative_SOC_deviation: 495.1501 Fuel Consumption: 150.8420\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 78.953\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -3086.6774013329173 SOC: 1.0000 Cumulative_SOC_deviation: 490.1864 Fuel Consumption: 145.5591\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.771\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -3127.9658013800804 SOC: 1.0000 Cumulative_SOC_deviation: 496.6224 Fuel Consumption: 148.2315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.014\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -3061.926408639475 SOC: 1.0000 Cumulative_SOC_deviation: 486.6958 Fuel Consumption: 141.7517\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.513\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -3004.0904167956355 SOC: 1.0000 Cumulative_SOC_deviation: 477.9197 Fuel Consumption: 136.5720\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.775\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -3029.943083397055 SOC: 1.0000 Cumulative_SOC_deviation: 482.1219 Fuel Consumption: 137.2118\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.448\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -3063.728963174049 SOC: 1.0000 Cumulative_SOC_deviation: 487.8698 Fuel Consumption: 136.5101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.768\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -2955.795437069362 SOC: 1.0000 Cumulative_SOC_deviation: 470.7493 Fuel Consumption: 131.2995\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.001\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -2978.5896774509247 SOC: 1.0000 Cumulative_SOC_deviation: 474.8751 Fuel Consumption: 129.3390\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.175\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -2816.4567290687837 SOC: 1.0000 Cumulative_SOC_deviation: 448.9209 Fuel Consumption: 122.9315\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.043\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -2907.9226940249773 SOC: 1.0000 Cumulative_SOC_deviation: 463.7215 Fuel Consumption: 125.5935\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.160\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -2833.5888508193193 SOC: 1.0000 Cumulative_SOC_deviation: 452.8442 Fuel Consumption: 116.5239\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.162\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -2830.6446840419735 SOC: 1.0000 Cumulative_SOC_deviation: 451.8840 Fuel Consumption: 119.3407\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.504\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -2723.6761868737817 SOC: 1.0000 Cumulative_SOC_deviation: 435.1342 Fuel Consumption: 112.8713\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.041\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -2822.686902228453 SOC: 1.0000 Cumulative_SOC_deviation: 451.6067 Fuel Consumption: 113.0467\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.098\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -2706.014352012805 SOC: 1.0000 Cumulative_SOC_deviation: 432.5310 Fuel Consumption: 110.8283\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.374\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -2632.614834757553 SOC: 1.0000 Cumulative_SOC_deviation: 419.8971 Fuel Consumption: 113.2324\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.272\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -2522.667916251902 SOC: 1.0000 Cumulative_SOC_deviation: 402.9139 Fuel Consumption: 105.1843\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.600\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2690.3727294108935 SOC: 1.0000 Cumulative_SOC_deviation: 430.7616 Fuel Consumption: 105.8033\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.472\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2629.115338820749 SOC: 1.0000 Cumulative_SOC_deviation: 420.5778 Fuel Consumption: 105.6486\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.884\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -2549.0577851083303 SOC: 1.0000 Cumulative_SOC_deviation: 408.3080 Fuel Consumption: 99.2101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.653\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -2430.9180766975996 SOC: 1.0000 Cumulative_SOC_deviation: 388.5630 Fuel Consumption: 99.5402\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.165\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -2332.3051860379314 SOC: 1.0000 Cumulative_SOC_deviation: 372.1653 Fuel Consumption: 99.3132\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.328\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -2379.0303733907713 SOC: 1.0000 Cumulative_SOC_deviation: 379.7121 Fuel Consumption: 100.7578\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.377\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -2298.9182306144457 SOC: 1.0000 Cumulative_SOC_deviation: 367.2990 Fuel Consumption: 95.1241\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.352\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -2127.258050176424 SOC: 1.0000 Cumulative_SOC_deviation: 339.0192 Fuel Consumption: 93.1430\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.278\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -2170.1181439985603 SOC: 1.0000 Cumulative_SOC_deviation: 346.6630 Fuel Consumption: 90.1404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.500\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -2101.8324662401983 SOC: 1.0000 Cumulative_SOC_deviation: 335.1771 Fuel Consumption: 90.7698\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.358\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -2006.6893732940516 SOC: 1.0000 Cumulative_SOC_deviation: 319.1153 Fuel Consumption: 91.9977\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.495\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -1657.1310474623938 SOC: 1.0000 Cumulative_SOC_deviation: 261.6707 Fuel Consumption: 87.1069\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.483\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -2091.2266384463323 SOC: 1.0000 Cumulative_SOC_deviation: 333.8635 Fuel Consumption: 88.0458\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.682\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -1703.5830044630147 SOC: 1.0000 Cumulative_SOC_deviation: 269.6345 Fuel Consumption: 85.7758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.773\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1377.4558745034817 SOC: 1.0000 Cumulative_SOC_deviation: 215.3763 Fuel Consumption: 85.1980\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.470\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -1676.553897383189 SOC: 1.0000 Cumulative_SOC_deviation: 265.3756 Fuel Consumption: 84.3003\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.580\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1219.9706471175173 SOC: 0.9642 Cumulative_SOC_deviation: 189.9697 Fuel Consumption: 80.1525\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.503\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1206.8649020971743 SOC: 0.9459 Cumulative_SOC_deviation: 187.7940 Fuel Consumption: 80.1009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.910\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1390.9613419503255 SOC: 0.9871 Cumulative_SOC_deviation: 217.9540 Fuel Consumption: 83.2376\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.342\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1214.0398562657294 SOC: 0.9624 Cumulative_SOC_deviation: 188.8351 Fuel Consumption: 81.0295\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.802\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -908.2133320840542 SOC: 0.9017 Cumulative_SOC_deviation: 138.6344 Fuel Consumption: 76.4070\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.926\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1098.1507449730134 SOC: 0.9276 Cumulative_SOC_deviation: 169.8951 Fuel Consumption: 78.7801\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.053\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -659.6925557120926 SOC: 0.8745 Cumulative_SOC_deviation: 97.4447 Fuel Consumption: 75.0243\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.468\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -753.1204504194559 SOC: 0.8601 Cumulative_SOC_deviation: 113.1931 Fuel Consumption: 73.9616\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.516\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -920.4398080127756 SOC: 0.8645 Cumulative_SOC_deviation: 141.0436 Fuel Consumption: 74.1783\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.623\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -670.7844727037343 SOC: 0.8319 Cumulative_SOC_deviation: 99.8213 Fuel Consumption: 71.8567\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.278\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -620.9544219723649 SOC: 0.7887 Cumulative_SOC_deviation: 92.0374 Fuel Consumption: 68.7303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.892\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -500.6160379970142 SOC: 0.7798 Cumulative_SOC_deviation: 72.0876 Fuel Consumption: 68.0906\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.817\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -555.0084752012301 SOC: 0.6665 Cumulative_SOC_deviation: 82.5855 Fuel Consumption: 59.4955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.216\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -478.1474067545792 SOC: 0.7345 Cumulative_SOC_deviation: 68.8880 Fuel Consumption: 64.8197\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.353\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -818.3381299545536 SOC: 0.6271 Cumulative_SOC_deviation: 126.9157 Fuel Consumption: 56.8438\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.976\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -583.5608424283475 SOC: 0.6732 Cumulative_SOC_deviation: 87.2410 Fuel Consumption: 60.1146\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.007\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -622.18650499543 SOC: 0.6215 Cumulative_SOC_deviation: 94.3872 Fuel Consumption: 55.8636\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.082\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -614.0420167513902 SOC: 0.6141 Cumulative_SOC_deviation: 93.0624 Fuel Consumption: 55.6675\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.136\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -695.7024553125524 SOC: 0.5893 Cumulative_SOC_deviation: 107.0938 Fuel Consumption: 53.1396\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.709\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -666.3159651684028 SOC: 0.6148 Cumulative_SOC_deviation: 101.7180 Fuel Consumption: 56.0080\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.716\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -896.9183082858151 SOC: 0.5695 Cumulative_SOC_deviation: 140.8379 Fuel Consumption: 51.8911\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.016\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -1082.4580461666037 SOC: 0.5343 Cumulative_SOC_deviation: 172.0621 Fuel Consumption: 50.0854\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.946\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -1012.9506557743274 SOC: 0.5041 Cumulative_SOC_deviation: 160.9694 Fuel Consumption: 47.1344\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.661\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -1175.9159322555138 SOC: 0.5077 Cumulative_SOC_deviation: 187.9910 Fuel Consumption: 47.9702\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.989\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -1539.1841790619007 SOC: 0.4508 Cumulative_SOC_deviation: 249.1995 Fuel Consumption: 43.9874\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.133\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -1512.2739028946096 SOC: 0.4286 Cumulative_SOC_deviation: 244.9964 Fuel Consumption: 42.2952\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.699\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -1646.5278540641564 SOC: 0.3797 Cumulative_SOC_deviation: 267.9654 Fuel Consumption: 38.7354\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.162\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -1776.2008680806746 SOC: 0.3254 Cumulative_SOC_deviation: 290.2276 Fuel Consumption: 34.8352\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.737\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -1779.884250139756 SOC: 0.3597 Cumulative_SOC_deviation: 290.5130 Fuel Consumption: 36.8060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.877\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -1683.2654004322146 SOC: 0.3883 Cumulative_SOC_deviation: 273.9817 Fuel Consumption: 39.3752\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.150\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -1510.6093209808364 SOC: 0.4209 Cumulative_SOC_deviation: 244.8755 Fuel Consumption: 41.3563\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.963\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -1399.2485240743936 SOC: 0.4525 Cumulative_SOC_deviation: 225.9353 Fuel Consumption: 43.6366\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.795\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -2103.3248996521465 SOC: 0.2863 Cumulative_SOC_deviation: 345.2728 Fuel Consumption: 31.6882\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.854\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -1726.661503704666 SOC: 0.3807 Cumulative_SOC_deviation: 281.2625 Fuel Consumption: 39.0863\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.994\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -2041.5178314842137 SOC: 0.2670 Cumulative_SOC_deviation: 335.1092 Fuel Consumption: 30.8627\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.997\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -1988.619248102892 SOC: 0.3094 Cumulative_SOC_deviation: 325.8903 Fuel Consumption: 33.2772\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.047\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -1996.7582960526822 SOC: 0.3152 Cumulative_SOC_deviation: 327.0955 Fuel Consumption: 34.1852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.750\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -2130.931395140956 SOC: 0.2820 Cumulative_SOC_deviation: 349.7930 Fuel Consumption: 32.1731\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.610\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -2014.8107633750935 SOC: 0.2647 Cumulative_SOC_deviation: 330.8093 Fuel Consumption: 29.9547\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.898\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -2270.856002090928 SOC: 0.2343 Cumulative_SOC_deviation: 373.7295 Fuel Consumption: 28.4792\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.163\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -2143.8649634980284 SOC: 0.2547 Cumulative_SOC_deviation: 352.3425 Fuel Consumption: 29.8103\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.380\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -2366.4175063989833 SOC: 0.1956 Cumulative_SOC_deviation: 390.1121 Fuel Consumption: 25.7449\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.275\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -2268.908139480481 SOC: 0.2048 Cumulative_SOC_deviation: 373.7608 Fuel Consumption: 26.3434\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.104\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -2277.1776722626887 SOC: 0.2509 Cumulative_SOC_deviation: 374.5268 Fuel Consumption: 30.0166\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.436\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -2072.30346670045 SOC: 0.2543 Cumulative_SOC_deviation: 340.4207 Fuel Consumption: 29.7793\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.799\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -2241.901615687344 SOC: 0.2119 Cumulative_SOC_deviation: 369.2236 Fuel Consumption: 26.5600\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.022\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -2479.8778093938618 SOC: 0.1751 Cumulative_SOC_deviation: 409.2199 Fuel Consumption: 24.5583\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.019\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -2596.389906353278 SOC: 0.1724 Cumulative_SOC_deviation: 428.6799 Fuel Consumption: 24.3107\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.593\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -2678.5846415277524 SOC: 0.1259 Cumulative_SOC_deviation: 442.9138 Fuel Consumption: 21.1018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.332\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -2477.1920066006137 SOC: 0.1800 Cumulative_SOC_deviation: 408.7396 Fuel Consumption: 24.7544\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.093\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -2685.654982871527 SOC: 0.1414 Cumulative_SOC_deviation: 443.9168 Fuel Consumption: 22.1542\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.454\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -2707.486536231744 SOC: 0.1261 Cumulative_SOC_deviation: 447.6706 Fuel Consumption: 21.4629\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.431\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -2589.6670178853756 SOC: 0.1410 Cumulative_SOC_deviation: 427.9326 Fuel Consumption: 22.0717\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.080\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -2360.254099166753 SOC: 0.1697 Cumulative_SOC_deviation: 389.3978 Fuel Consumption: 23.8670\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.741\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -2562.45574270259 SOC: 0.1449 Cumulative_SOC_deviation: 423.3406 Fuel Consumption: 22.4122\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.088\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -2668.9586938545885 SOC: 0.1182 Cumulative_SOC_deviation: 441.4247 Fuel Consumption: 20.4104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.098\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -3063.7853616150414 SOC: 0.0535 Cumulative_SOC_deviation: 507.9222 Fuel Consumption: 16.2522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.058\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -2535.164719481387 SOC: 0.1593 Cumulative_SOC_deviation: 418.6184 Fuel Consumption: 23.4543\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.799\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -2742.1282537892 SOC: 0.1186 Cumulative_SOC_deviation: 453.5353 Fuel Consumption: 20.9166\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.141\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -1806.1993080652005 SOC: 0.6102 Cumulative_SOC_deviation: 291.5166 Fuel Consumption: 57.0995\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 79.980\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -103.32588788543535 SOC: 0.6146 Cumulative_SOC_deviation: 8.9616 Fuel Consumption: 49.5561\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.585\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -105.9442913536921 SOC: 0.6078 Cumulative_SOC_deviation: 9.6705 Fuel Consumption: 47.9211\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.095\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -106.1390971035081 SOC: 0.6194 Cumulative_SOC_deviation: 9.5640 Fuel Consumption: 48.7549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.262\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -98.57420958977053 SOC: 0.6053 Cumulative_SOC_deviation: 8.3891 Fuel Consumption: 48.2394\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.410\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -87.37853402265489 SOC: 0.6054 Cumulative_SOC_deviation: 6.6524 Fuel Consumption: 47.4643\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.488\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -94.80035017037679 SOC: 0.5973 Cumulative_SOC_deviation: 7.9889 Fuel Consumption: 46.8671\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.496\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -101.39691841436134 SOC: 0.6012 Cumulative_SOC_deviation: 9.0440 Fuel Consumption: 47.1329\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.743\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -100.07898667595543 SOC: 0.5987 Cumulative_SOC_deviation: 8.8924 Fuel Consumption: 46.7249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.595\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -101.87047204989531 SOC: 0.5979 Cumulative_SOC_deviation: 9.2596 Fuel Consumption: 46.3128\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.654\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -106.20701688061745 SOC: 0.6001 Cumulative_SOC_deviation: 9.9595 Fuel Consumption: 46.4501\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.986\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -108.33947673047088 SOC: 0.5946 Cumulative_SOC_deviation: 10.3230 Fuel Consumption: 46.4017\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.167\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -102.45719728192292 SOC: 0.6003 Cumulative_SOC_deviation: 9.3177 Fuel Consumption: 46.5508\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.451\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -101.60454520978598 SOC: 0.6066 Cumulative_SOC_deviation: 9.0864 Fuel Consumption: 47.0861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.471\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -109.95764035444495 SOC: 0.5977 Cumulative_SOC_deviation: 10.6255 Fuel Consumption: 46.2049\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.657\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -117.22863357535017 SOC: 0.6014 Cumulative_SOC_deviation: 11.8704 Fuel Consumption: 46.0062\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.525\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -107.23011744150065 SOC: 0.5983 Cumulative_SOC_deviation: 10.2162 Fuel Consumption: 45.9327\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.601\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -101.70012064437651 SOC: 0.6027 Cumulative_SOC_deviation: 9.2595 Fuel Consumption: 46.1432\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.385\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -106.82014885788412 SOC: 0.6091 Cumulative_SOC_deviation: 10.0114 Fuel Consumption: 46.7516\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.924\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -105.9449086266982 SOC: 0.6002 Cumulative_SOC_deviation: 9.9573 Fuel Consumption: 46.2009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.557\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -93.02159666417492 SOC: 0.5973 Cumulative_SOC_deviation: 7.8038 Fuel Consumption: 46.1985\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.249\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -98.64957329446356 SOC: 0.6026 Cumulative_SOC_deviation: 8.7229 Fuel Consumption: 46.3120\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.360\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -100.0485693144884 SOC: 0.6000 Cumulative_SOC_deviation: 9.0241 Fuel Consumption: 45.9042\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.206\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -105.58706596661358 SOC: 0.6095 Cumulative_SOC_deviation: 9.7437 Fuel Consumption: 47.1250\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.377\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -95.5768556574364 SOC: 0.6042 Cumulative_SOC_deviation: 8.1884 Fuel Consumption: 46.4466\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.028\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -95.25639487793707 SOC: 0.6015 Cumulative_SOC_deviation: 8.2655 Fuel Consumption: 45.6633\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.625\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -99.93937438871389 SOC: 0.6004 Cumulative_SOC_deviation: 8.9699 Fuel Consumption: 46.1202\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.456\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -111.46080668738124 SOC: 0.5928 Cumulative_SOC_deviation: 11.0463 Fuel Consumption: 45.1829\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.738\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -113.19397175610112 SOC: 0.6045 Cumulative_SOC_deviation: 11.2173 Fuel Consumption: 45.8903\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.408\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -105.47065574424447 SOC: 0.5975 Cumulative_SOC_deviation: 9.9145 Fuel Consumption: 45.9837\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.351\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -125.06160334174646 SOC: 0.5964 Cumulative_SOC_deviation: 13.2209 Fuel Consumption: 45.7360\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.499\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -120.1865320911762 SOC: 0.6045 Cumulative_SOC_deviation: 12.3444 Fuel Consumption: 46.1201\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.174\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -115.18102818420333 SOC: 0.6014 Cumulative_SOC_deviation: 11.5074 Fuel Consumption: 46.1367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.361\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -116.90344112369692 SOC: 0.5984 Cumulative_SOC_deviation: 11.8987 Fuel Consumption: 45.5110\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.628\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -117.44065674926584 SOC: 0.6003 Cumulative_SOC_deviation: 11.9527 Fuel Consumption: 45.7244\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.379\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -126.64709681789758 SOC: 0.5998 Cumulative_SOC_deviation: 13.5103 Fuel Consumption: 45.5851\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.957\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -110.48388294313438 SOC: 0.5982 Cumulative_SOC_deviation: 10.7652 Fuel Consumption: 45.8925\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.797\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -122.07126492408145 SOC: 0.5936 Cumulative_SOC_deviation: 12.7546 Fuel Consumption: 45.5440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.409\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -115.53187794354925 SOC: 0.5995 Cumulative_SOC_deviation: 11.7262 Fuel Consumption: 45.1748\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.222\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -104.96056410443778 SOC: 0.5987 Cumulative_SOC_deviation: 9.8630 Fuel Consumption: 45.7825\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.200\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -121.65602411931175 SOC: 0.5974 Cumulative_SOC_deviation: 12.7186 Fuel Consumption: 45.3446\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.695\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -132.54831719717316 SOC: 0.5917 Cumulative_SOC_deviation: 14.5826 Fuel Consumption: 45.0530\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.396\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -118.02950416186764 SOC: 0.5952 Cumulative_SOC_deviation: 12.1060 Fuel Consumption: 45.3933\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.663\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -127.98203069164416 SOC: 0.5989 Cumulative_SOC_deviation: 13.8014 Fuel Consumption: 45.1738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.915\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -123.9627909148816 SOC: 0.5911 Cumulative_SOC_deviation: 13.1916 Fuel Consumption: 44.8130\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.012\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -176.58506575428862 SOC: 0.5845 Cumulative_SOC_deviation: 21.9946 Fuel Consumption: 44.6177\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.652\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -187.81364215160949 SOC: 0.5918 Cumulative_SOC_deviation: 23.8530 Fuel Consumption: 44.6956\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.226\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -164.6937709397495 SOC: 0.5810 Cumulative_SOC_deviation: 20.1391 Fuel Consumption: 43.8592\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.576\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -185.76624447922143 SOC: 0.6028 Cumulative_SOC_deviation: 23.3589 Fuel Consumption: 45.6131\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.425\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -140.3552527672484 SOC: 0.5961 Cumulative_SOC_deviation: 15.8432 Fuel Consumption: 45.2963\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.239\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -115.31249222270871 SOC: 0.5966 Cumulative_SOC_deviation: 11.7288 Fuel Consumption: 44.9400\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.051\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -110.31783834783721 SOC: 0.5986 Cumulative_SOC_deviation: 10.7997 Fuel Consumption: 45.5198\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.528\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -142.0281547973333 SOC: 0.5937 Cumulative_SOC_deviation: 16.1776 Fuel Consumption: 44.9626\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.718\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -112.95208235835291 SOC: 0.6054 Cumulative_SOC_deviation: 11.1570 Fuel Consumption: 46.0102\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.617\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -167.631870841389 SOC: 0.5908 Cumulative_SOC_deviation: 20.4056 Fuel Consumption: 45.1982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.708\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -213.80414101714805 SOC: 0.5823 Cumulative_SOC_deviation: 28.2831 Fuel Consumption: 44.1055\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.410\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -228.83244963864695 SOC: 0.5826 Cumulative_SOC_deviation: 30.7925 Fuel Consumption: 44.0776\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.518\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -232.15607653151835 SOC: 0.5814 Cumulative_SOC_deviation: 31.3756 Fuel Consumption: 43.9027\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.520\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -140.18413406242624 SOC: 0.6017 Cumulative_SOC_deviation: 15.7814 Fuel Consumption: 45.4955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.656\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -157.3118188025835 SOC: 0.5866 Cumulative_SOC_deviation: 18.7919 Fuel Consumption: 44.5605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.496\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -178.95010083183828 SOC: 0.5928 Cumulative_SOC_deviation: 22.3243 Fuel Consumption: 45.0042\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.609\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -200.25388686641452 SOC: 0.5988 Cumulative_SOC_deviation: 25.7946 Fuel Consumption: 45.4860\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.527\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -114.76811205865154 SOC: 0.5944 Cumulative_SOC_deviation: 11.6668 Fuel Consumption: 44.7675\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.028\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -121.17758744090392 SOC: 0.5914 Cumulative_SOC_deviation: 12.7562 Fuel Consumption: 44.6405\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.483\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -113.14633492616382 SOC: 0.5966 Cumulative_SOC_deviation: 11.3317 Fuel Consumption: 45.1558\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.004\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -121.28103044251738 SOC: 0.5934 Cumulative_SOC_deviation: 12.7387 Fuel Consumption: 44.8489\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.523\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -141.66157517828438 SOC: 0.5935 Cumulative_SOC_deviation: 16.1163 Fuel Consumption: 44.9637\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.836\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -139.1078915059563 SOC: 0.5977 Cumulative_SOC_deviation: 15.6320 Fuel Consumption: 45.3159\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.395\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -125.68919138426902 SOC: 0.5978 Cumulative_SOC_deviation: 13.4003 Fuel Consumption: 45.2874\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.761\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -118.20703838116282 SOC: 0.5954 Cumulative_SOC_deviation: 12.2222 Fuel Consumption: 44.8738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.363\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -131.72375650022232 SOC: 0.5891 Cumulative_SOC_deviation: 14.5258 Fuel Consumption: 44.5691\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.831\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -177.2110341749228 SOC: 0.5831 Cumulative_SOC_deviation: 22.1251 Fuel Consumption: 44.4605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.689\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -221.90784493504415 SOC: 0.5795 Cumulative_SOC_deviation: 29.6320 Fuel Consumption: 44.1159\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.274\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -142.96055997962873 SOC: 0.5957 Cumulative_SOC_deviation: 16.3276 Fuel Consumption: 44.9951\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.748\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -147.34894033719385 SOC: 0.5884 Cumulative_SOC_deviation: 17.1364 Fuel Consumption: 44.5308\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.620\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -128.5619827514721 SOC: 0.5922 Cumulative_SOC_deviation: 13.9375 Fuel Consumption: 44.9372\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.895\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -130.14607137698232 SOC: 0.5924 Cumulative_SOC_deviation: 14.2231 Fuel Consumption: 44.8077\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.678\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -135.77078936686308 SOC: 0.5936 Cumulative_SOC_deviation: 15.0616 Fuel Consumption: 45.4015\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.339\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -164.92024638313737 SOC: 0.5810 Cumulative_SOC_deviation: 19.9699 Fuel Consumption: 45.1009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.217\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -257.97496567186505 SOC: 0.5736 Cumulative_SOC_deviation: 35.4844 Fuel Consumption: 45.0688\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.784\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -266.77592150340803 SOC: 0.5762 Cumulative_SOC_deviation: 36.8780 Fuel Consumption: 45.5079\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.678\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -149.6065721625666 SOC: 0.5947 Cumulative_SOC_deviation: 17.3260 Fuel Consumption: 45.6503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.723\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -162.92973884613943 SOC: 0.5894 Cumulative_SOC_deviation: 19.5713 Fuel Consumption: 45.5022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.695\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -143.57575555019702 SOC: 0.5928 Cumulative_SOC_deviation: 16.2956 Fuel Consumption: 45.8022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.589\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -144.7915714044366 SOC: 0.5951 Cumulative_SOC_deviation: 16.4508 Fuel Consumption: 46.0866\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.809\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -138.09758116514013 SOC: 0.5959 Cumulative_SOC_deviation: 15.4381 Fuel Consumption: 45.4687\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.646\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -159.64233639124993 SOC: 0.5911 Cumulative_SOC_deviation: 19.0796 Fuel Consumption: 45.1645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.163\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -128.1343668446411 SOC: 0.5981 Cumulative_SOC_deviation: 13.8235 Fuel Consumption: 45.1934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.756\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -156.63480266725315 SOC: 0.5880 Cumulative_SOC_deviation: 18.7130 Fuel Consumption: 44.3571\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.038\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -161.43912901424062 SOC: 0.5964 Cumulative_SOC_deviation: 19.3428 Fuel Consumption: 45.3822\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.536\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -155.58211873883343 SOC: 0.5916 Cumulative_SOC_deviation: 18.4861 Fuel Consumption: 44.6656\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.549\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -201.53792694764797 SOC: 0.5836 Cumulative_SOC_deviation: 26.1021 Fuel Consumption: 44.9252\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.872\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -200.6306736303853 SOC: 0.5931 Cumulative_SOC_deviation: 25.6951 Fuel Consumption: 46.4603\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.578\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -165.40124738884393 SOC: 0.5906 Cumulative_SOC_deviation: 19.9602 Fuel Consumption: 45.6398\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.035\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -140.00489745907942 SOC: 0.5898 Cumulative_SOC_deviation: 15.6772 Fuel Consumption: 45.9417\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.272\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -146.31605965610913 SOC: 0.5925 Cumulative_SOC_deviation: 16.7902 Fuel Consumption: 45.5749\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.408\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -150.17623781522101 SOC: 0.5938 Cumulative_SOC_deviation: 17.3566 Fuel Consumption: 46.0367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.274\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -145.37370181764274 SOC: 0.5871 Cumulative_SOC_deviation: 16.6420 Fuel Consumption: 45.5215\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.815\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -163.29681359621898 SOC: 0.5910 Cumulative_SOC_deviation: 19.5089 Fuel Consumption: 46.2434\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.071\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -161.04357557671247 SOC: 0.5915 Cumulative_SOC_deviation: 19.0974 Fuel Consumption: 46.4594\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.137\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -155.23520760219523 SOC: 0.5935 Cumulative_SOC_deviation: 18.1384 Fuel Consumption: 46.4048\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.250\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -160.31391232318256 SOC: 0.5946 Cumulative_SOC_deviation: 19.0110 Fuel Consumption: 46.2479\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.255\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -140.36030235093625 SOC: 0.5934 Cumulative_SOC_deviation: 15.8063 Fuel Consumption: 45.5226\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.123\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -156.56416594868477 SOC: 0.5917 Cumulative_SOC_deviation: 18.5221 Fuel Consumption: 45.4317\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "# num_trials = 1\n",
    "reward_factors = [4, 5, 6]\n",
    "results_dict = {} \n",
    "driving_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "driving_cycle = sio.loadmat(driving_cycle_path)\n",
    "driving_cycle = driving_cycle[\"sch_cycle\"][:, 1]\n",
    "\n",
    "for reward_factor in reward_factors: \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(reward_factor))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "#         driving_cycle = driver.get_cycle() \n",
    "        env = initialization_env(driving_cycle, reward_factor)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "#             history = test_agent(actor_model, reward_factor)\n",
    "            history = env.history \n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "#         if (ep + 1) % 200 == 0:             \n",
    "    root = \"DDPG_cycleOne_reward_factor{}\".format(reward_factor)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "            \n",
    "    \n",
    "    results_dict[reward_factor] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG_cycleOne_4to6.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
