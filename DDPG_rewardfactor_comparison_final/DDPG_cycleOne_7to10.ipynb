{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "from tensorflow import keras \n",
    "import os \n",
    "import math \n",
    "import random \n",
    "import pickle \n",
    "import glob\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import deque \n",
    "from tensorflow.keras import layers\n",
    "import time \n",
    "import scipy.io as sio\n",
    "\n",
    "from vehicle_model_variant import Environment \n",
    "from cell_model import CellModel \n",
    "from driver_MDP import Driver_MDP \n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "drving_cycle = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "battery_path = \"../../OC_SIM_DB/OC_SIM_DB_Bat/OC_SIM_DB_Bat_nimh_6_240_panasonic_MY01_Prius.mat\"\n",
    "motor_path = \"../../OC_SIM_DB/OC_SIM_DB_Mot/OC_SIM_DB_Mot_pm_95_145_X2.mat\"\n",
    "cell_model = CellModel()\n",
    "# env = Environment(cell_model, drving_cycle, battery_path, motor_path, 10)\n",
    "driver = Driver_MDP(0.02)\n",
    "\n",
    "num_states = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise: \n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None): \n",
    "        self.theta = theta \n",
    "        self.mean = mean \n",
    "        self.std_dev = std_deviation \n",
    "        self.dt = dt \n",
    "        self.x_initial = x_initial \n",
    "        self.reset() \n",
    "        \n",
    "    def reset(self): \n",
    "        if self.x_initial is not None: \n",
    "            self.x_prev = self.x_initial \n",
    "        else: \n",
    "            self.x_prev = 0 \n",
    "            \n",
    "    def __call__(self): \n",
    "        x = (\n",
    "             self.x_prev + self.theta * (self.mean - self.x_prev) * self.dt \n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal() \n",
    "        )\n",
    "        self.x_prev = x \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: \n",
    "    def __init__(self, buffer_capacity=100000, batch_size=64):      \n",
    "        self.buffer_capacity = buffer_capacity \n",
    "        self.batch_size = batch_size \n",
    "        self.buffer_counter = 0 \n",
    "        \n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        \n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity \n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "        \n",
    "        self.buffer_counter += 1 \n",
    "        \n",
    "    def learn(self): \n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            target_actions = target_actor(next_state_batch)\n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions])\n",
    "            critic_value = critic_model([state_batch, action_batch])\n",
    "            critic_loss = tf.math.reduce_mean(tf.square(y - critic_value)) \n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables) \n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            actions = actor_model(state_batch)\n",
    "            critic_value = critic_model([state_batch, actions])\n",
    "            actor_loss = - tf.math.reduce_mean(critic_value)\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables) \n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_target(tau): \n",
    "    new_weights = [] \n",
    "    target_variables = target_critic.weights\n",
    "    for i, variable in enumerate(critic_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_critic.set_weights(new_weights)\n",
    "    \n",
    "    new_weights = [] \n",
    "    target_variables = target_actor.weights\n",
    "    for i, variable in enumerate(actor_model.weights): \n",
    "        new_weights.append(target_variables[i] * (1 - tau) + tau * variable)\n",
    "    target_actor.set_weights(new_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor(): \n",
    "    last_init = tf.random_uniform_initializer(minval=-0.003, maxval=0.003)\n",
    "    \n",
    "    inputs = layers.Input(shape=(num_states))\n",
    "    inputs_batchnorm = layers.BatchNormalization()(inputs)\n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(inputs_batchnorm)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\", \n",
    "                          kernel_initializer=last_init)(out)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic(): \n",
    "    state_input = layers.Input(shape=(num_states))\n",
    "    state_input_batchnorm = layers.BatchNormalization()(state_input)\n",
    "    \n",
    "    state_out = layers.Dense(16, activation=\"relu\")(state_input_batchnorm)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    state_out = layers.Dense(32, activation=\"relu\")(state_out)\n",
    "#     state_out = layers.BatchNormalization()(state_out)\n",
    "    \n",
    "    action_input = layers.Input(shape=(1))\n",
    "    action_out = layers.Dense(32, activation=\"relu\")(action_input)\n",
    "#     action_out = layers.BatchNormalization()(action_out)\n",
    "    \n",
    "    concat = layers.Concatenate()([state_out, action_out]) \n",
    "    \n",
    "    out = layers.Dense(512, activation=\"relu\")(concat)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    out = layers.Dense(512, activation=\"relu\")(out)\n",
    "#     out = layers.BatchNormalization()(out)\n",
    "    outputs = layers.Dense(1)(out)\n",
    "    \n",
    "    model = tf.keras.Model([state_input, action_input], outputs)\n",
    "    return model \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object): \n",
    "    j_min = state[0][2].numpy()\n",
    "    j_max = state[0][3].numpy()\n",
    "    sampled_action = tf.squeeze(actor_model(state)) \n",
    "    noise = noise_object()\n",
    "    sampled_action = sampled_action.numpy() + noise \n",
    "    legal_action = sampled_action * j_max \n",
    "    legal_action = np.clip(legal_action, j_min, j_max)\n",
    "#     print(j_min, j_max, legal_action, noise)\n",
    "    return legal_action \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_epsilon_greedy(state, eps): \n",
    "    j_min = state[0][-2].numpy()\n",
    "    j_max = state[0][-1].numpy()\n",
    "\n",
    "    if random.random() < eps: \n",
    "        a = random.randint(0, 9)\n",
    "        return np.linspace(j_min, j_max, 10)[a]\n",
    "    else: \n",
    "        sampled_action = tf.squeeze(actor_model(state)).numpy()  \n",
    "        legal_action = sampled_action * j_max \n",
    "        legal_action = np.clip(legal_action, j_min, j_max)\n",
    "        return legal_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2 \n",
    "ou_noise = OUActionNoise(mean=0, std_deviation=0.2)\n",
    "\n",
    "critic_lr = 0.0005 \n",
    "actor_lr = 0.00025 \n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 200 \n",
    "gamma = 0.95 \n",
    "tau = 0.001 \n",
    "\n",
    "MAX_EPSILON = 1.0 \n",
    "MIN_EPSILON = 0.01 \n",
    "DECAY_RATE = 0.00002\n",
    "BATCH_SIZE = 32 \n",
    "DELAY_TRAINING = 5000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(): \n",
    "    actor_model = get_actor() \n",
    "    critic_model = get_critic() \n",
    "    target_actor = get_actor() \n",
    "    target_critic = get_critic() \n",
    "    target_actor.set_weights(actor_model.get_weights())\n",
    "    target_critic.set_weights(critic_model.get_weights())\n",
    "#     actor_model.load_weights(\"./DDPG1_trial1/actor_model_checkpoint\")\n",
    "#     critic_model.load_weights(\"./DDPG1_trial1/critic_model_checkpoint\")\n",
    "#     target_actor.load_weights(\"./DDPG1_trial1/target_actor_checkpoint\")\n",
    "#     target_critic.load_weights(\"./DDPG1_trial1/target_critic_checkpoint\")\n",
    "    \n",
    "    buffer = Buffer(500000, BATCH_SIZE)\n",
    "    return actor_model, critic_model, target_actor, target_critic, buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weights(actor_model, critic_model, target_actor, target_critic, root): \n",
    "    if not os.path.exists(root): \n",
    "        os.makedirs(root)\n",
    "        \n",
    "    actor_model.save_weights(\"./{}/actor_model.h5\".format(root))\n",
    "    critic_model.save_weights(\"./{}/critic_model.h5\".format(root))\n",
    "    target_actor.save_weights(\"./{}/target_actor.h5\".format(root))\n",
    "    target_critic.save_weights(\"./{}/target_critic.h5\".format(root))\n",
    "    print(\"model is saved..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization_env(driving_path, reward_factor):\n",
    "    env = Environment(cell_model, driving_path, battery_path, motor_path, reward_factor)\n",
    "    return env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(actor_model, reward_factor):\n",
    "#     test_cycle = driver.get_cycle() \n",
    "    test_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "    test_cycle = sio.loadmat(test_cycle_path)\n",
    "    test_cycle = test_cycle[\"sch_cycle\"][:, 1]\n",
    "    env = initialization_env(test_cycle, reward_factor)\n",
    "    \n",
    "    total_reward = 0\n",
    "    state = env.reset() \n",
    "    while True: \n",
    "        tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "        action = policy_epsilon_greedy(tf_state, -1)\n",
    "        next_state, reward, done = env.step(action)\n",
    "        \n",
    "        state = next_state \n",
    "        total_reward += reward \n",
    "        \n",
    "        if done: \n",
    "            break \n",
    "        \n",
    "    SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "    \n",
    "    print(\"******************* Test is start *****************\")\n",
    "#     print(test_cycle)\n",
    "    print('Total reward: {}'.format(total_reward), \n",
    "          \"SOC: {:.4f}\".format(env.SOC), \n",
    "          \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "          \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption))\n",
    "    print(\"******************* Test is done *****************\")\n",
    "    print(\"\")\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_cycle)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(env.history[\"Action\"])\n",
    "    plt.show() \n",
    "    return env.history  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 7\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 14.777\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -3592.440995837971 SOC: 1.0000 Cumulative_SOC_deviation: 492.0373 Fuel Consumption: 148.1799\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 14.059\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -3629.894829428993 SOC: 1.0000 Cumulative_SOC_deviation: 496.6670 Fuel Consumption: 153.2255\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 14.447\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -3625.5167588200866 SOC: 1.0000 Cumulative_SOC_deviation: 496.2627 Fuel Consumption: 151.6778\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 40.490\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -3647.8701795923794 SOC: 1.0000 Cumulative_SOC_deviation: 499.2718 Fuel Consumption: 152.9677\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.755\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -3606.882384654481 SOC: 1.0000 Cumulative_SOC_deviation: 494.1342 Fuel Consumption: 147.9428\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.986\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -3572.200766772545 SOC: 1.0000 Cumulative_SOC_deviation: 489.5512 Fuel Consumption: 145.3425\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.850\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -3532.3126070862086 SOC: 1.0000 Cumulative_SOC_deviation: 484.7108 Fuel Consumption: 139.3373\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.137\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -3563.652627758858 SOC: 1.0000 Cumulative_SOC_deviation: 489.1201 Fuel Consumption: 139.8119\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.832\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -3447.4942103095013 SOC: 1.0000 Cumulative_SOC_deviation: 473.3161 Fuel Consumption: 134.2814\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.706\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -3468.2563892033354 SOC: 1.0000 Cumulative_SOC_deviation: 476.7347 Fuel Consumption: 131.1137\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.026\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -3400.342575857033 SOC: 1.0000 Cumulative_SOC_deviation: 467.4321 Fuel Consumption: 128.3175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.569\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -3367.514071823453 SOC: 1.0000 Cumulative_SOC_deviation: 462.8736 Fuel Consumption: 127.3992\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.486\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -3424.913224356299 SOC: 1.0000 Cumulative_SOC_deviation: 471.1810 Fuel Consumption: 126.6460\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.897\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -3406.1653449343444 SOC: 1.0000 Cumulative_SOC_deviation: 468.2330 Fuel Consumption: 128.5342\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.394\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -3330.679819329612 SOC: 1.0000 Cumulative_SOC_deviation: 458.7981 Fuel Consumption: 119.0931\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.933\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -3313.3323344397672 SOC: 1.0000 Cumulative_SOC_deviation: 455.8512 Fuel Consumption: 122.3743\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.933\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -3250.76617753958 SOC: 1.0000 Cumulative_SOC_deviation: 447.7091 Fuel Consumption: 116.8025\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.584\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -3207.1907523168547 SOC: 1.0000 Cumulative_SOC_deviation: 442.0191 Fuel Consumption: 113.0570\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.266\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -3135.2863168078347 SOC: 1.0000 Cumulative_SOC_deviation: 432.5931 Fuel Consumption: 107.1344\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.657\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -2905.0732219751258 SOC: 1.0000 Cumulative_SOC_deviation: 400.4632 Fuel Consumption: 101.8309\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.511\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -3185.7972830815634 SOC: 1.0000 Cumulative_SOC_deviation: 438.7669 Fuel Consumption: 114.4293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.708\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -2921.839023677733 SOC: 1.0000 Cumulative_SOC_deviation: 402.4397 Fuel Consumption: 104.7612\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.454\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -2944.1635664043474 SOC: 1.0000 Cumulative_SOC_deviation: 405.8132 Fuel Consumption: 103.4715\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.798\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -2842.513010852729 SOC: 1.0000 Cumulative_SOC_deviation: 391.5982 Fuel Consumption: 101.3253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.222\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -2953.1113561907287 SOC: 1.0000 Cumulative_SOC_deviation: 407.3243 Fuel Consumption: 101.8412\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.201\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -2822.556689819793 SOC: 1.0000 Cumulative_SOC_deviation: 389.6701 Fuel Consumption: 94.8661\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.799\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -2761.078586783868 SOC: 1.0000 Cumulative_SOC_deviation: 380.4762 Fuel Consumption: 97.7449\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.191\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -2456.5039045747326 SOC: 1.0000 Cumulative_SOC_deviation: 337.7159 Fuel Consumption: 92.4930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.116\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -2860.8565506837176 SOC: 1.0000 Cumulative_SOC_deviation: 395.0354 Fuel Consumption: 95.6090\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.790\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -2589.8848028415814 SOC: 1.0000 Cumulative_SOC_deviation: 356.8248 Fuel Consumption: 92.1112\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.230\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -2500.775452820299 SOC: 1.0000 Cumulative_SOC_deviation: 344.0300 Fuel Consumption: 92.5652\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.223\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -1989.04091184149 SOC: 1.0000 Cumulative_SOC_deviation: 271.5899 Fuel Consumption: 87.9117\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.153\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -2275.1875417050683 SOC: 1.0000 Cumulative_SOC_deviation: 312.4547 Fuel Consumption: 88.0046\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.447\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -1864.7796231157724 SOC: 1.0000 Cumulative_SOC_deviation: 254.3173 Fuel Consumption: 84.5583\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.895\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -2056.0632724936972 SOC: 1.0000 Cumulative_SOC_deviation: 281.2721 Fuel Consumption: 87.1585\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.225\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1768.7101012410753 SOC: 0.9949 Cumulative_SOC_deviation: 240.8157 Fuel Consumption: 83.0003\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.138\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -1911.110226576432 SOC: 0.9999 Cumulative_SOC_deviation: 261.0628 Fuel Consumption: 83.6709\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.399\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1604.660364663516 SOC: 1.0000 Cumulative_SOC_deviation: 217.1825 Fuel Consumption: 84.3829\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.863\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1449.1465723472327 SOC: 0.9972 Cumulative_SOC_deviation: 195.0090 Fuel Consumption: 84.0837\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.776\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1407.3258580853865 SOC: 0.9678 Cumulative_SOC_deviation: 189.3441 Fuel Consumption: 81.9169\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.461\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1305.9256838813901 SOC: 0.9309 Cumulative_SOC_deviation: 175.2402 Fuel Consumption: 79.2445\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.039\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1609.7061743772272 SOC: 0.9911 Cumulative_SOC_deviation: 217.9962 Fuel Consumption: 83.7329\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.592\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -672.4172012719121 SOC: 0.8006 Cumulative_SOC_deviation: 86.1422 Fuel Consumption: 69.4216\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.346\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -1025.7605021397553 SOC: 0.8983 Cumulative_SOC_deviation: 135.4686 Fuel Consumption: 77.4801\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.433\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -647.7416173645737 SOC: 0.7736 Cumulative_SOC_deviation: 82.9208 Fuel Consumption: 67.2961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.543\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -715.3215550010408 SOC: 0.7994 Cumulative_SOC_deviation: 92.3834 Fuel Consumption: 68.6374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.342\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -761.7638705444687 SOC: 0.8070 Cumulative_SOC_deviation: 98.9223 Fuel Consumption: 69.3081\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.140\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -667.1995199011251 SOC: 0.7913 Cumulative_SOC_deviation: 85.5192 Fuel Consumption: 68.5652\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.221\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -629.6237541197485 SOC: 0.7709 Cumulative_SOC_deviation: 80.3723 Fuel Consumption: 67.0175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.305\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -646.5068028092714 SOC: 0.6887 Cumulative_SOC_deviation: 83.6067 Fuel Consumption: 61.2599\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.449\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -705.1798013276932 SOC: 0.7523 Cumulative_SOC_deviation: 91.2663 Fuel Consumption: 66.3158\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.561\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -642.8634723384731 SOC: 0.6891 Cumulative_SOC_deviation: 83.1496 Fuel Consumption: 60.8163\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.546\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -542.2847587168234 SOC: 0.7518 Cumulative_SOC_deviation: 68.1312 Fuel Consumption: 65.3666\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.500\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -550.9253456363192 SOC: 0.6531 Cumulative_SOC_deviation: 70.3605 Fuel Consumption: 58.4018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.546\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -605.2512488490071 SOC: 0.6634 Cumulative_SOC_deviation: 78.0314 Fuel Consumption: 59.0312\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.702\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -728.7216241852094 SOC: 0.6265 Cumulative_SOC_deviation: 96.0120 Fuel Consumption: 56.6374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.433\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -1001.1346603889849 SOC: 0.5682 Cumulative_SOC_deviation: 135.5620 Fuel Consumption: 52.2006\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.972\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -1406.5979977745892 SOC: 0.5372 Cumulative_SOC_deviation: 193.8111 Fuel Consumption: 49.9203\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.530\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -1025.2041741420603 SOC: 0.5691 Cumulative_SOC_deviation: 138.9239 Fuel Consumption: 52.7372\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.570\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -1653.395197820828 SOC: 0.4681 Cumulative_SOC_deviation: 229.7931 Fuel Consumption: 44.8438\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.373\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -1382.9240249871054 SOC: 0.5275 Cumulative_SOC_deviation: 190.4763 Fuel Consumption: 49.5901\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.016\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -1042.2692391437843 SOC: 0.5545 Cumulative_SOC_deviation: 141.5283 Fuel Consumption: 51.5712\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.194\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -1584.400645449984 SOC: 0.4547 Cumulative_SOC_deviation: 220.1003 Fuel Consumption: 43.6985\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.540\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -1700.5996946655578 SOC: 0.4423 Cumulative_SOC_deviation: 236.7783 Fuel Consumption: 43.1516\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.008\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -1944.6291402527966 SOC: 0.4101 Cumulative_SOC_deviation: 271.9315 Fuel Consumption: 41.1086\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.569\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -1566.6233353688363 SOC: 0.4479 Cumulative_SOC_deviation: 217.5622 Fuel Consumption: 43.6882\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.433\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -1890.3678390414004 SOC: 0.4082 Cumulative_SOC_deviation: 264.2433 Fuel Consumption: 40.6649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.608\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -1543.8237930604143 SOC: 0.4381 Cumulative_SOC_deviation: 214.4201 Fuel Consumption: 42.8833\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.568\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -1806.4599652700497 SOC: 0.3862 Cumulative_SOC_deviation: 252.5984 Fuel Consumption: 38.2711\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.326\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -2195.1857228186486 SOC: 0.3219 Cumulative_SOC_deviation: 308.7497 Fuel Consumption: 33.9375\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.099\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -2256.7193115214627 SOC: 0.2840 Cumulative_SOC_deviation: 317.8734 Fuel Consumption: 31.6056\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.839\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -2217.097971808395 SOC: 0.3082 Cumulative_SOC_deviation: 311.9464 Fuel Consumption: 33.4732\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.120\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -2365.301408773898 SOC: 0.3042 Cumulative_SOC_deviation: 333.1684 Fuel Consumption: 33.1224\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.052\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -2737.263375886622 SOC: 0.2225 Cumulative_SOC_deviation: 387.0561 Fuel Consumption: 27.8704\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.535\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -2477.3259747167303 SOC: 0.2563 Cumulative_SOC_deviation: 349.5994 Fuel Consumption: 30.1301\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.593\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -2180.5099604218804 SOC: 0.3258 Cumulative_SOC_deviation: 306.5397 Fuel Consumption: 34.7320\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 107.020\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -2143.9769085483686 SOC: 0.3236 Cumulative_SOC_deviation: 301.4165 Fuel Consumption: 34.0613\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.025\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -2260.755447785861 SOC: 0.2800 Cumulative_SOC_deviation: 318.5119 Fuel Consumption: 31.1723\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 100.051\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -2611.1871720274016 SOC: 0.2421 Cumulative_SOC_deviation: 368.8271 Fuel Consumption: 29.3975\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.006\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -2697.310345879507 SOC: 0.2293 Cumulative_SOC_deviation: 381.2896 Fuel Consumption: 28.2832\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.933\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -2967.3583072385927 SOC: 0.1645 Cumulative_SOC_deviation: 420.5223 Fuel Consumption: 23.7019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.666\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -2585.058150725334 SOC: 0.2272 Cumulative_SOC_deviation: 365.3228 Fuel Consumption: 27.7982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.895\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -2799.1752414554094 SOC: 0.6023 Cumulative_SOC_deviation: 391.6188 Fuel Consumption: 57.8438\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.136\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -174.52816564114278 SOC: 0.6214 Cumulative_SOC_deviation: 17.3068 Fuel Consumption: 53.3804\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.856\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -172.0064678057236 SOC: 0.6209 Cumulative_SOC_deviation: 17.0406 Fuel Consumption: 52.7222\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.956\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -154.56133726459925 SOC: 0.6120 Cumulative_SOC_deviation: 14.5989 Fuel Consumption: 52.3688\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.300\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -106.97745345168059 SOC: 0.6053 Cumulative_SOC_deviation: 8.0085 Fuel Consumption: 50.9179\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.496\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -128.15942944523175 SOC: 0.5995 Cumulative_SOC_deviation: 11.0968 Fuel Consumption: 50.4817\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.409\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -148.64406595317516 SOC: 0.6121 Cumulative_SOC_deviation: 13.6343 Fuel Consumption: 53.2039\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.167\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -145.89983828755942 SOC: 0.5957 Cumulative_SOC_deviation: 13.7069 Fuel Consumption: 49.9517\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.224\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -153.79070519893807 SOC: 0.5938 Cumulative_SOC_deviation: 14.7966 Fuel Consumption: 50.2142\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.348\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -146.28775155382618 SOC: 0.5894 Cumulative_SOC_deviation: 13.7618 Fuel Consumption: 49.9554\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.039\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -195.20527849683137 SOC: 0.5992 Cumulative_SOC_deviation: 20.5618 Fuel Consumption: 51.2727\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.283\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -150.6342102363196 SOC: 0.5853 Cumulative_SOC_deviation: 14.4984 Fuel Consumption: 49.1453\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.190\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -219.88766129339487 SOC: 0.6034 Cumulative_SOC_deviation: 24.0456 Fuel Consumption: 51.5685\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.701\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -222.20433623385642 SOC: 0.6004 Cumulative_SOC_deviation: 24.3916 Fuel Consumption: 51.4633\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.218\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -234.79851060723664 SOC: 0.5797 Cumulative_SOC_deviation: 26.2913 Fuel Consumption: 50.7593\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.213\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -243.72811341090934 SOC: 0.5907 Cumulative_SOC_deviation: 27.4042 Fuel Consumption: 51.8984\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.511\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -186.11945477710455 SOC: 0.5921 Cumulative_SOC_deviation: 19.1915 Fuel Consumption: 51.7790\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.024\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -160.86432235605227 SOC: 0.6021 Cumulative_SOC_deviation: 15.4191 Fuel Consumption: 52.9306\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.453\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -212.6240107157044 SOC: 0.5851 Cumulative_SOC_deviation: 22.9942 Fuel Consumption: 51.6645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.204\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -203.5472371848942 SOC: 0.6016 Cumulative_SOC_deviation: 21.4900 Fuel Consumption: 53.1176\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.384\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -218.5370010007686 SOC: 0.5933 Cumulative_SOC_deviation: 23.6875 Fuel Consumption: 52.7243\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.261\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -192.6151935947627 SOC: 0.5887 Cumulative_SOC_deviation: 19.9549 Fuel Consumption: 52.9312\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.969\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -180.78852112765932 SOC: 0.6008 Cumulative_SOC_deviation: 18.1389 Fuel Consumption: 53.8162\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.386\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -217.1992221553844 SOC: 0.5996 Cumulative_SOC_deviation: 23.3343 Fuel Consumption: 53.8588\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.310\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -207.00105661458667 SOC: 0.5967 Cumulative_SOC_deviation: 21.9671 Fuel Consumption: 53.2317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.908\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -231.30331820623965 SOC: 0.5842 Cumulative_SOC_deviation: 25.5185 Fuel Consumption: 52.6735\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.565\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -236.33200945846514 SOC: 0.5779 Cumulative_SOC_deviation: 26.2688 Fuel Consumption: 52.4507\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.225\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -274.58943906783327 SOC: 0.5837 Cumulative_SOC_deviation: 31.6770 Fuel Consumption: 52.8506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.939\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -203.88707653968643 SOC: 0.5974 Cumulative_SOC_deviation: 21.4319 Fuel Consumption: 53.8639\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.563\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -171.8834281849773 SOC: 0.5817 Cumulative_SOC_deviation: 16.9918 Fuel Consumption: 52.9410\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.140\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -228.1567382955488 SOC: 0.6024 Cumulative_SOC_deviation: 24.7755 Fuel Consumption: 54.7280\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.343\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -177.98307696973853 SOC: 0.5949 Cumulative_SOC_deviation: 17.7526 Fuel Consumption: 53.7148\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.682\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -286.9700141503227 SOC: 0.5869 Cumulative_SOC_deviation: 33.4905 Fuel Consumption: 52.5364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.914\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -214.0523733629533 SOC: 0.6105 Cumulative_SOC_deviation: 22.7118 Fuel Consumption: 55.0698\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.695\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -204.60230940622617 SOC: 0.5916 Cumulative_SOC_deviation: 21.5617 Fuel Consumption: 53.6703\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.985\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -166.24165551610244 SOC: 0.5993 Cumulative_SOC_deviation: 15.9810 Fuel Consumption: 54.3748\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.495\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -148.4420987611757 SOC: 0.5873 Cumulative_SOC_deviation: 13.7087 Fuel Consumption: 52.4811\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.155\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -211.2790247810332 SOC: 0.5891 Cumulative_SOC_deviation: 22.6036 Fuel Consumption: 53.0542\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.208\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -269.4701464532308 SOC: 0.5871 Cumulative_SOC_deviation: 30.8411 Fuel Consumption: 53.5824\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.160\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -216.86048849739234 SOC: 0.5894 Cumulative_SOC_deviation: 23.3727 Fuel Consumption: 53.2519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.691\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -223.79115993938302 SOC: 0.5923 Cumulative_SOC_deviation: 24.3681 Fuel Consumption: 53.2143\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.518\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -194.51425124879913 SOC: 0.6005 Cumulative_SOC_deviation: 20.1760 Fuel Consumption: 53.2823\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.173\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -170.29610216464684 SOC: 0.5948 Cumulative_SOC_deviation: 16.9408 Fuel Consumption: 51.7107\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.877\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -182.71675869330807 SOC: 0.5913 Cumulative_SOC_deviation: 18.8410 Fuel Consumption: 50.8299\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.475\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -194.17332539973938 SOC: 0.5952 Cumulative_SOC_deviation: 20.5194 Fuel Consumption: 50.5374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.883\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -201.80186043923263 SOC: 0.5889 Cumulative_SOC_deviation: 21.9673 Fuel Consumption: 48.0307\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.492\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -148.4532288273248 SOC: 0.5992 Cumulative_SOC_deviation: 14.1153 Fuel Consumption: 49.6462\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.472\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -182.77571318461207 SOC: 0.5937 Cumulative_SOC_deviation: 19.0293 Fuel Consumption: 49.5708\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.957\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -180.56237258930466 SOC: 0.5971 Cumulative_SOC_deviation: 18.7602 Fuel Consumption: 49.2407\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.706\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -185.0661792098861 SOC: 0.5913 Cumulative_SOC_deviation: 19.5828 Fuel Consumption: 47.9867\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.163\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -171.8451644427699 SOC: 0.5917 Cumulative_SOC_deviation: 17.7380 Fuel Consumption: 47.6794\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.275\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -129.37169154344804 SOC: 0.6023 Cumulative_SOC_deviation: 11.5353 Fuel Consumption: 48.6249\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.236\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -201.89002979700263 SOC: 0.5977 Cumulative_SOC_deviation: 22.1186 Fuel Consumption: 47.0598\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.233\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -150.68443411367411 SOC: 0.5885 Cumulative_SOC_deviation: 14.9136 Fuel Consumption: 46.2892\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.132\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -178.49947750969858 SOC: 0.5954 Cumulative_SOC_deviation: 18.8454 Fuel Consumption: 46.5820\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.941\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -169.99823692355946 SOC: 0.6024 Cumulative_SOC_deviation: 17.3786 Fuel Consumption: 48.3481\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.542\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -181.92492483307132 SOC: 0.5970 Cumulative_SOC_deviation: 19.0907 Fuel Consumption: 48.2898\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.342\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -174.90003784808576 SOC: 0.5945 Cumulative_SOC_deviation: 18.2032 Fuel Consumption: 47.4778\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.717\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -196.73469701279058 SOC: 0.5940 Cumulative_SOC_deviation: 21.3755 Fuel Consumption: 47.1062\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.612\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -177.65900646051196 SOC: 0.5858 Cumulative_SOC_deviation: 18.7647 Fuel Consumption: 46.3060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.363\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -175.17043569503954 SOC: 0.5973 Cumulative_SOC_deviation: 18.2402 Fuel Consumption: 47.4889\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.124\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -177.63250530064226 SOC: 0.6012 Cumulative_SOC_deviation: 18.5799 Fuel Consumption: 47.5733\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.997\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -158.96550549064705 SOC: 0.5984 Cumulative_SOC_deviation: 15.9926 Fuel Consumption: 47.0175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.944\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -159.66991948617067 SOC: 0.6008 Cumulative_SOC_deviation: 15.9860 Fuel Consumption: 47.7678\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.389\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -157.7502744427197 SOC: 0.5976 Cumulative_SOC_deviation: 15.6309 Fuel Consumption: 48.3337\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.458\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -198.98275261275205 SOC: 0.5966 Cumulative_SOC_deviation: 21.6964 Fuel Consumption: 47.1079\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.523\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -180.68376727922 SOC: 0.5941 Cumulative_SOC_deviation: 19.0351 Fuel Consumption: 47.4379\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.635\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -209.00188338832714 SOC: 0.5948 Cumulative_SOC_deviation: 23.1230 Fuel Consumption: 47.1407\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.176\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -216.69948937465242 SOC: 0.5859 Cumulative_SOC_deviation: 24.3072 Fuel Consumption: 46.5491\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.030\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -202.53330549779997 SOC: 0.5942 Cumulative_SOC_deviation: 22.2562 Fuel Consumption: 46.7401\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.821\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -186.41321821013145 SOC: 0.5986 Cumulative_SOC_deviation: 19.8612 Fuel Consumption: 47.3847\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.329\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -161.22105969836915 SOC: 0.5997 Cumulative_SOC_deviation: 16.0897 Fuel Consumption: 48.5930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.604\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -173.97327045953367 SOC: 0.5981 Cumulative_SOC_deviation: 17.9405 Fuel Consumption: 48.3900\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.434\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -185.6307430475153 SOC: 0.5967 Cumulative_SOC_deviation: 19.6202 Fuel Consumption: 48.2895\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.318\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -169.1912264462302 SOC: 0.5985 Cumulative_SOC_deviation: 17.3886 Fuel Consumption: 47.4709\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.942\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -193.99997589711555 SOC: 0.5964 Cumulative_SOC_deviation: 20.9974 Fuel Consumption: 47.0185\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.208\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -178.8042534889328 SOC: 0.5953 Cumulative_SOC_deviation: 18.6471 Fuel Consumption: 48.2746\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.001\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -184.2775928046717 SOC: 0.5923 Cumulative_SOC_deviation: 19.4193 Fuel Consumption: 48.3423\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 99.992\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -207.2314984378449 SOC: 0.5897 Cumulative_SOC_deviation: 22.7605 Fuel Consumption: 47.9082\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 105.877\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -195.64443350129397 SOC: 0.5974 Cumulative_SOC_deviation: 21.2469 Fuel Consumption: 46.9164\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 102.497\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -179.22749532709034 SOC: 0.6010 Cumulative_SOC_deviation: 18.8739 Fuel Consumption: 47.1100\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 101.817\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -188.69727675563135 SOC: 0.5959 Cumulative_SOC_deviation: 20.3091 Fuel Consumption: 46.5334\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.414\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -179.02844532691324 SOC: 0.5913 Cumulative_SOC_deviation: 18.7410 Fuel Consumption: 47.8414\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.828\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -174.55543428757386 SOC: 0.5980 Cumulative_SOC_deviation: 18.0908 Fuel Consumption: 47.9196\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.955\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -181.62429124120706 SOC: 0.5968 Cumulative_SOC_deviation: 19.1658 Fuel Consumption: 47.4639\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.346\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -180.67336271857263 SOC: 0.5953 Cumulative_SOC_deviation: 19.1835 Fuel Consumption: 46.3891\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.246\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -193.6510116281792 SOC: 0.5892 Cumulative_SOC_deviation: 21.0229 Fuel Consumption: 46.4907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 93.104\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -195.38690424988167 SOC: 0.6015 Cumulative_SOC_deviation: 21.0732 Fuel Consumption: 47.8743\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 94.600\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -195.54381541554307 SOC: 0.5963 Cumulative_SOC_deviation: 21.2202 Fuel Consumption: 47.0026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.421\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -198.02995827283718 SOC: 0.5890 Cumulative_SOC_deviation: 21.5775 Fuel Consumption: 46.9875\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.562\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -221.12418243585034 SOC: 0.5900 Cumulative_SOC_deviation: 24.8803 Fuel Consumption: 46.9622\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.221\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -248.7077733942069 SOC: 0.5871 Cumulative_SOC_deviation: 28.9909 Fuel Consumption: 45.7718\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.561\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -210.51805958868403 SOC: 0.5938 Cumulative_SOC_deviation: 23.3781 Fuel Consumption: 46.8710\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.155\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -221.60531680252032 SOC: 0.5812 Cumulative_SOC_deviation: 25.0844 Fuel Consumption: 46.0143\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.153\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -259.2104482875986 SOC: 0.5832 Cumulative_SOC_deviation: 30.4779 Fuel Consumption: 45.8651\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.368\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -230.92656066075494 SOC: 0.5951 Cumulative_SOC_deviation: 26.3456 Fuel Consumption: 46.5071\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.227\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -218.49073063356172 SOC: 0.5953 Cumulative_SOC_deviation: 24.4561 Fuel Consumption: 47.2978\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.164\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -174.48148330882472 SOC: 0.5966 Cumulative_SOC_deviation: 17.9067 Fuel Consumption: 49.1347\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.180\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -191.26319797894408 SOC: 0.5965 Cumulative_SOC_deviation: 20.5280 Fuel Consumption: 47.5674\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.091\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -186.87864484446 SOC: 0.5961 Cumulative_SOC_deviation: 19.9988 Fuel Consumption: 46.8871\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.918\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -183.9127819428957 SOC: 0.5948 Cumulative_SOC_deviation: 19.6379 Fuel Consumption: 46.4476\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.365\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -225.80137952024847 SOC: 0.5983 Cumulative_SOC_deviation: 25.5867 Fuel Consumption: 46.6943\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.739\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -217.3079077511864 SOC: 0.5962 Cumulative_SOC_deviation: 24.3391 Fuel Consumption: 46.9339\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.451\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -207.4989377954066 SOC: 0.5946 Cumulative_SOC_deviation: 23.0297 Fuel Consumption: 46.2908\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.698\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -203.4662038434538 SOC: 0.5958 Cumulative_SOC_deviation: 22.3715 Fuel Consumption: 46.8660\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.497\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -199.77926997161006 SOC: 0.5964 Cumulative_SOC_deviation: 21.8741 Fuel Consumption: 46.6603\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.126\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -193.33232404678682 SOC: 0.5924 Cumulative_SOC_deviation: 21.0929 Fuel Consumption: 45.6819\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.701\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -185.0967732619191 SOC: 0.5979 Cumulative_SOC_deviation: 19.8202 Fuel Consumption: 46.3557\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.246\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -163.8212707794676 SOC: 0.5954 Cumulative_SOC_deviation: 16.8078 Fuel Consumption: 46.1664\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.567\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -160.19328358902823 SOC: 0.5970 Cumulative_SOC_deviation: 16.3721 Fuel Consumption: 45.5883\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.315\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -185.62312412264302 SOC: 0.5952 Cumulative_SOC_deviation: 19.9704 Fuel Consumption: 45.8306\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.676\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -182.7403885461153 SOC: 0.5948 Cumulative_SOC_deviation: 19.5846 Fuel Consumption: 45.6484\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.598\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -211.87198466445554 SOC: 0.5923 Cumulative_SOC_deviation: 23.8539 Fuel Consumption: 44.8949\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.902\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -184.66199278150236 SOC: 0.5928 Cumulative_SOC_deviation: 19.9631 Fuel Consumption: 44.9201\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.204\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -204.98470832091334 SOC: 0.5939 Cumulative_SOC_deviation: 22.7947 Fuel Consumption: 45.4220\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.393\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -196.43074140544763 SOC: 0.5968 Cumulative_SOC_deviation: 21.5223 Fuel Consumption: 45.7743\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.072\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -179.37085943466997 SOC: 0.5946 Cumulative_SOC_deviation: 19.1105 Fuel Consumption: 45.5970\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 92.991\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -208.06446809376914 SOC: 0.5959 Cumulative_SOC_deviation: 23.1660 Fuel Consumption: 45.9026\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 8\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.287\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -4097.43696451918 SOC: 1.0000 Cumulative_SOC_deviation: 493.4559 Fuel Consumption: 149.7896\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 20.176\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -4137.952481148284 SOC: 1.0000 Cumulative_SOC_deviation: 498.0470 Fuel Consumption: 153.5763\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 19.988\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -4091.3777637192566 SOC: 1.0000 Cumulative_SOC_deviation: 492.6198 Fuel Consumption: 150.4190\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_5 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_4 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 41.923\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -4121.415586493127 SOC: 1.0000 Cumulative_SOC_deviation: 496.0225 Fuel Consumption: 153.2358\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 87.177\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -4091.4870655853197 SOC: 1.0000 Cumulative_SOC_deviation: 492.9044 Fuel Consumption: 148.2522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.713\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4061.3295239614527 SOC: 1.0000 Cumulative_SOC_deviation: 489.8195 Fuel Consumption: 142.7732\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.975\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4040.888565129548 SOC: 1.0000 Cumulative_SOC_deviation: 487.5881 Fuel Consumption: 140.1834\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.837\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -3922.586874687026 SOC: 1.0000 Cumulative_SOC_deviation: 473.6839 Fuel Consumption: 133.1155\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.766\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -4064.99511958657 SOC: 1.0000 Cumulative_SOC_deviation: 491.0194 Fuel Consumption: 136.8403\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.173\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -3935.05481607843 SOC: 1.0000 Cumulative_SOC_deviation: 475.6500 Fuel Consumption: 129.8549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.305\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -3862.166502141277 SOC: 1.0000 Cumulative_SOC_deviation: 466.5609 Fuel Consumption: 129.6795\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.257\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -3844.911416270817 SOC: 1.0000 Cumulative_SOC_deviation: 464.4968 Fuel Consumption: 128.9366\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.092\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -3910.699734438528 SOC: 1.0000 Cumulative_SOC_deviation: 472.8313 Fuel Consumption: 128.0493\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.241\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -3819.5710210483203 SOC: 1.0000 Cumulative_SOC_deviation: 462.8048 Fuel Consumption: 117.1327\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.017\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -3731.668437783355 SOC: 1.0000 Cumulative_SOC_deviation: 451.1502 Fuel Consumption: 122.4671\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.341\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -3784.816439136133 SOC: 1.0000 Cumulative_SOC_deviation: 458.3147 Fuel Consumption: 118.2986\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.212\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -3702.0107654980125 SOC: 1.0000 Cumulative_SOC_deviation: 448.6476 Fuel Consumption: 112.8300\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.215\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -3728.409724448879 SOC: 1.0000 Cumulative_SOC_deviation: 451.7282 Fuel Consumption: 114.5841\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.294\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -3459.7019279037468 SOC: 1.0000 Cumulative_SOC_deviation: 418.4299 Fuel Consumption: 112.2625\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.197\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -3630.0855763710406 SOC: 1.0000 Cumulative_SOC_deviation: 439.6170 Fuel Consumption: 113.1499\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.444\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -3332.1868624925905 SOC: 1.0000 Cumulative_SOC_deviation: 403.4347 Fuel Consumption: 104.7096\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.002\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -3485.490651677109 SOC: 1.0000 Cumulative_SOC_deviation: 422.6441 Fuel Consumption: 104.3382\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.854\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -3397.7111187569844 SOC: 1.0000 Cumulative_SOC_deviation: 412.2262 Fuel Consumption: 99.9014\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.705\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -3124.3627683891896 SOC: 1.0000 Cumulative_SOC_deviation: 378.1041 Fuel Consumption: 99.5299\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.536\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -3512.6099239907144 SOC: 1.0000 Cumulative_SOC_deviation: 426.0843 Fuel Consumption: 103.9358\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.603\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -3036.7294362853563 SOC: 1.0000 Cumulative_SOC_deviation: 367.5820 Fuel Consumption: 96.0733\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.212\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -3226.207742514557 SOC: 1.0000 Cumulative_SOC_deviation: 391.2062 Fuel Consumption: 96.5583\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.163\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -2841.6183303258763 SOC: 0.9992 Cumulative_SOC_deviation: 343.5401 Fuel Consumption: 93.2978\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 89.343\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -2944.945822624319 SOC: 1.0000 Cumulative_SOC_deviation: 356.5437 Fuel Consumption: 92.5961\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.923\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -3031.9170378634376 SOC: 1.0000 Cumulative_SOC_deviation: 367.3042 Fuel Consumption: 93.4835\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.217\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -2459.232496144579 SOC: 1.0000 Cumulative_SOC_deviation: 296.2242 Fuel Consumption: 89.4388\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.264\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -2781.4101335103464 SOC: 1.0000 Cumulative_SOC_deviation: 336.5841 Fuel Consumption: 88.7371\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 90.805\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -2957.1026320981573 SOC: 1.0000 Cumulative_SOC_deviation: 357.8312 Fuel Consumption: 94.4534\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.069\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -2579.513377934746 SOC: 0.9994 Cumulative_SOC_deviation: 311.2735 Fuel Consumption: 89.3253\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.128\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -2292.2891229810307 SOC: 1.0000 Cumulative_SOC_deviation: 275.7935 Fuel Consumption: 85.9409\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 91.036\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -1895.8777963942875 SOC: 1.0000 Cumulative_SOC_deviation: 226.3814 Fuel Consumption: 84.8266\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.327\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -2203.131993717877 SOC: 1.0000 Cumulative_SOC_deviation: 264.9726 Fuel Consumption: 83.3511\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.057\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -1795.193208150071 SOC: 0.9919 Cumulative_SOC_deviation: 213.9532 Fuel Consumption: 83.5678\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.789\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1914.0712487388219 SOC: 1.0000 Cumulative_SOC_deviation: 228.6969 Fuel Consumption: 84.4964\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.842\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1454.4676940030392 SOC: 0.9727 Cumulative_SOC_deviation: 171.5289 Fuel Consumption: 82.2367\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.454\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1648.3006462612457 SOC: 0.9846 Cumulative_SOC_deviation: 195.6948 Fuel Consumption: 82.7423\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.375\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1670.3814508135385 SOC: 0.9554 Cumulative_SOC_deviation: 198.7245 Fuel Consumption: 80.5858\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.712\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1195.270540425015 SOC: 0.8981 Cumulative_SOC_deviation: 139.9160 Fuel Consumption: 75.9427\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.152\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -1086.3447287415015 SOC: 0.8737 Cumulative_SOC_deviation: 126.4318 Fuel Consumption: 74.8902\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.707\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -1286.8030328008574 SOC: 0.9147 Cumulative_SOC_deviation: 151.0906 Fuel Consumption: 78.0785\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.117\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -828.988502865539 SOC: 0.7891 Cumulative_SOC_deviation: 95.0723 Fuel Consumption: 68.4104\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.835\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -1347.4303715709018 SOC: 0.9030 Cumulative_SOC_deviation: 158.8263 Fuel Consumption: 76.8197\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.692\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -1188.0946933896198 SOC: 0.8754 Cumulative_SOC_deviation: 139.1119 Fuel Consumption: 75.1998\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.794\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -886.8914329153731 SOC: 0.8040 Cumulative_SOC_deviation: 102.1515 Fuel Consumption: 69.6795\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.367\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -702.0697216749226 SOC: 0.7442 Cumulative_SOC_deviation: 79.6408 Fuel Consumption: 64.9435\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.014\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -565.9374393255563 SOC: 0.7413 Cumulative_SOC_deviation: 62.6023 Fuel Consumption: 65.1189\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.276\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -827.7536988665692 SOC: 0.7002 Cumulative_SOC_deviation: 95.6273 Fuel Consumption: 62.7354\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.315\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -787.2579000873229 SOC: 0.6424 Cumulative_SOC_deviation: 91.1457 Fuel Consumption: 58.0923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.535\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -1490.5620896326218 SOC: 0.5452 Cumulative_SOC_deviation: 180.0015 Fuel Consumption: 50.5497\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.412\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -872.2931335696132 SOC: 0.6016 Cumulative_SOC_deviation: 102.1620 Fuel Consumption: 54.9968\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.060\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -846.4578703006722 SOC: 0.6648 Cumulative_SOC_deviation: 98.4270 Fuel Consumption: 59.0415\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.345\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -1558.0717550491613 SOC: 0.4867 Cumulative_SOC_deviation: 188.9820 Fuel Consumption: 46.2161\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.734\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -1283.2052567219544 SOC: 0.5701 Cumulative_SOC_deviation: 153.8459 Fuel Consumption: 52.4379\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.241\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -1940.7885711209788 SOC: 0.4289 Cumulative_SOC_deviation: 237.3220 Fuel Consumption: 42.2127\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.111\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -1659.2950077439646 SOC: 0.4779 Cumulative_SOC_deviation: 201.7406 Fuel Consumption: 45.3700\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.601\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -1726.8118122629544 SOC: 0.4970 Cumulative_SOC_deviation: 209.9403 Fuel Consumption: 47.2892\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.468\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -1473.665939222874 SOC: 0.4882 Cumulative_SOC_deviation: 178.4054 Fuel Consumption: 46.4225\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.605\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -1637.6656524821135 SOC: 0.4745 Cumulative_SOC_deviation: 199.0124 Fuel Consumption: 45.5661\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.124\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -2423.998299576411 SOC: 0.4001 Cumulative_SOC_deviation: 297.9592 Fuel Consumption: 40.3244\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.333\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -2208.4768021874406 SOC: 0.3654 Cumulative_SOC_deviation: 271.3892 Fuel Consumption: 37.3631\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.582\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -2169.286591051019 SOC: 0.3980 Cumulative_SOC_deviation: 266.1951 Fuel Consumption: 39.7260\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.666\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -2039.6366408805047 SOC: 0.3955 Cumulative_SOC_deviation: 250.0030 Fuel Consumption: 39.6125\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.530\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -2307.5668452960876 SOC: 0.3774 Cumulative_SOC_deviation: 283.6452 Fuel Consumption: 38.4053\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.521\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -2273.4186091057327 SOC: 0.3579 Cumulative_SOC_deviation: 279.5843 Fuel Consumption: 36.7440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.343\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -2450.4807524821654 SOC: 0.3685 Cumulative_SOC_deviation: 301.5572 Fuel Consumption: 38.0235\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.591\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -2376.763128882285 SOC: 0.3341 Cumulative_SOC_deviation: 292.6830 Fuel Consumption: 35.2995\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.625\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -2212.9516672125546 SOC: 0.3760 Cumulative_SOC_deviation: 271.8041 Fuel Consumption: 38.5188\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.416\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -2928.551958431643 SOC: 0.2532 Cumulative_SOC_deviation: 362.3556 Fuel Consumption: 29.7071\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.646\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -3043.5102069275213 SOC: 0.2229 Cumulative_SOC_deviation: 376.9808 Fuel Consumption: 27.6641\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.517\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -2939.9301623848664 SOC: 0.2408 Cumulative_SOC_deviation: 363.9043 Fuel Consumption: 28.6959\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.445\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -2438.3248034494995 SOC: 0.3086 Cumulative_SOC_deviation: 300.6297 Fuel Consumption: 33.2875\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.459\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -2899.5507823436797 SOC: 0.2621 Cumulative_SOC_deviation: 358.6350 Fuel Consumption: 30.4706\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.960\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -3205.7594913817866 SOC: 0.1967 Cumulative_SOC_deviation: 397.4348 Fuel Consumption: 26.2815\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.337\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -3054.8556975753336 SOC: 0.2172 Cumulative_SOC_deviation: 378.4570 Fuel Consumption: 27.1998\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.401\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -3394.613235933255 SOC: 0.1861 Cumulative_SOC_deviation: 421.1950 Fuel Consumption: 25.0536\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.918\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -3164.9062777137274 SOC: 0.2252 Cumulative_SOC_deviation: 392.0843 Fuel Consumption: 28.2316\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.314\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -3290.253410973557 SOC: 0.1954 Cumulative_SOC_deviation: 408.0442 Fuel Consumption: 25.8997\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.433\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -3046.269794226783 SOC: 0.2192 Cumulative_SOC_deviation: 377.3657 Fuel Consumption: 27.3442\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.744\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -2896.351226646095 SOC: 0.2477 Cumulative_SOC_deviation: 358.3370 Fuel Consumption: 29.6555\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.741\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -1432.4299763380793 SOC: 0.6455 Cumulative_SOC_deviation: 171.7283 Fuel Consumption: 58.6034\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.402\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -222.6697231408636 SOC: 0.6262 Cumulative_SOC_deviation: 21.2485 Fuel Consumption: 52.6819\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.853\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -147.48260556975347 SOC: 0.6076 Cumulative_SOC_deviation: 12.2257 Fuel Consumption: 49.6770\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.549\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -175.4020398945708 SOC: 0.6257 Cumulative_SOC_deviation: 15.4946 Fuel Consumption: 51.4453\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.838\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -128.63569049767267 SOC: 0.6044 Cumulative_SOC_deviation: 9.9259 Fuel Consumption: 49.2288\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.646\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -115.55934256309436 SOC: 0.5994 Cumulative_SOC_deviation: 8.3457 Fuel Consumption: 48.7935\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.616\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -124.47746646807491 SOC: 0.6072 Cumulative_SOC_deviation: 9.4314 Fuel Consumption: 49.0266\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.898\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -122.26980243286354 SOC: 0.6012 Cumulative_SOC_deviation: 9.1949 Fuel Consumption: 48.7105\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.594\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -132.44362922500076 SOC: 0.5998 Cumulative_SOC_deviation: 10.5919 Fuel Consumption: 47.7080\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.417\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -123.50166696426601 SOC: 0.6125 Cumulative_SOC_deviation: 9.2103 Fuel Consumption: 49.8196\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.557\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -141.54286267048224 SOC: 0.6018 Cumulative_SOC_deviation: 11.5536 Fuel Consumption: 49.1143\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.805\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -129.9371393541617 SOC: 0.6129 Cumulative_SOC_deviation: 10.0215 Fuel Consumption: 49.7650\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.773\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -139.0908886253506 SOC: 0.5988 Cumulative_SOC_deviation: 11.2726 Fuel Consumption: 48.9100\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.532\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -127.80418614906338 SOC: 0.6041 Cumulative_SOC_deviation: 9.7668 Fuel Consumption: 49.6699\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.876\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -139.45476590896376 SOC: 0.6015 Cumulative_SOC_deviation: 11.3119 Fuel Consumption: 48.9599\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.166\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -157.46053536717736 SOC: 0.6004 Cumulative_SOC_deviation: 13.5557 Fuel Consumption: 49.0149\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.079\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -125.24113495881248 SOC: 0.6084 Cumulative_SOC_deviation: 9.4440 Fuel Consumption: 49.6895\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.311\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -130.75519857985432 SOC: 0.5915 Cumulative_SOC_deviation: 10.3198 Fuel Consumption: 48.1965\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.832\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -141.55775269738385 SOC: 0.5978 Cumulative_SOC_deviation: 11.6756 Fuel Consumption: 48.1527\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.861\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -147.74304781563447 SOC: 0.6013 Cumulative_SOC_deviation: 12.4324 Fuel Consumption: 48.2842\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.555\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -139.74325132833738 SOC: 0.5900 Cumulative_SOC_deviation: 11.4988 Fuel Consumption: 47.7525\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.692\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -177.95559411235038 SOC: 0.5918 Cumulative_SOC_deviation: 16.3749 Fuel Consumption: 46.9566\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.565\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -159.95549759384787 SOC: 0.6012 Cumulative_SOC_deviation: 13.9817 Fuel Consumption: 48.1022\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.663\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -166.25239147139652 SOC: 0.5962 Cumulative_SOC_deviation: 14.8310 Fuel Consumption: 47.6041\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.435\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -204.88014888880326 SOC: 0.5880 Cumulative_SOC_deviation: 19.7575 Fuel Consumption: 46.8204\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.276\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -173.91067955350843 SOC: 0.5872 Cumulative_SOC_deviation: 15.9130 Fuel Consumption: 46.6065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.187\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -198.60852120479146 SOC: 0.5870 Cumulative_SOC_deviation: 19.0217 Fuel Consumption: 46.4350\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.618\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -190.25310664030786 SOC: 0.5954 Cumulative_SOC_deviation: 17.8296 Fuel Consumption: 47.6166\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.412\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -217.92767670389304 SOC: 0.5840 Cumulative_SOC_deviation: 21.4667 Fuel Consumption: 46.1938\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.545\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -236.92161112405083 SOC: 0.5826 Cumulative_SOC_deviation: 23.7923 Fuel Consumption: 46.5830\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.538\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -183.70194233884203 SOC: 0.5910 Cumulative_SOC_deviation: 17.0394 Fuel Consumption: 47.3865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.811\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -194.22817910768404 SOC: 0.5873 Cumulative_SOC_deviation: 18.3258 Fuel Consumption: 47.6216\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.362\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -215.79772211888763 SOC: 0.5902 Cumulative_SOC_deviation: 21.0567 Fuel Consumption: 47.3440\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.285\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -208.5177306544401 SOC: 0.5902 Cumulative_SOC_deviation: 20.1086 Fuel Consumption: 47.6487\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.608\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -204.06258954817287 SOC: 0.5920 Cumulative_SOC_deviation: 19.5510 Fuel Consumption: 47.6547\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.727\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -166.46469761456936 SOC: 0.5892 Cumulative_SOC_deviation: 14.9048 Fuel Consumption: 47.2264\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.631\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -210.06224936807234 SOC: 0.5848 Cumulative_SOC_deviation: 20.2162 Fuel Consumption: 48.3328\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.767\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -240.34062946475015 SOC: 0.5808 Cumulative_SOC_deviation: 24.1182 Fuel Consumption: 47.3949\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.845\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -217.67226909496884 SOC: 0.5939 Cumulative_SOC_deviation: 21.0849 Fuel Consumption: 48.9934\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.705\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -213.7049845263343 SOC: 0.5842 Cumulative_SOC_deviation: 20.8378 Fuel Consumption: 47.0024\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.861\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -221.87394278480733 SOC: 0.5850 Cumulative_SOC_deviation: 21.8867 Fuel Consumption: 46.7805\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.214\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -221.2457454949082 SOC: 0.5781 Cumulative_SOC_deviation: 21.7523 Fuel Consumption: 47.2273\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.836\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -216.90219347399682 SOC: 0.5784 Cumulative_SOC_deviation: 21.2069 Fuel Consumption: 47.2473\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.302\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -266.58423133126666 SOC: 0.5883 Cumulative_SOC_deviation: 27.3381 Fuel Consumption: 47.8798\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.588\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -245.75470827707483 SOC: 0.5769 Cumulative_SOC_deviation: 24.8831 Fuel Consumption: 46.6903\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.013\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -287.9620699702931 SOC: 0.5790 Cumulative_SOC_deviation: 30.2131 Fuel Consumption: 46.2574\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.424\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -304.88926042746584 SOC: 0.5814 Cumulative_SOC_deviation: 32.2016 Fuel Consumption: 47.2763\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.113\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -252.4034054813969 SOC: 0.5835 Cumulative_SOC_deviation: 25.6984 Fuel Consumption: 46.8159\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.136\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -314.61420948759957 SOC: 0.5683 Cumulative_SOC_deviation: 33.7280 Fuel Consumption: 44.7904\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.454\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -348.48738416862795 SOC: 0.5716 Cumulative_SOC_deviation: 37.9462 Fuel Consumption: 44.9180\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.378\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -205.37298123903162 SOC: 0.5884 Cumulative_SOC_deviation: 19.9239 Fuel Consumption: 45.9819\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.670\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -232.38760693461532 SOC: 0.5903 Cumulative_SOC_deviation: 23.1447 Fuel Consumption: 47.2304\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.045\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -184.50987092901514 SOC: 0.5951 Cumulative_SOC_deviation: 17.0897 Fuel Consumption: 47.7923\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.834\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -109.79145802368974 SOC: 0.5990 Cumulative_SOC_deviation: 7.5970 Fuel Consumption: 49.0158\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.480\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -115.62067186851216 SOC: 0.6017 Cumulative_SOC_deviation: 8.1149 Fuel Consumption: 50.7016\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.620\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -125.25511437767454 SOC: 0.6017 Cumulative_SOC_deviation: 9.4352 Fuel Consumption: 49.7732\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.517\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -124.55573829667249 SOC: 0.6050 Cumulative_SOC_deviation: 9.2992 Fuel Consumption: 50.1622\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.114\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -115.1370116827299 SOC: 0.5997 Cumulative_SOC_deviation: 8.1307 Fuel Consumption: 50.0912\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.943\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -119.15519773163513 SOC: 0.5989 Cumulative_SOC_deviation: 8.6726 Fuel Consumption: 49.7743\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.119\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -129.11493309339002 SOC: 0.6026 Cumulative_SOC_deviation: 10.0339 Fuel Consumption: 48.8434\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.121\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -139.84357081689103 SOC: 0.6019 Cumulative_SOC_deviation: 11.3962 Fuel Consumption: 48.6738\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.094\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -134.21251695820712 SOC: 0.5971 Cumulative_SOC_deviation: 10.6603 Fuel Consumption: 48.9302\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.624\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -133.97166430109067 SOC: 0.5967 Cumulative_SOC_deviation: 10.6345 Fuel Consumption: 48.8956\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.431\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -143.91551116792067 SOC: 0.5915 Cumulative_SOC_deviation: 11.9064 Fuel Consumption: 48.6644\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.621\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -169.2899931070273 SOC: 0.5913 Cumulative_SOC_deviation: 14.9625 Fuel Consumption: 49.5900\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.380\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -159.765189703488 SOC: 0.6008 Cumulative_SOC_deviation: 13.8209 Fuel Consumption: 49.1977\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.173\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -156.70619034269 SOC: 0.6019 Cumulative_SOC_deviation: 13.3733 Fuel Consumption: 49.7201\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.905\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -142.2653638598188 SOC: 0.5934 Cumulative_SOC_deviation: 11.7069 Fuel Consumption: 48.6101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.772\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -147.57890742711456 SOC: 0.5914 Cumulative_SOC_deviation: 12.4159 Fuel Consumption: 48.2514\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.447\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -141.11867522116253 SOC: 0.5966 Cumulative_SOC_deviation: 11.6974 Fuel Consumption: 47.5393\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.442\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -146.5299264495218 SOC: 0.5979 Cumulative_SOC_deviation: 12.3109 Fuel Consumption: 48.0428\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.887\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -122.81355867443422 SOC: 0.5959 Cumulative_SOC_deviation: 9.3555 Fuel Consumption: 47.9696\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.100\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -140.19632385162598 SOC: 0.5985 Cumulative_SOC_deviation: 11.4763 Fuel Consumption: 48.3857\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.718\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -132.7817385586839 SOC: 0.5854 Cumulative_SOC_deviation: 10.6680 Fuel Consumption: 47.4374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.916\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -134.76532865551292 SOC: 0.6012 Cumulative_SOC_deviation: 10.7255 Fuel Consumption: 48.9614\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.183\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -146.9038918198253 SOC: 0.5948 Cumulative_SOC_deviation: 12.3132 Fuel Consumption: 48.3982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.689\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -132.5394834824185 SOC: 0.5932 Cumulative_SOC_deviation: 10.5925 Fuel Consumption: 47.7991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.567\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -138.69523016188646 SOC: 0.5967 Cumulative_SOC_deviation: 11.2319 Fuel Consumption: 48.8400\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.840\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -150.07019674684108 SOC: 0.5975 Cumulative_SOC_deviation: 12.7245 Fuel Consumption: 48.2742\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.844\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -133.510795635495 SOC: 0.5928 Cumulative_SOC_deviation: 10.6260 Fuel Consumption: 48.5026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.560\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -138.2154509115533 SOC: 0.5980 Cumulative_SOC_deviation: 11.2158 Fuel Consumption: 48.4889\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.542\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -136.03462338025906 SOC: 0.5983 Cumulative_SOC_deviation: 10.9124 Fuel Consumption: 48.7351\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.790\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -141.92411709857947 SOC: 0.5993 Cumulative_SOC_deviation: 11.5604 Fuel Consumption: 49.4408\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.757\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -124.97495211189703 SOC: 0.6031 Cumulative_SOC_deviation: 9.5044 Fuel Consumption: 48.9397\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.766\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -117.85389828658074 SOC: 0.5939 Cumulative_SOC_deviation: 8.7182 Fuel Consumption: 48.1086\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.238\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -157.6235480237017 SOC: 0.5936 Cumulative_SOC_deviation: 13.6477 Fuel Consumption: 48.4421\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.973\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -119.6535841699396 SOC: 0.5966 Cumulative_SOC_deviation: 8.8636 Fuel Consumption: 48.7450\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.010\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -122.20766401617082 SOC: 0.6010 Cumulative_SOC_deviation: 9.1657 Fuel Consumption: 48.8824\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.088\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -137.963184232109 SOC: 0.5863 Cumulative_SOC_deviation: 11.2115 Fuel Consumption: 48.2714\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.588\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -146.15152252971268 SOC: 0.5972 Cumulative_SOC_deviation: 12.1721 Fuel Consumption: 48.7750\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.677\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -127.41876461708364 SOC: 0.6043 Cumulative_SOC_deviation: 9.8556 Fuel Consumption: 48.5740\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.137\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -147.9259924047068 SOC: 0.5940 Cumulative_SOC_deviation: 12.4711 Fuel Consumption: 48.1575\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.783\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -146.81106357154312 SOC: 0.5961 Cumulative_SOC_deviation: 12.2324 Fuel Consumption: 48.9522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.207\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -144.3917580043304 SOC: 0.5920 Cumulative_SOC_deviation: 12.0096 Fuel Consumption: 48.3147\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.075\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -153.24057647719331 SOC: 0.5943 Cumulative_SOC_deviation: 13.0371 Fuel Consumption: 48.9434\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.356\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -152.23411017372067 SOC: 0.5960 Cumulative_SOC_deviation: 13.0003 Fuel Consumption: 48.2317\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.212\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -169.85292144105614 SOC: 0.5933 Cumulative_SOC_deviation: 15.0813 Fuel Consumption: 49.2028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.841\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -133.72548106929662 SOC: 0.5984 Cumulative_SOC_deviation: 10.7373 Fuel Consumption: 47.8273\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.740\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -114.20655345178236 SOC: 0.5979 Cumulative_SOC_deviation: 8.3951 Fuel Consumption: 47.0459\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.188\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -159.34169751603653 SOC: 0.5967 Cumulative_SOC_deviation: 13.9155 Fuel Consumption: 48.0176\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.327\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -140.52731380960614 SOC: 0.6001 Cumulative_SOC_deviation: 11.5301 Fuel Consumption: 48.2861\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.479\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -146.83649089721428 SOC: 0.5969 Cumulative_SOC_deviation: 12.3309 Fuel Consumption: 48.1894\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.766\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -140.03884384252714 SOC: 0.5991 Cumulative_SOC_deviation: 11.5115 Fuel Consumption: 47.9470\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.145\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -137.67279897451823 SOC: 0.6046 Cumulative_SOC_deviation: 11.1008 Fuel Consumption: 48.8665\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.823\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -145.6178752580294 SOC: 0.6037 Cumulative_SOC_deviation: 12.0989 Fuel Consumption: 48.8266\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.648\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -150.2889878991901 SOC: 0.6022 Cumulative_SOC_deviation: 12.7006 Fuel Consumption: 48.6843\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.464\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -128.41505409320274 SOC: 0.6036 Cumulative_SOC_deviation: 10.0199 Fuel Consumption: 48.2558\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.369\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -123.46266225151628 SOC: 0.5998 Cumulative_SOC_deviation: 9.4196 Fuel Consumption: 48.1061\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.899\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -127.8014251474897 SOC: 0.5980 Cumulative_SOC_deviation: 10.0251 Fuel Consumption: 47.6007\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.500\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -158.34912425617705 SOC: 0.5951 Cumulative_SOC_deviation: 13.7019 Fuel Consumption: 48.7343\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.129\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -135.70295141183328 SOC: 0.5972 Cumulative_SOC_deviation: 10.8221 Fuel Consumption: 49.1265\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.054\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -158.29068547328882 SOC: 0.5894 Cumulative_SOC_deviation: 13.6716 Fuel Consumption: 48.9180\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.542\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -161.77367416425636 SOC: 0.6024 Cumulative_SOC_deviation: 14.1969 Fuel Consumption: 48.1988\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.962\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -135.2972333632876 SOC: 0.5962 Cumulative_SOC_deviation: 10.9399 Fuel Consumption: 47.7779\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 80.663\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -133.43731706289748 SOC: 0.5996 Cumulative_SOC_deviation: 10.6058 Fuel Consumption: 48.5908\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.374\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -132.76810809513896 SOC: 0.5993 Cumulative_SOC_deviation: 10.6667 Fuel Consumption: 47.4347\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 9\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.102\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -4612.0648976459415 SOC: 1.0000 Cumulative_SOC_deviation: 495.9425 Fuel Consumption: 148.5824\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.073\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -4623.488424913347 SOC: 1.0000 Cumulative_SOC_deviation: 496.9332 Fuel Consumption: 151.0897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 17.020\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -4597.265934587124 SOC: 1.0000 Cumulative_SOC_deviation: 493.7341 Fuel Consumption: 153.6589\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_10 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_11 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_9 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 41.006\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -4579.89862574581 SOC: 1.0000 Cumulative_SOC_deviation: 492.3731 Fuel Consumption: 148.5411\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.415\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -4565.569592272663 SOC: 1.0000 Cumulative_SOC_deviation: 490.9678 Fuel Consumption: 146.8592\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.441\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4515.6655396713995 SOC: 1.0000 Cumulative_SOC_deviation: 485.7164 Fuel Consumption: 144.2178\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.602\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4510.462723376784 SOC: 1.0000 Cumulative_SOC_deviation: 485.1704 Fuel Consumption: 143.9289\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.714\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -4463.491749203077 SOC: 1.0000 Cumulative_SOC_deviation: 480.5728 Fuel Consumption: 138.3364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.762\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -4466.93315658804 SOC: 1.0000 Cumulative_SOC_deviation: 480.8818 Fuel Consumption: 138.9968\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.835\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -4414.07649073535 SOC: 1.0000 Cumulative_SOC_deviation: 475.7472 Fuel Consumption: 132.3519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.729\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -4364.948838708755 SOC: 1.0000 Cumulative_SOC_deviation: 471.1862 Fuel Consumption: 124.2728\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.830\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -4382.882407658159 SOC: 1.0000 Cumulative_SOC_deviation: 472.7111 Fuel Consumption: 128.4826\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.094\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -4319.485125011663 SOC: 1.0000 Cumulative_SOC_deviation: 465.8160 Fuel Consumption: 127.1413\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.716\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -4194.167900464329 SOC: 1.0000 Cumulative_SOC_deviation: 452.6038 Fuel Consumption: 120.7337\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.846\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -4232.975097339036 SOC: 1.0000 Cumulative_SOC_deviation: 457.2115 Fuel Consumption: 118.0716\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.882\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -4128.061740814859 SOC: 1.0000 Cumulative_SOC_deviation: 445.5854 Fuel Consumption: 117.7930\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.247\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -4072.0934058272705 SOC: 1.0000 Cumulative_SOC_deviation: 439.7886 Fuel Consumption: 113.9960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.358\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -4111.109077839116 SOC: 1.0000 Cumulative_SOC_deviation: 444.0090 Fuel Consumption: 115.0278\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.205\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -3936.3570147310807 SOC: 1.0000 Cumulative_SOC_deviation: 425.3075 Fuel Consumption: 108.5892\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.440\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -3915.144232744919 SOC: 1.0000 Cumulative_SOC_deviation: 423.1489 Fuel Consumption: 106.8042\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.407\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -3831.7345826549767 SOC: 1.0000 Cumulative_SOC_deviation: 414.0141 Fuel Consumption: 105.6073\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.395\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -3913.0443170308035 SOC: 1.0000 Cumulative_SOC_deviation: 422.8571 Fuel Consumption: 107.3304\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.185\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -3676.661974212763 SOC: 1.0000 Cumulative_SOC_deviation: 397.3938 Fuel Consumption: 100.1181\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.093\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -3629.5785293135364 SOC: 1.0000 Cumulative_SOC_deviation: 391.8275 Fuel Consumption: 103.1310\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.179\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -3602.0573992528334 SOC: 1.0000 Cumulative_SOC_deviation: 389.3119 Fuel Consumption: 98.2505\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.344\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -3311.2589233679846 SOC: 1.0000 Cumulative_SOC_deviation: 357.6281 Fuel Consumption: 92.6065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.463\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -3494.7766453706276 SOC: 1.0000 Cumulative_SOC_deviation: 377.3998 Fuel Consumption: 98.1782\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.517\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -3103.4152959927824 SOC: 1.0000 Cumulative_SOC_deviation: 334.1743 Fuel Consumption: 95.8463\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.180\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -3298.664027232437 SOC: 1.0000 Cumulative_SOC_deviation: 355.8744 Fuel Consumption: 95.7948\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.343\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -3609.6749090195717 SOC: 1.0000 Cumulative_SOC_deviation: 390.3750 Fuel Consumption: 96.3003\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.953\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -3518.2493285442292 SOC: 1.0000 Cumulative_SOC_deviation: 380.1787 Fuel Consumption: 96.6408\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.311\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -3048.8601307880135 SOC: 1.0000 Cumulative_SOC_deviation: 328.7856 Fuel Consumption: 89.7896\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.616\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -2592.595325139608 SOC: 1.0000 Cumulative_SOC_deviation: 278.3268 Fuel Consumption: 87.6537\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 83.589\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -2458.536022839882 SOC: 1.0000 Cumulative_SOC_deviation: 263.6217 Fuel Consumption: 85.9409\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.831\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -2309.982164122431 SOC: 1.0000 Cumulative_SOC_deviation: 247.2097 Fuel Consumption: 85.0948\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.610\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -2304.4230534571934 SOC: 1.0000 Cumulative_SOC_deviation: 246.3192 Fuel Consumption: 87.5506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.603\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -2430.4445903012297 SOC: 1.0000 Cumulative_SOC_deviation: 260.4717 Fuel Consumption: 86.1989\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.627\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -2113.4791524498014 SOC: 0.9991 Cumulative_SOC_deviation: 225.4345 Fuel Consumption: 84.5686\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.776\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1673.9380716100964 SOC: 0.9685 Cumulative_SOC_deviation: 176.8683 Fuel Consumption: 82.1232\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.490\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1406.6256425617332 SOC: 0.9273 Cumulative_SOC_deviation: 147.5888 Fuel Consumption: 78.3261\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.544\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1937.3263759536003 SOC: 0.9720 Cumulative_SOC_deviation: 206.1234 Fuel Consumption: 82.2161\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.398\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1474.6019273581321 SOC: 0.9198 Cumulative_SOC_deviation: 155.1337 Fuel Consumption: 78.3984\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.990\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1438.0394042997823 SOC: 0.9554 Cumulative_SOC_deviation: 150.7525 Fuel Consumption: 81.2668\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.812\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -1486.7400933033264 SOC: 0.9535 Cumulative_SOC_deviation: 156.2336 Fuel Consumption: 80.6374\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.042\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -1358.698432967736 SOC: 0.8970 Cumulative_SOC_deviation: 142.4642 Fuel Consumption: 76.5205\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.956\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -1207.9935563586441 SOC: 0.8797 Cumulative_SOC_deviation: 125.8648 Fuel Consumption: 75.2101\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.325\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -830.2889303733496 SOC: 0.7892 Cumulative_SOC_deviation: 84.6268 Fuel Consumption: 68.6477\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.122\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -997.9816219375275 SOC: 0.8150 Cumulative_SOC_deviation: 103.0644 Fuel Consumption: 70.4018\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.082\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -862.3576850783679 SOC: 0.7085 Cumulative_SOC_deviation: 88.8515 Fuel Consumption: 62.6942\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.779\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -865.5140182322534 SOC: 0.6861 Cumulative_SOC_deviation: 89.3788 Fuel Consumption: 61.1052\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.013\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -964.5590210022355 SOC: 0.6421 Cumulative_SOC_deviation: 100.7071 Fuel Consumption: 58.1955\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.304\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -701.4837894273246 SOC: 0.7448 Cumulative_SOC_deviation: 70.7599 Fuel Consumption: 64.6443\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.564\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -827.7810439604345 SOC: 0.7229 Cumulative_SOC_deviation: 84.8423 Fuel Consumption: 64.2006\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.802\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -578.9197367658476 SOC: 0.6940 Cumulative_SOC_deviation: 57.5659 Fuel Consumption: 60.8266\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.842\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -780.7277692218638 SOC: 0.7169 Cumulative_SOC_deviation: 79.7081 Fuel Consumption: 63.3545\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.152\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -1742.232482237737 SOC: 0.5372 Cumulative_SOC_deviation: 188.0668 Fuel Consumption: 49.6314\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.123\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -1158.0585497998281 SOC: 0.6027 Cumulative_SOC_deviation: 122.5555 Fuel Consumption: 55.0587\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.972\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -1018.4977803056165 SOC: 0.6053 Cumulative_SOC_deviation: 107.1199 Fuel Consumption: 54.4190\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.993\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -1733.785642014107 SOC: 0.5326 Cumulative_SOC_deviation: 187.0767 Fuel Consumption: 50.0957\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.098\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -2397.0539553022027 SOC: 0.3955 Cumulative_SOC_deviation: 261.9276 Fuel Consumption: 39.7054\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.756\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -1527.1401033244817 SOC: 0.4996 Cumulative_SOC_deviation: 164.4623 Fuel Consumption: 46.9796\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.851\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -1642.3492960721742 SOC: 0.5079 Cumulative_SOC_deviation: 177.1934 Fuel Consumption: 47.6090\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.436\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -2333.9258576976445 SOC: 0.4381 Cumulative_SOC_deviation: 254.5866 Fuel Consumption: 42.6460\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.112\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -2393.3063271448764 SOC: 0.4042 Cumulative_SOC_deviation: 261.4138 Fuel Consumption: 40.5824\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.007\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -2250.2570238784097 SOC: 0.4111 Cumulative_SOC_deviation: 245.4965 Fuel Consumption: 40.7888\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.797\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -1694.9139082764134 SOC: 0.4449 Cumulative_SOC_deviation: 183.5681 Fuel Consumption: 42.8008\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.402\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -2572.5279785432926 SOC: 0.3665 Cumulative_SOC_deviation: 281.6632 Fuel Consumption: 37.5592\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.148\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -2863.753999309039 SOC: 0.2957 Cumulative_SOC_deviation: 314.5777 Fuel Consumption: 32.5549\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.268\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -2785.338889983835 SOC: 0.3256 Cumulative_SOC_deviation: 305.6448 Fuel Consumption: 34.5360\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.886\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -2851.0303304253443 SOC: 0.3069 Cumulative_SOC_deviation: 313.1513 Fuel Consumption: 32.6684\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.025\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -2826.6191471063853 SOC: 0.3523 Cumulative_SOC_deviation: 309.9414 Fuel Consumption: 37.1465\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.311\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -2532.53655098016 SOC: 0.3641 Cumulative_SOC_deviation: 277.2369 Fuel Consumption: 37.4044\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.379\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -3078.517699031817 SOC: 0.2686 Cumulative_SOC_deviation: 338.6857 Fuel Consumption: 30.3468\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.671\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -3019.2912296246163 SOC: 0.2799 Cumulative_SOC_deviation: 331.9548 Fuel Consumption: 31.6985\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.821\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -3492.6255463820685 SOC: 0.2240 Cumulative_SOC_deviation: 384.9487 Fuel Consumption: 28.0871\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.458\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -3176.6933988151163 SOC: 0.2633 Cumulative_SOC_deviation: 349.5872 Fuel Consumption: 30.4087\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.419\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -3344.840929219137 SOC: 0.2611 Cumulative_SOC_deviation: 368.2164 Fuel Consumption: 30.8937\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.064\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -753.4418291771887 SOC: 0.6559 Cumulative_SOC_deviation: 77.2352 Fuel Consumption: 58.3250\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.053\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -229.1242364541081 SOC: 0.6144 Cumulative_SOC_deviation: 19.7526 Fuel Consumption: 51.3506\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.051\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -249.56121743262318 SOC: 0.6341 Cumulative_SOC_deviation: 21.6858 Fuel Consumption: 54.3894\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.401\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -146.57589323564525 SOC: 0.6169 Cumulative_SOC_deviation: 10.5359 Fuel Consumption: 51.7527\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.468\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -145.55124099628478 SOC: 0.6174 Cumulative_SOC_deviation: 10.4523 Fuel Consumption: 51.4804\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.753\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -154.52669453422877 SOC: 0.6055 Cumulative_SOC_deviation: 11.5613 Fuel Consumption: 50.4746\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.523\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -155.2013669329012 SOC: 0.6052 Cumulative_SOC_deviation: 11.6906 Fuel Consumption: 49.9864\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.554\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -234.03591178786428 SOC: 0.5897 Cumulative_SOC_deviation: 20.3889 Fuel Consumption: 50.5358\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.031\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -288.58272110648903 SOC: 0.6045 Cumulative_SOC_deviation: 26.5046 Fuel Consumption: 50.0412\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.040\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -147.39300031648102 SOC: 0.6072 Cumulative_SOC_deviation: 10.5847 Fuel Consumption: 52.1306\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.352\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -150.90990942031362 SOC: 0.6122 Cumulative_SOC_deviation: 11.0173 Fuel Consumption: 51.7541\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.229\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -182.69039471631186 SOC: 0.5904 Cumulative_SOC_deviation: 14.7863 Fuel Consumption: 49.6139\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.317\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -377.75289142983956 SOC: 0.5623 Cumulative_SOC_deviation: 36.5802 Fuel Consumption: 48.5312\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.329\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -259.2615308159047 SOC: 0.5916 Cumulative_SOC_deviation: 23.0215 Fuel Consumption: 52.0680\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.303\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -145.92133282632048 SOC: 0.6012 Cumulative_SOC_deviation: 10.3944 Fuel Consumption: 52.3715\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.301\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -180.08342370431794 SOC: 0.5962 Cumulative_SOC_deviation: 14.3329 Fuel Consumption: 51.0875\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.416\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -146.2547449380227 SOC: 0.5998 Cumulative_SOC_deviation: 10.3702 Fuel Consumption: 52.9225\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.384\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -158.72245878924002 SOC: 0.6058 Cumulative_SOC_deviation: 11.7605 Fuel Consumption: 52.8777\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.568\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -123.71207609026067 SOC: 0.6056 Cumulative_SOC_deviation: 7.9317 Fuel Consumption: 52.3272\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.378\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -126.93269726877482 SOC: 0.6141 Cumulative_SOC_deviation: 8.3052 Fuel Consumption: 52.1859\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.509\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -148.7754133928371 SOC: 0.6044 Cumulative_SOC_deviation: 10.9804 Fuel Consumption: 49.9517\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.099\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -124.14935832929446 SOC: 0.5962 Cumulative_SOC_deviation: 8.4370 Fuel Consumption: 48.2160\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.420\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -128.46209745854333 SOC: 0.6023 Cumulative_SOC_deviation: 8.9383 Fuel Consumption: 48.0178\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.819\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -127.38556984658393 SOC: 0.5966 Cumulative_SOC_deviation: 8.8261 Fuel Consumption: 47.9509\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.216\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -151.28869198730237 SOC: 0.5977 Cumulative_SOC_deviation: 11.4836 Fuel Consumption: 47.9363\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.510\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -118.89521707208193 SOC: 0.5948 Cumulative_SOC_deviation: 7.9199 Fuel Consumption: 47.6162\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.564\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -139.05254905696762 SOC: 0.6036 Cumulative_SOC_deviation: 10.0196 Fuel Consumption: 48.8759\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.982\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -150.24826190072315 SOC: 0.6017 Cumulative_SOC_deviation: 11.2034 Fuel Consumption: 49.4175\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.972\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -143.29321551372448 SOC: 0.6090 Cumulative_SOC_deviation: 10.3039 Fuel Consumption: 50.5580\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.786\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -134.9188180991183 SOC: 0.6016 Cumulative_SOC_deviation: 9.4584 Fuel Consumption: 49.7929\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.912\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -131.25850814548184 SOC: 0.5966 Cumulative_SOC_deviation: 9.0507 Fuel Consumption: 49.8026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.860\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -116.55878685959112 SOC: 0.6008 Cumulative_SOC_deviation: 7.4886 Fuel Consumption: 49.1612\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.667\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -111.96433523447993 SOC: 0.6029 Cumulative_SOC_deviation: 7.2016 Fuel Consumption: 47.1499\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.920\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -168.37222485448584 SOC: 0.5974 Cumulative_SOC_deviation: 13.1464 Fuel Consumption: 50.0543\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.491\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -186.73498093632895 SOC: 0.5989 Cumulative_SOC_deviation: 15.1963 Fuel Consumption: 49.9682\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.718\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -222.19550748859297 SOC: 0.5915 Cumulative_SOC_deviation: 19.0974 Fuel Consumption: 50.3185\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.266\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -138.84157386616795 SOC: 0.6036 Cumulative_SOC_deviation: 10.0072 Fuel Consumption: 48.7766\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.527\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -186.0927678976529 SOC: 0.5948 Cumulative_SOC_deviation: 15.2705 Fuel Consumption: 48.6584\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.537\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -135.44261621936874 SOC: 0.6030 Cumulative_SOC_deviation: 9.6709 Fuel Consumption: 48.4045\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.884\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -145.197433117976 SOC: 0.5972 Cumulative_SOC_deviation: 10.8751 Fuel Consumption: 47.3217\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.735\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -116.43125462532771 SOC: 0.6047 Cumulative_SOC_deviation: 7.6244 Fuel Consumption: 47.8115\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.150\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -110.75953800597372 SOC: 0.6059 Cumulative_SOC_deviation: 7.0625 Fuel Consumption: 47.1970\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.356\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -113.85094113083976 SOC: 0.5990 Cumulative_SOC_deviation: 7.5270 Fuel Consumption: 46.1083\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.482\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -143.0557855699687 SOC: 0.5926 Cumulative_SOC_deviation: 10.8108 Fuel Consumption: 45.7584\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.629\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -134.96843606180587 SOC: 0.6056 Cumulative_SOC_deviation: 9.8231 Fuel Consumption: 46.5604\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.519\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -114.13004546010191 SOC: 0.5999 Cumulative_SOC_deviation: 7.5586 Fuel Consumption: 46.1029\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.545\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -112.56088654934784 SOC: 0.6016 Cumulative_SOC_deviation: 7.3667 Fuel Consumption: 46.2604\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.883\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -119.8135731779675 SOC: 0.5994 Cumulative_SOC_deviation: 8.1877 Fuel Consumption: 46.1240\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.948\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -126.34447631073186 SOC: 0.6024 Cumulative_SOC_deviation: 8.9116 Fuel Consumption: 46.1404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.147\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -143.95658164787204 SOC: 0.6040 Cumulative_SOC_deviation: 10.8888 Fuel Consumption: 45.9573\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.662\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -151.67466163438795 SOC: 0.5992 Cumulative_SOC_deviation: 11.7243 Fuel Consumption: 46.1564\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.461\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -139.21627831738516 SOC: 0.5970 Cumulative_SOC_deviation: 10.3339 Fuel Consumption: 46.2110\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.523\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -119.68788786296757 SOC: 0.5999 Cumulative_SOC_deviation: 8.1844 Fuel Consumption: 46.0285\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.518\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -118.46933563739539 SOC: 0.6022 Cumulative_SOC_deviation: 8.0855 Fuel Consumption: 45.6997\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.896\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -120.96825196604274 SOC: 0.5945 Cumulative_SOC_deviation: 8.3573 Fuel Consumption: 45.7528\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.740\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -131.5152022623227 SOC: 0.6012 Cumulative_SOC_deviation: 9.4699 Fuel Consumption: 46.2864\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.093\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -138.03914308795063 SOC: 0.5936 Cumulative_SOC_deviation: 10.3019 Fuel Consumption: 45.3216\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.405\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -141.58819878762313 SOC: 0.5946 Cumulative_SOC_deviation: 10.6874 Fuel Consumption: 45.4017\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.874\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -145.711698911193 SOC: 0.5952 Cumulative_SOC_deviation: 11.1339 Fuel Consumption: 45.5065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.593\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -141.3383673195926 SOC: 0.5960 Cumulative_SOC_deviation: 10.6429 Fuel Consumption: 45.5519\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.798\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -140.6778808330189 SOC: 0.5956 Cumulative_SOC_deviation: 10.5973 Fuel Consumption: 45.3019\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.556\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -136.58707426363586 SOC: 0.5969 Cumulative_SOC_deviation: 10.1150 Fuel Consumption: 45.5520\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.539\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -140.34803602312903 SOC: 0.5954 Cumulative_SOC_deviation: 10.5693 Fuel Consumption: 45.2241\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.310\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -144.08373690878867 SOC: 0.5955 Cumulative_SOC_deviation: 10.9818 Fuel Consumption: 45.2472\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.640\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -131.1225433065697 SOC: 0.5954 Cumulative_SOC_deviation: 9.5180 Fuel Consumption: 45.4609\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.328\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -138.9666282792883 SOC: 0.5967 Cumulative_SOC_deviation: 10.3884 Fuel Consumption: 45.4708\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.765\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -152.30440555504495 SOC: 0.6013 Cumulative_SOC_deviation: 11.8193 Fuel Consumption: 45.9307\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 84.811\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -133.48420481359105 SOC: 0.6030 Cumulative_SOC_deviation: 9.6851 Fuel Consumption: 46.3182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.213\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -138.59503196247434 SOC: 0.5936 Cumulative_SOC_deviation: 10.3841 Fuel Consumption: 45.1382\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.837\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -151.74504243360167 SOC: 0.5925 Cumulative_SOC_deviation: 11.8394 Fuel Consumption: 45.1905\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.771\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -148.41172336540416 SOC: 0.5942 Cumulative_SOC_deviation: 11.4846 Fuel Consumption: 45.0499\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.472\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -144.4968075915878 SOC: 0.5961 Cumulative_SOC_deviation: 10.9802 Fuel Consumption: 45.6754\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.226\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -152.18249667749689 SOC: 0.5920 Cumulative_SOC_deviation: 11.8553 Fuel Consumption: 45.4852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 88.326\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -157.69914933856327 SOC: 0.5946 Cumulative_SOC_deviation: 12.5045 Fuel Consumption: 45.1588\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.567\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -175.4820264405784 SOC: 0.5952 Cumulative_SOC_deviation: 14.5025 Fuel Consumption: 44.9592\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.242\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -164.5844123988592 SOC: 0.5923 Cumulative_SOC_deviation: 13.3091 Fuel Consumption: 44.8025\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.600\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -145.41086013043295 SOC: 0.5979 Cumulative_SOC_deviation: 11.0963 Fuel Consumption: 45.5446\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.800\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -144.96646765737933 SOC: 0.5980 Cumulative_SOC_deviation: 11.0681 Fuel Consumption: 45.3536\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.533\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -158.59611050310951 SOC: 0.5941 Cumulative_SOC_deviation: 12.6381 Fuel Consumption: 44.8531\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.465\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -155.07242168430807 SOC: 0.5946 Cumulative_SOC_deviation: 12.1812 Fuel Consumption: 45.4415\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.907\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -146.2202186774978 SOC: 0.5942 Cumulative_SOC_deviation: 11.2339 Fuel Consumption: 45.1152\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.689\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -162.87618689114692 SOC: 0.5951 Cumulative_SOC_deviation: 13.0820 Fuel Consumption: 45.1379\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.981\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -156.34367497747976 SOC: 0.5924 Cumulative_SOC_deviation: 12.3781 Fuel Consumption: 44.9410\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.743\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -156.33762274643948 SOC: 0.5932 Cumulative_SOC_deviation: 12.3581 Fuel Consumption: 45.1147\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.469\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -162.88750762871396 SOC: 0.5933 Cumulative_SOC_deviation: 13.1207 Fuel Consumption: 44.8013\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.282\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -163.77421518794625 SOC: 0.5939 Cumulative_SOC_deviation: 13.2171 Fuel Consumption: 44.8206\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.567\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -168.40587049360659 SOC: 0.5935 Cumulative_SOC_deviation: 13.7125 Fuel Consumption: 44.9936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.854\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -168.33136630597747 SOC: 0.5930 Cumulative_SOC_deviation: 13.6863 Fuel Consumption: 45.1548\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.599\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -164.05214820021675 SOC: 0.5955 Cumulative_SOC_deviation: 13.2281 Fuel Consumption: 44.9994\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.020\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -173.62634726158626 SOC: 0.5929 Cumulative_SOC_deviation: 14.3409 Fuel Consumption: 44.5585\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.944\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -185.06662427784104 SOC: 0.5940 Cumulative_SOC_deviation: 15.5732 Fuel Consumption: 44.9078\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.761\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -164.02935645091236 SOC: 0.5937 Cumulative_SOC_deviation: 13.2150 Fuel Consumption: 45.0947\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.570\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -162.32413994692354 SOC: 0.5920 Cumulative_SOC_deviation: 13.0653 Fuel Consumption: 44.7360\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.504\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -171.0047624688586 SOC: 0.5933 Cumulative_SOC_deviation: 14.0387 Fuel Consumption: 44.6561\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.356\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -170.69002041254683 SOC: 0.5916 Cumulative_SOC_deviation: 14.0028 Fuel Consumption: 44.6649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.166\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -186.17460670874323 SOC: 0.5901 Cumulative_SOC_deviation: 15.6870 Fuel Consumption: 44.9914\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.782\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -174.29978076967922 SOC: 0.5902 Cumulative_SOC_deviation: 14.4236 Fuel Consumption: 44.4876\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.783\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -193.66683458985275 SOC: 0.5888 Cumulative_SOC_deviation: 16.5873 Fuel Consumption: 44.3813\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.257\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -185.88052741226153 SOC: 0.5918 Cumulative_SOC_deviation: 15.6822 Fuel Consumption: 44.7408\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.118\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -165.00237538980448 SOC: 0.5923 Cumulative_SOC_deviation: 13.3134 Fuel Consumption: 45.1815\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.482\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -183.78883536035846 SOC: 0.5978 Cumulative_SOC_deviation: 15.3960 Fuel Consumption: 45.2246\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.809\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -157.03300650416372 SOC: 0.5950 Cumulative_SOC_deviation: 12.4761 Fuel Consumption: 44.7481\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.513\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -148.7072245946754 SOC: 0.5970 Cumulative_SOC_deviation: 11.5145 Fuel Consumption: 45.0771\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 85.903\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -164.29011324474175 SOC: 0.5988 Cumulative_SOC_deviation: 13.2491 Fuel Consumption: 45.0479\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.645\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -165.0472738626898 SOC: 0.5955 Cumulative_SOC_deviation: 13.3493 Fuel Consumption: 44.9040\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.259\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -170.30966008732722 SOC: 0.5960 Cumulative_SOC_deviation: 13.9188 Fuel Consumption: 45.0405\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.157\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -168.12235886524812 SOC: 0.5947 Cumulative_SOC_deviation: 13.6807 Fuel Consumption: 44.9960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.441\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -164.09751227233613 SOC: 0.5952 Cumulative_SOC_deviation: 13.2436 Fuel Consumption: 44.9050\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.631\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -186.58115390032995 SOC: 0.5948 Cumulative_SOC_deviation: 15.7638 Fuel Consumption: 44.7070\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.048\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -167.95968740101878 SOC: 0.5974 Cumulative_SOC_deviation: 13.6233 Fuel Consumption: 45.3496\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.265\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -195.0522867709562 SOC: 0.5919 Cumulative_SOC_deviation: 16.7097 Fuel Consumption: 44.6648\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 86.382\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -197.45585934677152 SOC: 0.5951 Cumulative_SOC_deviation: 16.9698 Fuel Consumption: 44.7279\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 82.134\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -163.105826148927 SOC: 0.5935 Cumulative_SOC_deviation: 13.1504 Fuel Consumption: 44.7522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 81.253\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -187.51633397285954 SOC: 0.5974 Cumulative_SOC_deviation: 15.8330 Fuel Consumption: 45.0195\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 75.444\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -166.75256859108998 SOC: 0.5961 Cumulative_SOC_deviation: 13.5260 Fuel Consumption: 45.0182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.209\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -171.25332027391642 SOC: 0.5972 Cumulative_SOC_deviation: 14.0272 Fuel Consumption: 45.0083\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.169\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -170.63626920323082 SOC: 0.5957 Cumulative_SOC_deviation: 14.0100 Fuel Consumption: 44.5465\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.975\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -170.71441041726084 SOC: 0.5954 Cumulative_SOC_deviation: 14.0013 Fuel Consumption: 44.7028\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.018\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -185.63051828510163 SOC: 0.5908 Cumulative_SOC_deviation: 15.6739 Fuel Consumption: 44.5657\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.014\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -175.4506859394741 SOC: 0.5929 Cumulative_SOC_deviation: 14.5144 Fuel Consumption: 44.8215\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.102\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -193.52155432764548 SOC: 0.5951 Cumulative_SOC_deviation: 16.5511 Fuel Consumption: 44.5617\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 71.185\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -152.4530727646654 SOC: 0.5987 Cumulative_SOC_deviation: 11.9083 Fuel Consumption: 45.2788\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 70.961\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -174.19210089014933 SOC: 0.5987 Cumulative_SOC_deviation: 14.3742 Fuel Consumption: 44.8244\n",
      "\n",
      "model is saved..\n",
      "\n",
      "Trial 10\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.557\n",
      "Episode: 1 Exploration P: 1.0000 Total reward: -5126.449467280251 SOC: 1.0000 Cumulative_SOC_deviation: 497.5546 Fuel Consumption: 150.9039\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.279\n",
      "Episode: 2 Exploration P: 1.0000 Total reward: -5026.2827911407685 SOC: 1.0000 Cumulative_SOC_deviation: 487.4863 Fuel Consumption: 151.4198\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 12.133\n",
      "Episode: 3 Exploration P: 1.0000 Total reward: -5088.355437075464 SOC: 1.0000 Cumulative_SOC_deviation: 493.9278 Fuel Consumption: 149.0776\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_14 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:Layer batch_normalization_13 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer batch_normalization_12 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 31.078\n",
      "Episode: 4 Exploration P: 0.9903 Total reward: -5155.085447417934 SOC: 1.0000 Cumulative_SOC_deviation: 500.5100 Fuel Consumption: 149.9856\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.468\n",
      "Episode: 5 Exploration P: 0.9638 Total reward: -5091.574052831853 SOC: 1.0000 Cumulative_SOC_deviation: 494.2404 Fuel Consumption: 149.1705\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.718\n",
      "Episode: 6 Exploration P: 0.9379 Total reward: -4981.953249032387 SOC: 1.0000 Cumulative_SOC_deviation: 484.0614 Fuel Consumption: 141.3390\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.758\n",
      "Episode: 7 Exploration P: 0.9128 Total reward: -4929.704076630298 SOC: 1.0000 Cumulative_SOC_deviation: 479.0522 Fuel Consumption: 139.1825\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.460\n",
      "Episode: 8 Exploration P: 0.8883 Total reward: -4976.800954885725 SOC: 1.0000 Cumulative_SOC_deviation: 483.8465 Fuel Consumption: 138.3364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.658\n",
      "Episode: 9 Exploration P: 0.8646 Total reward: -4931.452803300609 SOC: 1.0000 Cumulative_SOC_deviation: 479.6934 Fuel Consumption: 134.5187\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.746\n",
      "Episode: 10 Exploration P: 0.8414 Total reward: -4996.362918353521 SOC: 1.0000 Cumulative_SOC_deviation: 486.0142 Fuel Consumption: 136.2212\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.665\n",
      "Episode: 11 Exploration P: 0.8189 Total reward: -4866.489433447706 SOC: 1.0000 Cumulative_SOC_deviation: 473.7398 Fuel Consumption: 129.0914\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.788\n",
      "Episode: 12 Exploration P: 0.7970 Total reward: -4915.371950129345 SOC: 1.0000 Cumulative_SOC_deviation: 478.8117 Fuel Consumption: 127.2548\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.870\n",
      "Episode: 13 Exploration P: 0.7757 Total reward: -4649.11119468925 SOC: 1.0000 Cumulative_SOC_deviation: 452.7758 Fuel Consumption: 121.3528\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.826\n",
      "Episode: 14 Exploration P: 0.7549 Total reward: -4602.306569090234 SOC: 1.0000 Cumulative_SOC_deviation: 448.2336 Fuel Consumption: 119.9702\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.037\n",
      "Episode: 15 Exploration P: 0.7347 Total reward: -4610.615720402105 SOC: 1.0000 Cumulative_SOC_deviation: 449.4618 Fuel Consumption: 115.9977\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.022\n",
      "Episode: 16 Exploration P: 0.7151 Total reward: -4623.1086687341185 SOC: 1.0000 Cumulative_SOC_deviation: 450.6368 Fuel Consumption: 116.7406\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.144\n",
      "Episode: 17 Exploration P: 0.6960 Total reward: -4553.2519369928705 SOC: 1.0000 Cumulative_SOC_deviation: 443.4582 Fuel Consumption: 118.6701\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.069\n",
      "Episode: 18 Exploration P: 0.6774 Total reward: -4601.540910415388 SOC: 1.0000 Cumulative_SOC_deviation: 448.5481 Fuel Consumption: 116.0596\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.910\n",
      "Episode: 19 Exploration P: 0.6594 Total reward: -4389.959020448176 SOC: 1.0000 Cumulative_SOC_deviation: 427.9626 Fuel Consumption: 110.3330\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.743\n",
      "Episode: 20 Exploration P: 0.6418 Total reward: -4237.3535679867355 SOC: 1.0000 Cumulative_SOC_deviation: 412.9445 Fuel Consumption: 107.9083\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.107\n",
      "Episode: 21 Exploration P: 0.6247 Total reward: -4554.409699672439 SOC: 1.0000 Cumulative_SOC_deviation: 444.4304 Fuel Consumption: 110.1060\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.034\n",
      "Episode: 22 Exploration P: 0.6080 Total reward: -4358.688698498236 SOC: 1.0000 Cumulative_SOC_deviation: 425.5393 Fuel Consumption: 103.2960\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.303\n",
      "Episode: 23 Exploration P: 0.5918 Total reward: -4345.166455631256 SOC: 1.0000 Cumulative_SOC_deviation: 424.0158 Fuel Consumption: 105.0089\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.079\n",
      "Episode: 24 Exploration P: 0.5761 Total reward: -4175.494185560392 SOC: 1.0000 Cumulative_SOC_deviation: 407.2281 Fuel Consumption: 103.2135\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.237\n",
      "Episode: 25 Exploration P: 0.5607 Total reward: -3947.485436629432 SOC: 1.0000 Cumulative_SOC_deviation: 384.7718 Fuel Consumption: 99.7672\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.275\n",
      "Episode: 26 Exploration P: 0.5458 Total reward: -3534.147201764974 SOC: 1.0000 Cumulative_SOC_deviation: 343.8497 Fuel Consumption: 95.6503\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.374\n",
      "Episode: 27 Exploration P: 0.5313 Total reward: -4006.298260044578 SOC: 1.0000 Cumulative_SOC_deviation: 391.1876 Fuel Consumption: 94.4224\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.355\n",
      "Episode: 28 Exploration P: 0.5172 Total reward: -3657.4276445885703 SOC: 1.0000 Cumulative_SOC_deviation: 356.1292 Fuel Consumption: 96.1353\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.594\n",
      "Episode: 29 Exploration P: 0.5034 Total reward: -3651.3639699847836 SOC: 1.0000 Cumulative_SOC_deviation: 355.6549 Fuel Consumption: 94.8145\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.565\n",
      "Episode: 30 Exploration P: 0.4901 Total reward: -3503.594321480367 SOC: 1.0000 Cumulative_SOC_deviation: 340.6881 Fuel Consumption: 96.7131\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.586\n",
      "Episode: 31 Exploration P: 0.4771 Total reward: -3365.7325881692027 SOC: 1.0000 Cumulative_SOC_deviation: 327.3983 Fuel Consumption: 91.7500\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.622\n",
      "Episode: 32 Exploration P: 0.4644 Total reward: -2916.3830124231454 SOC: 1.0000 Cumulative_SOC_deviation: 282.7099 Fuel Consumption: 89.2840\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.023\n",
      "Episode: 33 Exploration P: 0.4521 Total reward: -2934.4155500740403 SOC: 1.0000 Cumulative_SOC_deviation: 284.6927 Fuel Consumption: 87.4887\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.757\n",
      "Episode: 34 Exploration P: 0.4401 Total reward: -2968.651567055128 SOC: 1.0000 Cumulative_SOC_deviation: 288.1669 Fuel Consumption: 86.9831\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.435\n",
      "Episode: 35 Exploration P: 0.4285 Total reward: -3068.939438685967 SOC: 1.0000 Cumulative_SOC_deviation: 298.1626 Fuel Consumption: 87.3132\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.367\n",
      "Episode: 36 Exploration P: 0.4171 Total reward: -3130.252588782902 SOC: 1.0000 Cumulative_SOC_deviation: 304.2000 Fuel Consumption: 88.2522\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.833\n",
      "Episode: 37 Exploration P: 0.4061 Total reward: -2438.0928240551075 SOC: 1.0000 Cumulative_SOC_deviation: 235.3473 Fuel Consumption: 84.6202\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.519\n",
      "Episode: 38 Exploration P: 0.3954 Total reward: -2308.747005910084 SOC: 1.0000 Cumulative_SOC_deviation: 222.5303 Fuel Consumption: 83.4439\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.517\n",
      "Episode: 39 Exploration P: 0.3849 Total reward: -1979.9349541194576 SOC: 0.9704 Cumulative_SOC_deviation: 189.7884 Fuel Consumption: 82.0510\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.559\n",
      "Episode: 40 Exploration P: 0.3748 Total reward: -1911.335642111052 SOC: 0.9707 Cumulative_SOC_deviation: 182.9635 Fuel Consumption: 81.7002\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.561\n",
      "Episode: 41 Exploration P: 0.3649 Total reward: -1531.8494871406444 SOC: 0.9275 Cumulative_SOC_deviation: 145.3193 Fuel Consumption: 78.6563\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.729\n",
      "Episode: 42 Exploration P: 0.3553 Total reward: -1753.9295493377467 SOC: 0.9373 Cumulative_SOC_deviation: 167.4881 Fuel Consumption: 79.0484\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.650\n",
      "Episode: 43 Exploration P: 0.3459 Total reward: -1730.0315282227277 SOC: 0.9162 Cumulative_SOC_deviation: 165.1932 Fuel Consumption: 78.0991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.665\n",
      "Episode: 44 Exploration P: 0.3368 Total reward: -1086.073132635346 SOC: 0.8399 Cumulative_SOC_deviation: 101.3577 Fuel Consumption: 72.4964\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.574\n",
      "Episode: 45 Exploration P: 0.3280 Total reward: -1480.2537238720454 SOC: 0.9029 Cumulative_SOC_deviation: 140.2836 Fuel Consumption: 77.4182\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.691\n",
      "Episode: 46 Exploration P: 0.3194 Total reward: -1144.3384190226452 SOC: 0.8239 Cumulative_SOC_deviation: 107.3637 Fuel Consumption: 70.7010\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.817\n",
      "Episode: 47 Exploration P: 0.3110 Total reward: -885.5988990366924 SOC: 0.7446 Cumulative_SOC_deviation: 82.0470 Fuel Consumption: 65.1292\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.831\n",
      "Episode: 48 Exploration P: 0.3028 Total reward: -925.7894783747764 SOC: 0.7819 Cumulative_SOC_deviation: 85.7781 Fuel Consumption: 68.0080\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.811\n",
      "Episode: 49 Exploration P: 0.2949 Total reward: -1078.084624586489 SOC: 0.7513 Cumulative_SOC_deviation: 101.2120 Fuel Consumption: 65.9650\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.968\n",
      "Episode: 50 Exploration P: 0.2872 Total reward: -932.4800478192403 SOC: 0.7026 Cumulative_SOC_deviation: 87.0209 Fuel Consumption: 62.2711\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.692\n",
      "Episode: 51 Exploration P: 0.2797 Total reward: -1000.1579540524177 SOC: 0.7947 Cumulative_SOC_deviation: 93.1428 Fuel Consumption: 68.7303\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.023\n",
      "Episode: 52 Exploration P: 0.2724 Total reward: -848.8822931225959 SOC: 0.6505 Cumulative_SOC_deviation: 79.0522 Fuel Consumption: 58.3605\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.967\n",
      "Episode: 53 Exploration P: 0.2653 Total reward: -824.6784953342224 SOC: 0.6564 Cumulative_SOC_deviation: 76.6132 Fuel Consumption: 58.5463\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.276\n",
      "Episode: 54 Exploration P: 0.2584 Total reward: -1587.5137908684683 SOC: 0.5973 Cumulative_SOC_deviation: 153.3198 Fuel Consumption: 54.3158\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.241\n",
      "Episode: 55 Exploration P: 0.2516 Total reward: -877.5768242887539 SOC: 0.6572 Cumulative_SOC_deviation: 81.7999 Fuel Consumption: 59.5781\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.262\n",
      "Episode: 56 Exploration P: 0.2451 Total reward: -2020.1386892687544 SOC: 0.5131 Cumulative_SOC_deviation: 197.1673 Fuel Consumption: 48.4655\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.101\n",
      "Episode: 57 Exploration P: 0.2387 Total reward: -1435.4992208662145 SOC: 0.5879 Cumulative_SOC_deviation: 138.1833 Fuel Consumption: 53.6658\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.169\n",
      "Episode: 58 Exploration P: 0.2325 Total reward: -1443.6836305302684 SOC: 0.5966 Cumulative_SOC_deviation: 138.8594 Fuel Consumption: 55.0897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.027\n",
      "Episode: 59 Exploration P: 0.2265 Total reward: -1989.4581700976983 SOC: 0.5087 Cumulative_SOC_deviation: 194.1694 Fuel Consumption: 47.7638\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.312\n",
      "Episode: 60 Exploration P: 0.2206 Total reward: -1673.4718305856711 SOC: 0.5466 Cumulative_SOC_deviation: 162.2685 Fuel Consumption: 50.7870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.285\n",
      "Episode: 61 Exploration P: 0.2149 Total reward: -1278.458875733456 SOC: 0.5742 Cumulative_SOC_deviation: 122.5649 Fuel Consumption: 52.8094\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.273\n",
      "Episode: 62 Exploration P: 0.2094 Total reward: -1992.254677084917 SOC: 0.5107 Cumulative_SOC_deviation: 194.4006 Fuel Consumption: 48.2488\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.402\n",
      "Episode: 63 Exploration P: 0.2040 Total reward: -2210.569274366731 SOC: 0.4471 Cumulative_SOC_deviation: 216.7149 Fuel Consumption: 43.4199\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.080\n",
      "Episode: 64 Exploration P: 0.1987 Total reward: -2557.788492186882 SOC: 0.4174 Cumulative_SOC_deviation: 251.6422 Fuel Consumption: 41.3666\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.021\n",
      "Episode: 65 Exploration P: 0.1936 Total reward: -2454.9234118042873 SOC: 0.4403 Cumulative_SOC_deviation: 241.1442 Fuel Consumption: 43.4818\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.241\n",
      "Episode: 66 Exploration P: 0.1886 Total reward: -2399.213465104902 SOC: 0.4321 Cumulative_SOC_deviation: 235.7073 Fuel Consumption: 42.1404\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.041\n",
      "Episode: 67 Exploration P: 0.1838 Total reward: -2506.4698600102865 SOC: 0.3897 Cumulative_SOC_deviation: 246.7600 Fuel Consumption: 38.8696\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.177\n",
      "Episode: 68 Exploration P: 0.1791 Total reward: -3047.140760659648 SOC: 0.3258 Cumulative_SOC_deviation: 301.2450 Fuel Consumption: 34.6907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.162\n",
      "Episode: 69 Exploration P: 0.1745 Total reward: -2822.8314867189792 SOC: 0.3832 Cumulative_SOC_deviation: 278.3931 Fuel Consumption: 38.9005\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.152\n",
      "Episode: 70 Exploration P: 0.1701 Total reward: -2995.7348112026866 SOC: 0.3260 Cumulative_SOC_deviation: 296.0951 Fuel Consumption: 34.7836\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.150\n",
      "Episode: 71 Exploration P: 0.1657 Total reward: -2723.18580895084 SOC: 0.3782 Cumulative_SOC_deviation: 268.4564 Fuel Consumption: 38.6219\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.928\n",
      "Episode: 72 Exploration P: 0.1615 Total reward: -3454.4724421207598 SOC: 0.2996 Cumulative_SOC_deviation: 342.1484 Fuel Consumption: 32.9882\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.213\n",
      "Episode: 73 Exploration P: 0.1574 Total reward: -3123.5665896458063 SOC: 0.3092 Cumulative_SOC_deviation: 309.0279 Fuel Consumption: 33.2875\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.032\n",
      "Episode: 74 Exploration P: 0.1534 Total reward: -3449.3937950813997 SOC: 0.3136 Cumulative_SOC_deviation: 341.5374 Fuel Consumption: 34.0201\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.227\n",
      "Episode: 75 Exploration P: 0.1495 Total reward: -3114.9557020381512 SOC: 0.3203 Cumulative_SOC_deviation: 308.0791 Fuel Consumption: 34.1645\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.503\n",
      "Episode: 76 Exploration P: 0.1457 Total reward: -3628.9082186723904 SOC: 0.2466 Cumulative_SOC_deviation: 359.9707 Fuel Consumption: 29.2015\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.201\n",
      "Episode: 77 Exploration P: 0.1421 Total reward: -3591.84260905817 SOC: 0.2438 Cumulative_SOC_deviation: 356.2951 Fuel Consumption: 28.8919\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.507\n",
      "Episode: 78 Exploration P: 0.1385 Total reward: -3376.6990077509067 SOC: 0.2485 Cumulative_SOC_deviation: 334.7611 Fuel Consumption: 29.0880\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.583\n",
      "Episode: 79 Exploration P: 0.1350 Total reward: -3203.9092323460313 SOC: 0.6287 Cumulative_SOC_deviation: 314.5133 Fuel Consumption: 58.7758\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.523\n",
      "Episode: 80 Exploration P: 0.1316 Total reward: -270.3304488927079 SOC: 0.6217 Cumulative_SOC_deviation: 21.8479 Fuel Consumption: 51.8513\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.350\n",
      "Episode: 81 Exploration P: 0.1283 Total reward: -239.4267995999686 SOC: 0.6309 Cumulative_SOC_deviation: 18.7174 Fuel Consumption: 52.2532\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.281\n",
      "Episode: 82 Exploration P: 0.1251 Total reward: -201.34685372208716 SOC: 0.6235 Cumulative_SOC_deviation: 14.9162 Fuel Consumption: 52.1849\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.323\n",
      "Episode: 83 Exploration P: 0.1220 Total reward: -197.6426159735605 SOC: 0.6097 Cumulative_SOC_deviation: 14.7692 Fuel Consumption: 49.9502\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.325\n",
      "Episode: 84 Exploration P: 0.1190 Total reward: -160.21976347042903 SOC: 0.6176 Cumulative_SOC_deviation: 10.8624 Fuel Consumption: 51.5962\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.014\n",
      "Episode: 85 Exploration P: 0.1160 Total reward: -138.32757972962435 SOC: 0.6073 Cumulative_SOC_deviation: 8.8833 Fuel Consumption: 49.4942\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.625\n",
      "Episode: 86 Exploration P: 0.1131 Total reward: -118.36761723864228 SOC: 0.6041 Cumulative_SOC_deviation: 6.9734 Fuel Consumption: 48.6333\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.940\n",
      "Episode: 87 Exploration P: 0.1104 Total reward: -154.59631856379022 SOC: 0.6165 Cumulative_SOC_deviation: 10.4217 Fuel Consumption: 50.3789\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.966\n",
      "Episode: 88 Exploration P: 0.1076 Total reward: -155.86587245981153 SOC: 0.6060 Cumulative_SOC_deviation: 10.6035 Fuel Consumption: 49.8307\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.042\n",
      "Episode: 89 Exploration P: 0.1050 Total reward: -131.50613809844836 SOC: 0.6008 Cumulative_SOC_deviation: 8.3222 Fuel Consumption: 48.2844\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.899\n",
      "Episode: 90 Exploration P: 0.1024 Total reward: -144.17994823430823 SOC: 0.6017 Cumulative_SOC_deviation: 9.5979 Fuel Consumption: 48.2009\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.037\n",
      "Episode: 91 Exploration P: 0.0999 Total reward: -154.310384350505 SOC: 0.6049 Cumulative_SOC_deviation: 10.5235 Fuel Consumption: 49.0757\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.764\n",
      "Episode: 92 Exploration P: 0.0975 Total reward: -143.16151837459526 SOC: 0.6077 Cumulative_SOC_deviation: 9.4419 Fuel Consumption: 48.7424\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.082\n",
      "Episode: 93 Exploration P: 0.0951 Total reward: -149.5529860248357 SOC: 0.5970 Cumulative_SOC_deviation: 10.1562 Fuel Consumption: 47.9907\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.371\n",
      "Episode: 94 Exploration P: 0.0928 Total reward: -145.7530654320427 SOC: 0.5981 Cumulative_SOC_deviation: 9.7854 Fuel Consumption: 47.8992\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.332\n",
      "Episode: 95 Exploration P: 0.0906 Total reward: -151.095560831139 SOC: 0.6010 Cumulative_SOC_deviation: 10.2966 Fuel Consumption: 48.1293\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.220\n",
      "Episode: 96 Exploration P: 0.0884 Total reward: -166.56232029026052 SOC: 0.6003 Cumulative_SOC_deviation: 11.8503 Fuel Consumption: 48.0593\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.618\n",
      "Episode: 97 Exploration P: 0.0863 Total reward: -190.74659371251934 SOC: 0.5941 Cumulative_SOC_deviation: 14.3598 Fuel Consumption: 47.1485\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.199\n",
      "Episode: 98 Exploration P: 0.0842 Total reward: -199.4095128873445 SOC: 0.5960 Cumulative_SOC_deviation: 15.2021 Fuel Consumption: 47.3884\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.358\n",
      "Episode: 99 Exploration P: 0.0822 Total reward: -199.81748171686726 SOC: 0.5926 Cumulative_SOC_deviation: 15.1941 Fuel Consumption: 47.8760\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.541\n",
      "Episode: 100 Exploration P: 0.0802 Total reward: -239.42246001795093 SOC: 0.5872 Cumulative_SOC_deviation: 19.2706 Fuel Consumption: 46.7167\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.660\n",
      "Episode: 101 Exploration P: 0.0783 Total reward: -233.82299247682732 SOC: 0.5891 Cumulative_SOC_deviation: 18.6533 Fuel Consumption: 47.2897\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.561\n",
      "Episode: 102 Exploration P: 0.0765 Total reward: -208.26333829551055 SOC: 0.6057 Cumulative_SOC_deviation: 16.0675 Fuel Consumption: 47.5880\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.554\n",
      "Episode: 103 Exploration P: 0.0747 Total reward: -153.43779591706524 SOC: 0.6022 Cumulative_SOC_deviation: 10.5801 Fuel Consumption: 47.6364\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.473\n",
      "Episode: 104 Exploration P: 0.0729 Total reward: -134.7023172714836 SOC: 0.6095 Cumulative_SOC_deviation: 8.6815 Fuel Consumption: 47.8873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.594\n",
      "Episode: 105 Exploration P: 0.0712 Total reward: -140.955805246881 SOC: 0.5972 Cumulative_SOC_deviation: 9.4357 Fuel Consumption: 46.5991\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.808\n",
      "Episode: 106 Exploration P: 0.0696 Total reward: -133.55291437572347 SOC: 0.6007 Cumulative_SOC_deviation: 8.7196 Fuel Consumption: 46.3573\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.487\n",
      "Episode: 107 Exploration P: 0.0679 Total reward: -128.4169017718426 SOC: 0.6054 Cumulative_SOC_deviation: 8.0776 Fuel Consumption: 47.6407\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.485\n",
      "Episode: 108 Exploration P: 0.0664 Total reward: -124.0902771593002 SOC: 0.5982 Cumulative_SOC_deviation: 7.7239 Fuel Consumption: 46.8513\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.483\n",
      "Episode: 109 Exploration P: 0.0648 Total reward: -124.18142163060156 SOC: 0.6012 Cumulative_SOC_deviation: 7.7319 Fuel Consumption: 46.8623\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.532\n",
      "Episode: 110 Exploration P: 0.0634 Total reward: -129.60603659406738 SOC: 0.6026 Cumulative_SOC_deviation: 8.2501 Fuel Consumption: 47.1054\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.451\n",
      "Episode: 111 Exploration P: 0.0619 Total reward: -133.8625437671139 SOC: 0.5979 Cumulative_SOC_deviation: 8.6494 Fuel Consumption: 47.3686\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.254\n",
      "Episode: 112 Exploration P: 0.0605 Total reward: -140.14199128377953 SOC: 0.6067 Cumulative_SOC_deviation: 9.2388 Fuel Consumption: 47.7544\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.625\n",
      "Episode: 113 Exploration P: 0.0591 Total reward: -131.1572245271403 SOC: 0.5987 Cumulative_SOC_deviation: 8.4319 Fuel Consumption: 46.8384\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.598\n",
      "Episode: 114 Exploration P: 0.0578 Total reward: -135.50729296662124 SOC: 0.6042 Cumulative_SOC_deviation: 8.7921 Fuel Consumption: 47.5865\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.134\n",
      "Episode: 115 Exploration P: 0.0565 Total reward: -128.46302022007055 SOC: 0.6007 Cumulative_SOC_deviation: 8.1597 Fuel Consumption: 46.8658\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.171\n",
      "Episode: 116 Exploration P: 0.0553 Total reward: -130.6619032099905 SOC: 0.6047 Cumulative_SOC_deviation: 8.3586 Fuel Consumption: 47.0755\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.375\n",
      "Episode: 117 Exploration P: 0.0540 Total reward: -117.47569696399415 SOC: 0.6063 Cumulative_SOC_deviation: 7.0260 Fuel Consumption: 47.2160\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.163\n",
      "Episode: 118 Exploration P: 0.0528 Total reward: -119.97665229589437 SOC: 0.6096 Cumulative_SOC_deviation: 7.3220 Fuel Consumption: 46.7566\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.351\n",
      "Episode: 119 Exploration P: 0.0517 Total reward: -127.16268277317342 SOC: 0.5945 Cumulative_SOC_deviation: 8.0956 Fuel Consumption: 46.2065\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.416\n",
      "Episode: 120 Exploration P: 0.0505 Total reward: -143.48982819291334 SOC: 0.5995 Cumulative_SOC_deviation: 9.7172 Fuel Consumption: 46.3180\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.549\n",
      "Episode: 121 Exploration P: 0.0495 Total reward: -143.85431331849753 SOC: 0.5949 Cumulative_SOC_deviation: 9.7444 Fuel Consumption: 46.4105\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.339\n",
      "Episode: 122 Exploration P: 0.0484 Total reward: -152.06046983121712 SOC: 0.5909 Cumulative_SOC_deviation: 10.6204 Fuel Consumption: 45.8570\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.226\n",
      "Episode: 123 Exploration P: 0.0473 Total reward: -178.7996024933519 SOC: 0.5942 Cumulative_SOC_deviation: 13.2304 Fuel Consumption: 46.4955\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.446\n",
      "Episode: 124 Exploration P: 0.0463 Total reward: -159.338030504145 SOC: 0.5933 Cumulative_SOC_deviation: 11.3157 Fuel Consumption: 46.1813\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.269\n",
      "Episode: 125 Exploration P: 0.0453 Total reward: -153.78531258581663 SOC: 0.5949 Cumulative_SOC_deviation: 10.7388 Fuel Consumption: 46.3977\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.562\n",
      "Episode: 126 Exploration P: 0.0444 Total reward: -110.83554995880418 SOC: 0.6011 Cumulative_SOC_deviation: 6.4348 Fuel Consumption: 46.4877\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.741\n",
      "Episode: 127 Exploration P: 0.0435 Total reward: -107.21579211373441 SOC: 0.6106 Cumulative_SOC_deviation: 6.0209 Fuel Consumption: 47.0071\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.344\n",
      "Episode: 128 Exploration P: 0.0426 Total reward: -110.18677412445238 SOC: 0.6143 Cumulative_SOC_deviation: 6.3091 Fuel Consumption: 47.0953\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.361\n",
      "Episode: 129 Exploration P: 0.0417 Total reward: -101.68195473866287 SOC: 0.6027 Cumulative_SOC_deviation: 5.5362 Fuel Consumption: 46.3202\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.446\n",
      "Episode: 130 Exploration P: 0.0408 Total reward: -112.671051666834 SOC: 0.6038 Cumulative_SOC_deviation: 6.6071 Fuel Consumption: 46.6000\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.433\n",
      "Episode: 131 Exploration P: 0.0400 Total reward: -115.56176754655269 SOC: 0.6036 Cumulative_SOC_deviation: 6.8975 Fuel Consumption: 46.5870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.182\n",
      "Episode: 132 Exploration P: 0.0392 Total reward: -113.90625525632838 SOC: 0.6063 Cumulative_SOC_deviation: 6.7430 Fuel Consumption: 46.4762\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.752\n",
      "Episode: 133 Exploration P: 0.0384 Total reward: -104.53990017604764 SOC: 0.6011 Cumulative_SOC_deviation: 5.8697 Fuel Consumption: 45.8427\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.505\n",
      "Episode: 134 Exploration P: 0.0376 Total reward: -105.26162950171687 SOC: 0.6030 Cumulative_SOC_deviation: 5.9144 Fuel Consumption: 46.1172\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.553\n",
      "Episode: 135 Exploration P: 0.0369 Total reward: -111.75867947756426 SOC: 0.6079 Cumulative_SOC_deviation: 6.5105 Fuel Consumption: 46.6542\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.546\n",
      "Episode: 136 Exploration P: 0.0361 Total reward: -111.43558420831377 SOC: 0.6035 Cumulative_SOC_deviation: 6.5350 Fuel Consumption: 46.0856\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.182\n",
      "Episode: 137 Exploration P: 0.0354 Total reward: -112.80633067688105 SOC: 0.6046 Cumulative_SOC_deviation: 6.6418 Fuel Consumption: 46.3879\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.333\n",
      "Episode: 138 Exploration P: 0.0347 Total reward: -119.02720258980912 SOC: 0.6047 Cumulative_SOC_deviation: 7.1756 Fuel Consumption: 47.2711\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.297\n",
      "Episode: 139 Exploration P: 0.0341 Total reward: -113.69479883575762 SOC: 0.6022 Cumulative_SOC_deviation: 6.7669 Fuel Consumption: 46.0262\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.830\n",
      "Episode: 140 Exploration P: 0.0334 Total reward: -109.39809081721624 SOC: 0.6012 Cumulative_SOC_deviation: 6.3803 Fuel Consumption: 45.5947\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.487\n",
      "Episode: 141 Exploration P: 0.0328 Total reward: -119.5083321993694 SOC: 0.6033 Cumulative_SOC_deviation: 7.3346 Fuel Consumption: 46.1626\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.336\n",
      "Episode: 142 Exploration P: 0.0322 Total reward: -118.4009697957892 SOC: 0.6019 Cumulative_SOC_deviation: 7.2282 Fuel Consumption: 46.1188\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.558\n",
      "Episode: 143 Exploration P: 0.0316 Total reward: -120.25215299085032 SOC: 0.5990 Cumulative_SOC_deviation: 7.4494 Fuel Consumption: 45.7580\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.948\n",
      "Episode: 144 Exploration P: 0.0310 Total reward: -130.66392417128984 SOC: 0.6011 Cumulative_SOC_deviation: 8.4519 Fuel Consumption: 46.1454\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.660\n",
      "Episode: 145 Exploration P: 0.0304 Total reward: -106.1535384764644 SOC: 0.5994 Cumulative_SOC_deviation: 6.0480 Fuel Consumption: 45.6731\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.233\n",
      "Episode: 146 Exploration P: 0.0299 Total reward: -123.25002229984095 SOC: 0.6059 Cumulative_SOC_deviation: 7.7223 Fuel Consumption: 46.0274\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.133\n",
      "Episode: 147 Exploration P: 0.0293 Total reward: -115.10677085703112 SOC: 0.6079 Cumulative_SOC_deviation: 6.8692 Fuel Consumption: 46.4146\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.337\n",
      "Episode: 148 Exploration P: 0.0288 Total reward: -119.20384331364521 SOC: 0.6038 Cumulative_SOC_deviation: 7.2891 Fuel Consumption: 46.3125\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.436\n",
      "Episode: 149 Exploration P: 0.0283 Total reward: -106.88829457142636 SOC: 0.6006 Cumulative_SOC_deviation: 6.1075 Fuel Consumption: 45.8136\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 68.801\n",
      "Episode: 150 Exploration P: 0.0278 Total reward: -116.65473121563419 SOC: 0.6022 Cumulative_SOC_deviation: 7.0452 Fuel Consumption: 46.2026\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.375\n",
      "Episode: 151 Exploration P: 0.0273 Total reward: -108.21928249853725 SOC: 0.5976 Cumulative_SOC_deviation: 6.2854 Fuel Consumption: 45.3649\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.266\n",
      "Episode: 152 Exploration P: 0.0268 Total reward: -131.50967993489337 SOC: 0.6038 Cumulative_SOC_deviation: 8.5453 Fuel Consumption: 46.0565\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.298\n",
      "Episode: 153 Exploration P: 0.0264 Total reward: -109.52322999497765 SOC: 0.6038 Cumulative_SOC_deviation: 6.3484 Fuel Consumption: 46.0393\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.459\n",
      "Episode: 154 Exploration P: 0.0259 Total reward: -111.97021689127119 SOC: 0.6035 Cumulative_SOC_deviation: 6.5782 Fuel Consumption: 46.1882\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.135\n",
      "Episode: 155 Exploration P: 0.0255 Total reward: -118.9046077367895 SOC: 0.6051 Cumulative_SOC_deviation: 7.2711 Fuel Consumption: 46.1936\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.297\n",
      "Episode: 156 Exploration P: 0.0251 Total reward: -114.68943196028289 SOC: 0.6011 Cumulative_SOC_deviation: 6.8643 Fuel Consumption: 46.0465\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.359\n",
      "Episode: 157 Exploration P: 0.0247 Total reward: -112.39616963122522 SOC: 0.6022 Cumulative_SOC_deviation: 6.6281 Fuel Consumption: 46.1156\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.362\n",
      "Episode: 158 Exploration P: 0.0243 Total reward: -109.61859674361321 SOC: 0.6033 Cumulative_SOC_deviation: 6.3580 Fuel Consumption: 46.0391\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.177\n",
      "Episode: 159 Exploration P: 0.0239 Total reward: -148.03979606040392 SOC: 0.6033 Cumulative_SOC_deviation: 10.2098 Fuel Consumption: 45.9419\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.421\n",
      "Episode: 160 Exploration P: 0.0235 Total reward: -119.42671911183052 SOC: 0.6064 Cumulative_SOC_deviation: 7.3440 Fuel Consumption: 45.9870\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.606\n",
      "Episode: 161 Exploration P: 0.0232 Total reward: -114.0580972614913 SOC: 0.6033 Cumulative_SOC_deviation: 6.8439 Fuel Consumption: 45.6191\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.555\n",
      "Episode: 162 Exploration P: 0.0228 Total reward: -111.71622354988584 SOC: 0.6049 Cumulative_SOC_deviation: 6.5429 Fuel Consumption: 46.2873\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.970\n",
      "Episode: 163 Exploration P: 0.0225 Total reward: -125.00892853091315 SOC: 0.5981 Cumulative_SOC_deviation: 7.9527 Fuel Consumption: 45.4816\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.544\n",
      "Episode: 164 Exploration P: 0.0221 Total reward: -115.37159438750214 SOC: 0.6004 Cumulative_SOC_deviation: 6.9720 Fuel Consumption: 45.6512\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.408\n",
      "Episode: 165 Exploration P: 0.0218 Total reward: -111.60282362869586 SOC: 0.5941 Cumulative_SOC_deviation: 6.6532 Fuel Consumption: 45.0707\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.395\n",
      "Episode: 166 Exploration P: 0.0215 Total reward: -129.64379476804888 SOC: 0.5998 Cumulative_SOC_deviation: 8.4518 Fuel Consumption: 45.1258\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.301\n",
      "Episode: 167 Exploration P: 0.0212 Total reward: -109.08227933996433 SOC: 0.6040 Cumulative_SOC_deviation: 6.3281 Fuel Consumption: 45.8014\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.672\n",
      "Episode: 168 Exploration P: 0.0209 Total reward: -109.9996392778081 SOC: 0.6034 Cumulative_SOC_deviation: 6.4071 Fuel Consumption: 45.9291\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.505\n",
      "Episode: 169 Exploration P: 0.0206 Total reward: -115.61151282909829 SOC: 0.6036 Cumulative_SOC_deviation: 7.0052 Fuel Consumption: 45.5599\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.203\n",
      "Episode: 170 Exploration P: 0.0203 Total reward: -115.82886963527584 SOC: 0.6003 Cumulative_SOC_deviation: 7.0274 Fuel Consumption: 45.5552\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.985\n",
      "Episode: 171 Exploration P: 0.0200 Total reward: -114.13385782864118 SOC: 0.6019 Cumulative_SOC_deviation: 6.8775 Fuel Consumption: 45.3593\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.756\n",
      "Episode: 172 Exploration P: 0.0197 Total reward: -117.39867412520053 SOC: 0.6022 Cumulative_SOC_deviation: 7.2044 Fuel Consumption: 45.3550\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.417\n",
      "Episode: 173 Exploration P: 0.0195 Total reward: -115.48586099483667 SOC: 0.5988 Cumulative_SOC_deviation: 7.0388 Fuel Consumption: 45.0982\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.391\n",
      "Episode: 174 Exploration P: 0.0192 Total reward: -118.24483022119571 SOC: 0.6032 Cumulative_SOC_deviation: 7.2513 Fuel Consumption: 45.7323\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.475\n",
      "Episode: 175 Exploration P: 0.0190 Total reward: -111.76810808845082 SOC: 0.6030 Cumulative_SOC_deviation: 6.6239 Fuel Consumption: 45.5292\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.643\n",
      "Episode: 176 Exploration P: 0.0187 Total reward: -111.2796914130443 SOC: 0.5973 Cumulative_SOC_deviation: 6.6112 Fuel Consumption: 45.1682\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.483\n",
      "Episode: 177 Exploration P: 0.0185 Total reward: -121.95895941779446 SOC: 0.5983 Cumulative_SOC_deviation: 7.6829 Fuel Consumption: 45.1296\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.846\n",
      "Episode: 178 Exploration P: 0.0182 Total reward: -125.82331999707392 SOC: 0.5988 Cumulative_SOC_deviation: 8.0511 Fuel Consumption: 45.3119\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 66.027\n",
      "Episode: 179 Exploration P: 0.0180 Total reward: -111.5547621815594 SOC: 0.6027 Cumulative_SOC_deviation: 6.6616 Fuel Consumption: 44.9384\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 69.608\n",
      "Episode: 180 Exploration P: 0.0178 Total reward: -116.56877821099283 SOC: 0.6050 Cumulative_SOC_deviation: 7.0869 Fuel Consumption: 45.6998\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 67.210\n",
      "Episode: 181 Exploration P: 0.0176 Total reward: -115.48077300552167 SOC: 0.6002 Cumulative_SOC_deviation: 7.0351 Fuel Consumption: 45.1296\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.970\n",
      "Episode: 182 Exploration P: 0.0174 Total reward: -131.57786916303817 SOC: 0.5993 Cumulative_SOC_deviation: 8.6494 Fuel Consumption: 45.0839\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.956\n",
      "Episode: 183 Exploration P: 0.0172 Total reward: -139.09323856995218 SOC: 0.6012 Cumulative_SOC_deviation: 9.3931 Fuel Consumption: 45.1618\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.787\n",
      "Episode: 184 Exploration P: 0.0170 Total reward: -116.18560580393032 SOC: 0.5975 Cumulative_SOC_deviation: 7.1221 Fuel Consumption: 44.9647\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.870\n",
      "Episode: 185 Exploration P: 0.0168 Total reward: -129.4301387123269 SOC: 0.5955 Cumulative_SOC_deviation: 8.4328 Fuel Consumption: 45.1023\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.897\n",
      "Episode: 186 Exploration P: 0.0166 Total reward: -120.62184631563966 SOC: 0.5984 Cumulative_SOC_deviation: 7.5277 Fuel Consumption: 45.3452\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.685\n",
      "Episode: 187 Exploration P: 0.0164 Total reward: -126.57817783952129 SOC: 0.5979 Cumulative_SOC_deviation: 8.1443 Fuel Consumption: 45.1351\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.753\n",
      "Episode: 188 Exploration P: 0.0163 Total reward: -132.8251158702281 SOC: 0.5981 Cumulative_SOC_deviation: 8.7774 Fuel Consumption: 45.0507\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.778\n",
      "Episode: 189 Exploration P: 0.0161 Total reward: -122.79645925288348 SOC: 0.5978 Cumulative_SOC_deviation: 7.7684 Fuel Consumption: 45.1121\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.744\n",
      "Episode: 190 Exploration P: 0.0159 Total reward: -132.71298055498272 SOC: 0.5978 Cumulative_SOC_deviation: 8.7694 Fuel Consumption: 45.0189\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.578\n",
      "Episode: 191 Exploration P: 0.0158 Total reward: -118.16142034865629 SOC: 0.5986 Cumulative_SOC_deviation: 7.3094 Fuel Consumption: 45.0676\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.888\n",
      "Episode: 192 Exploration P: 0.0156 Total reward: -122.62830283225999 SOC: 0.5957 Cumulative_SOC_deviation: 7.7849 Fuel Consumption: 44.7792\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.837\n",
      "Episode: 193 Exploration P: 0.0155 Total reward: -109.88955330177569 SOC: 0.5996 Cumulative_SOC_deviation: 6.4492 Fuel Consumption: 45.3979\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 63.141\n",
      "Episode: 194 Exploration P: 0.0153 Total reward: -124.81631210356984 SOC: 0.5983 Cumulative_SOC_deviation: 7.9730 Fuel Consumption: 45.0863\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.630\n",
      "Episode: 195 Exploration P: 0.0152 Total reward: -117.73496678389277 SOC: 0.5988 Cumulative_SOC_deviation: 7.2505 Fuel Consumption: 45.2297\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.724\n",
      "Episode: 196 Exploration P: 0.0150 Total reward: -129.43565954477413 SOC: 0.5995 Cumulative_SOC_deviation: 8.3762 Fuel Consumption: 45.6741\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.818\n",
      "Episode: 197 Exploration P: 0.0149 Total reward: -135.35363374890935 SOC: 0.5969 Cumulative_SOC_deviation: 9.0368 Fuel Consumption: 44.9852\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.991\n",
      "Episode: 198 Exploration P: 0.0148 Total reward: -134.00799884393712 SOC: 0.5959 Cumulative_SOC_deviation: 8.9390 Fuel Consumption: 44.6177\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.866\n",
      "Episode: 199 Exploration P: 0.0146 Total reward: -126.83662955483217 SOC: 0.5983 Cumulative_SOC_deviation: 8.1580 Fuel Consumption: 45.2570\n",
      "\n",
      "maximum steps, simulation is done ... \n",
      "elapsed_time: 62.848\n",
      "Episode: 200 Exploration P: 0.0145 Total reward: -133.27598989094506 SOC: 0.5965 Cumulative_SOC_deviation: 8.8105 Fuel Consumption: 45.1713\n",
      "\n",
      "model is saved..\n"
     ]
    }
   ],
   "source": [
    "# print(env.version)\n",
    "\n",
    "# num_trials = 1\n",
    "reward_factors = [7, 8, 9, 10]\n",
    "results_dict = {} \n",
    "driving_cycle_path = '../../OC_SIM_DB/OC_SIM_DB_Cycles/Highway/01_FTP72_fuds.mat'\n",
    "driving_cycle = sio.loadmat(driving_cycle_path)\n",
    "driving_cycle = driving_cycle[\"sch_cycle\"][:, 1]\n",
    "\n",
    "for reward_factor in reward_factors: \n",
    "    print(\"\")\n",
    "    print(\"Trial {}\".format(reward_factor))\n",
    "    print(\"\")\n",
    "    \n",
    "    actor_model, critic_model, target_actor, target_critic, buffer = initialization()\n",
    "    \n",
    "    eps = MAX_EPSILON \n",
    "    steps = 0\n",
    "    \n",
    "    episode_rewards = [] \n",
    "    episode_SOCs = [] \n",
    "    episode_FCs = [] \n",
    "    episode_test_history = [] \n",
    "    episode_num_test = [] \n",
    "    for ep in range(total_episodes): \n",
    "#         driving_cycle = driver.get_cycle() \n",
    "        env = initialization_env(driving_cycle, reward_factor)\n",
    "        \n",
    "        start = time.time() \n",
    "        state = env.reset() \n",
    "        episodic_reward = 0 \n",
    "\n",
    "        while True: \n",
    "            tf_state = tf.expand_dims(tf.convert_to_tensor(state), 0)\n",
    "            action = policy_epsilon_greedy(tf_state, eps)\n",
    "    #         print(action)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            if done: \n",
    "                next_state = [0] * num_states \n",
    "\n",
    "            buffer.record((state, action, reward, next_state))\n",
    "            episodic_reward += reward \n",
    "\n",
    "            if steps > DELAY_TRAINING: \n",
    "                buffer.learn() \n",
    "                update_target(tau)\n",
    "                eps = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE * (steps\n",
    "                                                                        -DELAY_TRAINING))\n",
    "\n",
    "            steps += 1\n",
    "\n",
    "            if done: \n",
    "                break \n",
    "\n",
    "            state = next_state \n",
    "\n",
    "        elapsed_time = time.time() - start \n",
    "        print(\"elapsed_time: {:.3f}\".format(elapsed_time))\n",
    "        episode_rewards.append(episodic_reward) \n",
    "        episode_SOCs.append(env.SOC)\n",
    "        episode_FCs.append(env.fuel_consumption) \n",
    "\n",
    "    #     print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "        SOC_deviation_history = np.sum(np.abs(np.array(env.history[\"SOC\"]) - 0.6)) \n",
    "        print(\n",
    "              'Episode: {}'.format(ep + 1),\n",
    "              \"Exploration P: {:.4f}\".format(eps),\n",
    "              'Total reward: {}'.format(episodic_reward), \n",
    "              \"SOC: {:.4f}\".format(env.SOC), \n",
    "              \"Cumulative_SOC_deviation: {:.4f}\".format(SOC_deviation_history), \n",
    "              \"Fuel Consumption: {:.4f}\".format(env.fuel_consumption), \n",
    "        )\n",
    "        print(\"\")\n",
    "        \n",
    "        if (ep + 1) % 10 == 0: \n",
    "#             history = test_agent(actor_model, reward_factor)\n",
    "            history = env.history \n",
    "            episode_test_history.append(history) \n",
    "            episode_num_test.append(ep + 1)\n",
    "            \n",
    "#         if (ep + 1) % 200 == 0:             \n",
    "    root = \"DDPG_cycleOne_reward_factor{}\".format(reward_factor)\n",
    "    save_weights(actor_model, critic_model, target_actor, target_critic, root)\n",
    "            \n",
    "    \n",
    "    results_dict[reward_factor] = {\n",
    "        \"rewards\": episode_rewards, \n",
    "        \"SOCs\": episode_SOCs, \n",
    "        \"FCs\": episode_FCs, \n",
    "        \"test_history\": episode_test_history, \n",
    "        \"test_episode_num\": episode_num_test, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"DDPG_cycleOne_7to10.pkl\", \"wb\") as f: \n",
    "    pickle.dump(results_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
